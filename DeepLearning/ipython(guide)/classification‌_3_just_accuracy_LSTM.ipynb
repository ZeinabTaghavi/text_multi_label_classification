{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.1"},"colab":{"name":"classification‌_3_just_accuracy_LSTM.ipynb","provenance":[{"file_id":"198n7rjL8wKTk0rjOE4cc3QltV9EEG2CK","timestamp":1608716289786},{"file_id":"1q0XyNMhL70yLKyMRRicbK3dFzngLAPAw","timestamp":1608434664847},{"file_id":"13NicNTDwerqE8tlbE7iTAEAsBIPdEZbm","timestamp":1608297413509}],"collapsed_sections":[]}},"cells":[{"cell_type":"markdown","metadata":{"id":"iVt79YwP91Ku"},"source":["A neural network consist of cnn layer (Yoon Kim,2014) and 4 fully connected layers.\r\n","\r\n","Source: https://github.com/jojonki/cnn-for-sentence-classification\r\n","\r\n","\r\n","\r\n"]},{"cell_type":"code","metadata":{"id":"QmY-dTGAAXEk","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1608953989902,"user_tz":-210,"elapsed":33266,"user":{"displayName":"zeinab taghavi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GheNU3ejtJBEFfDC_0W_JdLEuwkW7SKnnDuH80MRA=s64","userId":"07214630829740929140"}},"outputId":"781aa575-d703-4691-a70f-13c68d9feade"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"jajq2iOXA-2q","executionInfo":{"status":"ok","timestamp":1608954002966,"user_tz":-210,"elapsed":1115,"user":{"displayName":"zeinab taghavi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GheNU3ejtJBEFfDC_0W_JdLEuwkW7SKnnDuH80MRA=s64","userId":"07214630829740929140"}}},"source":["import os\n","os.chdir('/content/drive/MyDrive/sharif/DeepLearning/ipython(guide)')"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"KWHVC9OB6b3E","executionInfo":{"status":"ok","timestamp":1608954006650,"user_tz":-210,"elapsed":4610,"user":{"displayName":"zeinab taghavi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GheNU3ejtJBEFfDC_0W_JdLEuwkW7SKnnDuH80MRA=s64","userId":"07214630829740929140"}}},"source":["import numpy as np\n","import codecs\n","import os\n","import random\n","import pandas\n","from keras import backend as K\n","from keras.models import Model\n","from keras.layers.embeddings import Embedding\n","from keras.layers import Input, Dense, Lambda, Permute, Dropout\n","from keras.layers import Conv2D, MaxPooling1D\n","from keras.optimizers import SGD\n","import ast\n","import re\n","from sklearn.preprocessing import MultiLabelBinarizer\n","from sklearn.model_selection import train_test_split\n","import gensim\n","from keras.models import load_model\n","from keras.callbacks import EarlyStopping, ModelCheckpoint"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"CJj759Rj6b3L","executionInfo":{"status":"ok","timestamp":1608954015753,"user_tz":-210,"elapsed":12517,"user":{"displayName":"zeinab taghavi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GheNU3ejtJBEFfDC_0W_JdLEuwkW7SKnnDuH80MRA=s64","userId":"07214630829740929140"}}},"source":["limit_number = 750\n","data = pandas.read_csv('../Data/limited_to_'+str(limit_number)+'.csv',index_col=0,converters={'body': eval})\n","data = data.dropna().reset_index(drop=True)\n","X = data[\"body\"].values.tolist()\n","y = pandas.read_csv('../Data/limited_to_'+str(limit_number)+'.csv')\n","labels = []\n","tag=[]\n","for item in y['tag']:\n","  labels += [i for i in re.sub('\\\"|\\[|\\]|\\'| |=','',item.lower()).split(\",\") if i!='' and i!=' ']\n","  tag.append([i for i in re.sub('\\\"|\\[|\\]|\\'| |=','',item.lower()).split(\",\") if i!='' and i!=' '])\n","labels = list(set(labels))\n","mlb = MultiLabelBinarizer()\n","Y=mlb.fit_transform(tag)"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vM997bpQcX9A","executionInfo":{"status":"ok","timestamp":1608954015755,"user_tz":-210,"elapsed":12280,"user":{"displayName":"zeinab taghavi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GheNU3ejtJBEFfDC_0W_JdLEuwkW7SKnnDuH80MRA=s64","userId":"07214630829740929140"}},"outputId":"ef19ff0c-6be4-406c-e754-b8dbf3c4d953"},"source":["len(labels)"],"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/plain":["78"]},"metadata":{"tags":[]},"execution_count":5}]},{"cell_type":"code","metadata":{"id":"9_VUcunM6b3M","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1608954015756,"user_tz":-210,"elapsed":12127,"user":{"displayName":"zeinab taghavi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GheNU3ejtJBEFfDC_0W_JdLEuwkW7SKnnDuH80MRA=s64","userId":"07214630829740929140"}},"outputId":"26eb9518-2294-4a30-f709-0f9c4fe7a2f3"},"source":["sentence_maxlen = max(map(len, (d for d in X)))\n","print('sentence maxlen', sentence_maxlen)"],"execution_count":6,"outputs":[{"output_type":"stream","text":["sentence maxlen 300\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"W_7JIWCbF6GP","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1608954016232,"user_tz":-210,"elapsed":12405,"user":{"displayName":"zeinab taghavi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GheNU3ejtJBEFfDC_0W_JdLEuwkW7SKnnDuH80MRA=s64","userId":"07214630829740929140"}},"outputId":"e1bd5a6c-04a8-4ec4-87c7-52d72ea348b6"},"source":["freq_dist = pandas.read_csv('../Data/FreqDist_sorted.csv',index_col=False)\n","vocab=[]\n","for item in freq_dist[\"word\"]:\n","  try:\n","    word=re.sub(r\"[\\u200c-\\u200f]\",\"\",item.replace(\" \",\"\"))\n","    vocab.append(word)\n","  except:\n","    pass\n","  \n","print(vocab[10])"],"execution_count":7,"outputs":[{"output_type":"stream","text":["زبان\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"jo8Gh3Se4cDR","executionInfo":{"status":"ok","timestamp":1608954016699,"user_tz":-210,"elapsed":12690,"user":{"displayName":"zeinab taghavi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GheNU3ejtJBEFfDC_0W_JdLEuwkW7SKnnDuH80MRA=s64","userId":"07214630829740929140"}}},"source":["vocab = sorted(vocab)\n","vocab_size = len(vocab)"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"AvQ6Yn7r6b3N","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1608954016699,"user_tz":-210,"elapsed":12495,"user":{"displayName":"zeinab taghavi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GheNU3ejtJBEFfDC_0W_JdLEuwkW7SKnnDuH80MRA=s64","userId":"07214630829740929140"}},"outputId":"a11e1f58-dd90-4b8f-9956-627b2838fe59"},"source":["print('vocab size', len(vocab))\n","w2i = {w:i for i,w in enumerate(vocab)}\n","# i2w = {i:w for i,w in enumerate(vocab)}\n","print(w2i[\"زبان\"])"],"execution_count":9,"outputs":[{"output_type":"stream","text":["vocab size 225345\n","129280\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"collapsed":true,"id":"-CWX1GRP6b3N","executionInfo":{"status":"ok","timestamp":1608954018645,"user_tz":-210,"elapsed":14260,"user":{"displayName":"zeinab taghavi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GheNU3ejtJBEFfDC_0W_JdLEuwkW7SKnnDuH80MRA=s64","userId":"07214630829740929140"}}},"source":["def vectorize(data, sentence_maxlen, w2i):\n","    vec_data = []\n","    \n","    for d in data:\n","       \n","        vec = [w2i[w] for w in d if w in w2i]\n","        pad_len = max(0, sentence_maxlen - len(vec))\n","        vec += [0] * pad_len\n","        vec_data.append(vec)\n","        # print(d)\n","        \n","    vec_data = np.array(vec_data)\n","    \n","    return vec_data\n","\n","vecX = vectorize(X, sentence_maxlen, w2i)\n","vecY=Y"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"Rrx-u3vO6b3N","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1608954018649,"user_tz":-210,"elapsed":14071,"user":{"displayName":"zeinab taghavi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GheNU3ejtJBEFfDC_0W_JdLEuwkW7SKnnDuH80MRA=s64","userId":"07214630829740929140"}},"outputId":"58420277-3c61-42bc-bd7b-0d7d273dd17d"},"source":["X_train, X_test, y_train, y_test = train_test_split(vecX, vecY, test_size=0.2)\n","X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25)\n","print('train: ', X_train.shape , '\\ntest: ', X_test.shape , '\\nval: ', X_val.shape ,\"\\ny_tain:\",y_train.shape )\n","# print(vecX[0])"],"execution_count":11,"outputs":[{"output_type":"stream","text":["train:  (12935, 300) \n","test:  (4312, 300) \n","val:  (4312, 300) \n","y_tain: (12935, 78)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"2NN8pBPe6b3O","executionInfo":{"status":"ok","timestamp":1608954018650,"user_tz":-210,"elapsed":13910,"user":{"displayName":"zeinab taghavi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GheNU3ejtJBEFfDC_0W_JdLEuwkW7SKnnDuH80MRA=s64","userId":"07214630829740929140"}}},"source":["embd_dim = 300\n"],"execution_count":12,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"bKcEzoCqCdfg"},"source":["# ***If the word2vec model is not generated before, we should run the next block.***"]},{"cell_type":"code","metadata":{"id":"0E91RDFOAsM-","executionInfo":{"status":"ok","timestamp":1608954018650,"user_tz":-210,"elapsed":13056,"user":{"displayName":"zeinab taghavi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GheNU3ejtJBEFfDC_0W_JdLEuwkW7SKnnDuH80MRA=s64","userId":"07214630829740929140"}}},"source":["# embed_model = gensim.models.Word2Vec(X, size=embd_dim, window=5, min_count=5)\r\n","# embed_model.save('word2vec_model')"],"execution_count":13,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hlk6Pf3XDY_K"},"source":["# ***Otherwise, we can run the next block.***"]},{"cell_type":"code","metadata":{"id":"ROzrPxYhAxL1","executionInfo":{"status":"ok","timestamp":1608954020921,"user_tz":-210,"elapsed":14983,"user":{"displayName":"zeinab taghavi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GheNU3ejtJBEFfDC_0W_JdLEuwkW7SKnnDuH80MRA=s64","userId":"07214630829740929140"}}},"source":["embed_model=gensim.models.Word2Vec.load('word2vec_model')"],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"id":"mMysImM9Fd01","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1608954021377,"user_tz":-210,"elapsed":14887,"user":{"displayName":"zeinab taghavi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GheNU3ejtJBEFfDC_0W_JdLEuwkW7SKnnDuH80MRA=s64","userId":"07214630829740929140"}},"outputId":"02854388-e527-4deb-ed75-1c6e35e115cd"},"source":["word2vec_embd_w = np.zeros((vocab_size, embd_dim))\n","for word, i in w2i.items():\n","  if word in embed_model.wv.vocab:\n","        embedding_vector =embed_model[word]\n","  \n","        # words not found in embedding index will be all-zeros.\n","        word2vec_embd_w[i] = embedding_vector"],"execution_count":15,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n","  after removing the cwd from sys.path.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"OKOLRwWv6b3O","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1608890539109,"user_tz":-210,"elapsed":2687,"user":{"displayName":"zeinab taghavi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GheNU3ejtJBEFfDC_0W_JdLEuwkW7SKnnDuH80MRA=s64","userId":"07214630829740929140"}},"outputId":"8eacc2b0-c4a5-4913-c7c0-3d67a8959fb9"},"source":["def Net(vocab_size, embd_size, sentence_maxlen, glove_embd_w):\n","    sentence = Input((sentence_maxlen,), name='SentenceInput')\n","    \n","    # embedding\n","    embd_layer = Embedding(input_dim=vocab_size, \n","                           output_dim=embd_size, \n","                           weights=[word2vec_embd_w], \n","                           trainable=False,\n","                           name='shared_embd')\n","    embd_sentence = embd_layer(sentence)\n","    # embd_sentence = Permute((2,1))(embd_sentence)\n","    # embd_sentence = Lambda(lambda x: K.expand_dims(x, -1))(embd_sentence)\n","    \n","    # lstm\n","    lstm_1 = LSTM(128, return_sequences=True,name='lstm_1')(embd_sentence)\n","    # drop_out_1 = Dropout(0.5,name='drop_out_1')(lstm_1)\n","    lstm_2 = LSTM(64,name='lstm_2')(lstm_1)\n","    drop_out_2 = Dropout(0.4,name='drop_out_2')(lstm_2)\n","\n","    # dense\n","    dense_1 = Dense(256,name='dense_1')(drop_out_2)\n","    dense_2 = Dense(128,name='dense_2')(dense_1)\n","    dense_3 = Dense(len(labels),activation='sigmoid',name='dense_3')(dense_1)\n","    out = Softmax(name='out')(dense_3) \n","    \n","    sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n","    model = Model(inputs=sentence, outputs=out, name='sentence_claccification')\n","    model.compile(optimizer=sgd, loss='binary_crossentropy', metrics=[\"accuracy\"]) \n","    return model\n","\n","\n","model = Net(vocab_size, embd_dim, sentence_maxlen,word2vec_embd_w)\n","print(model.summary())"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model: \"sentence_claccification\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","SentenceInput (InputLayer)   [(None, 300)]             0         \n","_________________________________________________________________\n","shared_embd (Embedding)      (None, 300, 300)          67603500  \n","_________________________________________________________________\n","lstm_1 (LSTM)                (None, 300, 128)          219648    \n","_________________________________________________________________\n","lstm_2 (LSTM)                (None, 64)                49408     \n","_________________________________________________________________\n","drop_out_2 (Dropout)         (None, 64)                0         \n","_________________________________________________________________\n","dense_1 (Dense)              (None, 256)               16640     \n","_________________________________________________________________\n","dense_3 (Dense)              (None, 78)                20046     \n","_________________________________________________________________\n","out (Softmax)                (None, 78)                0         \n","=================================================================\n","Total params: 67,909,242\n","Trainable params: 305,742\n","Non-trainable params: 67,603,500\n","_________________________________________________________________\n","None\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"YezCDpzv6b3P","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1608906396214,"user_tz":-210,"elapsed":15856440,"user":{"displayName":"zeinab taghavi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GheNU3ejtJBEFfDC_0W_JdLEuwkW7SKnnDuH80MRA=s64","userId":"07214630829740929140"}},"outputId":"22a825e1-e166-4c1b-9773-54a9aeb29345"},"source":["es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=5) # Model stop training after 50 epoch where validation loss didnt decrease\n","mc = ModelCheckpoint('best_cnn_4fc.h5', monitor='val_loss', mode='min', verbose=1, save_best_only=True) #You save model weight at the epoch where validation loss is minimal\n","model.fit(X_train, y_train, batch_size=32,epochs=50,verbose=1,validation_data=(X_val, y_val),callbacks=[es,mc])#you can run for 1000 epoch btw model will stop after 50 epoch without better validation loss"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/50\n","405/405 [==============================] - 308s 752ms/step - loss: 0.1133 - accuracy: 0.0169 - val_loss: 0.1169 - val_accuracy: 0.0213\n","\n","Epoch 00001: val_loss improved from inf to 0.11694, saving model to best_cnn_4fc.h5\n","Epoch 2/50\n","405/405 [==============================] - 306s 756ms/step - loss: 0.1118 - accuracy: 0.0244 - val_loss: 0.1169 - val_accuracy: 0.0223\n","\n","Epoch 00002: val_loss improved from 0.11694 to 0.11692, saving model to best_cnn_4fc.h5\n","Epoch 3/50\n","405/405 [==============================] - 310s 766ms/step - loss: 0.1120 - accuracy: 0.0252 - val_loss: 0.1169 - val_accuracy: 0.0264\n","\n","Epoch 00003: val_loss improved from 0.11692 to 0.11690, saving model to best_cnn_4fc.h5\n","Epoch 4/50\n","405/405 [==============================] - 310s 765ms/step - loss: 0.1145 - accuracy: 0.0217 - val_loss: 0.1169 - val_accuracy: 0.0278\n","\n","Epoch 00004: val_loss improved from 0.11690 to 0.11688, saving model to best_cnn_4fc.h5\n","Epoch 5/50\n","405/405 [==============================] - 312s 771ms/step - loss: 0.1119 - accuracy: 0.0252 - val_loss: 0.1169 - val_accuracy: 0.0278\n","\n","Epoch 00005: val_loss improved from 0.11688 to 0.11685, saving model to best_cnn_4fc.h5\n","Epoch 6/50\n","405/405 [==============================] - 314s 776ms/step - loss: 0.1116 - accuracy: 0.0251 - val_loss: 0.1168 - val_accuracy: 0.0278\n","\n","Epoch 00006: val_loss improved from 0.11685 to 0.11683, saving model to best_cnn_4fc.h5\n","Epoch 7/50\n","405/405 [==============================] - 308s 762ms/step - loss: 0.1127 - accuracy: 0.0286 - val_loss: 0.1168 - val_accuracy: 0.0271\n","\n","Epoch 00007: val_loss improved from 0.11683 to 0.11681, saving model to best_cnn_4fc.h5\n","Epoch 8/50\n","405/405 [==============================] - 312s 771ms/step - loss: 0.1120 - accuracy: 0.0253 - val_loss: 0.1168 - val_accuracy: 0.0257\n","\n","Epoch 00008: val_loss improved from 0.11681 to 0.11679, saving model to best_cnn_4fc.h5\n","Epoch 9/50\n","405/405 [==============================] - 310s 766ms/step - loss: 0.1141 - accuracy: 0.0278 - val_loss: 0.1168 - val_accuracy: 0.0262\n","\n","Epoch 00009: val_loss improved from 0.11679 to 0.11676, saving model to best_cnn_4fc.h5\n","Epoch 10/50\n","405/405 [==============================] - 312s 770ms/step - loss: 0.1104 - accuracy: 0.0276 - val_loss: 0.1167 - val_accuracy: 0.0264\n","\n","Epoch 00010: val_loss improved from 0.11676 to 0.11674, saving model to best_cnn_4fc.h5\n","Epoch 11/50\n","405/405 [==============================] - 313s 774ms/step - loss: 0.1117 - accuracy: 0.0262 - val_loss: 0.1167 - val_accuracy: 0.0262\n","\n","Epoch 00011: val_loss improved from 0.11674 to 0.11671, saving model to best_cnn_4fc.h5\n","Epoch 12/50\n","405/405 [==============================] - 314s 776ms/step - loss: 0.1124 - accuracy: 0.0248 - val_loss: 0.1167 - val_accuracy: 0.0271\n","\n","Epoch 00012: val_loss improved from 0.11671 to 0.11668, saving model to best_cnn_4fc.h5\n","Epoch 13/50\n","405/405 [==============================] - 310s 766ms/step - loss: 0.1118 - accuracy: 0.0268 - val_loss: 0.1167 - val_accuracy: 0.0269\n","\n","Epoch 00013: val_loss improved from 0.11668 to 0.11666, saving model to best_cnn_4fc.h5\n","Epoch 14/50\n","405/405 [==============================] - 314s 777ms/step - loss: 0.1123 - accuracy: 0.0262 - val_loss: 0.1166 - val_accuracy: 0.0271\n","\n","Epoch 00014: val_loss improved from 0.11666 to 0.11663, saving model to best_cnn_4fc.h5\n","Epoch 15/50\n","405/405 [==============================] - 313s 772ms/step - loss: 0.1112 - accuracy: 0.0276 - val_loss: 0.1166 - val_accuracy: 0.0269\n","\n","Epoch 00015: val_loss improved from 0.11663 to 0.11659, saving model to best_cnn_4fc.h5\n","Epoch 16/50\n","405/405 [==============================] - 313s 774ms/step - loss: 0.1132 - accuracy: 0.0277 - val_loss: 0.1166 - val_accuracy: 0.0271\n","\n","Epoch 00016: val_loss improved from 0.11659 to 0.11656, saving model to best_cnn_4fc.h5\n","Epoch 17/50\n","405/405 [==============================] - 318s 786ms/step - loss: 0.1118 - accuracy: 0.0278 - val_loss: 0.1165 - val_accuracy: 0.0271\n","\n","Epoch 00017: val_loss improved from 0.11656 to 0.11652, saving model to best_cnn_4fc.h5\n","Epoch 18/50\n","405/405 [==============================] - 316s 781ms/step - loss: 0.1125 - accuracy: 0.0267 - val_loss: 0.1165 - val_accuracy: 0.0271\n","\n","Epoch 00018: val_loss improved from 0.11652 to 0.11649, saving model to best_cnn_4fc.h5\n","Epoch 19/50\n","405/405 [==============================] - 315s 777ms/step - loss: 0.1127 - accuracy: 0.0273 - val_loss: 0.1164 - val_accuracy: 0.0271\n","\n","Epoch 00019: val_loss improved from 0.11649 to 0.11644, saving model to best_cnn_4fc.h5\n","Epoch 20/50\n","405/405 [==============================] - 317s 782ms/step - loss: 0.1120 - accuracy: 0.0246 - val_loss: 0.1164 - val_accuracy: 0.0271\n","\n","Epoch 00020: val_loss improved from 0.11644 to 0.11640, saving model to best_cnn_4fc.h5\n","Epoch 21/50\n","405/405 [==============================] - 316s 782ms/step - loss: 0.1130 - accuracy: 0.0263 - val_loss: 0.1164 - val_accuracy: 0.0271\n","\n","Epoch 00021: val_loss improved from 0.11640 to 0.11635, saving model to best_cnn_4fc.h5\n","Epoch 22/50\n","405/405 [==============================] - 317s 782ms/step - loss: 0.1135 - accuracy: 0.0252 - val_loss: 0.1163 - val_accuracy: 0.0271\n","\n","Epoch 00022: val_loss improved from 0.11635 to 0.11630, saving model to best_cnn_4fc.h5\n","Epoch 23/50\n","405/405 [==============================] - 317s 782ms/step - loss: 0.1108 - accuracy: 0.0272 - val_loss: 0.1162 - val_accuracy: 0.0271\n","\n","Epoch 00023: val_loss improved from 0.11630 to 0.11625, saving model to best_cnn_4fc.h5\n","Epoch 24/50\n","405/405 [==============================] - 313s 773ms/step - loss: 0.1121 - accuracy: 0.0274 - val_loss: 0.1162 - val_accuracy: 0.0267\n","\n","Epoch 00024: val_loss improved from 0.11625 to 0.11619, saving model to best_cnn_4fc.h5\n","Epoch 25/50\n","405/405 [==============================] - 310s 765ms/step - loss: 0.1134 - accuracy: 0.0259 - val_loss: 0.1161 - val_accuracy: 0.0267\n","\n","Epoch 00025: val_loss improved from 0.11619 to 0.11613, saving model to best_cnn_4fc.h5\n","Epoch 26/50\n","405/405 [==============================] - 315s 778ms/step - loss: 0.1115 - accuracy: 0.0277 - val_loss: 0.1161 - val_accuracy: 0.0264\n","\n","Epoch 00026: val_loss improved from 0.11613 to 0.11607, saving model to best_cnn_4fc.h5\n","Epoch 27/50\n","405/405 [==============================] - 314s 776ms/step - loss: 0.1135 - accuracy: 0.0269 - val_loss: 0.1160 - val_accuracy: 0.0264\n","\n","Epoch 00027: val_loss improved from 0.11607 to 0.11601, saving model to best_cnn_4fc.h5\n","Epoch 28/50\n","405/405 [==============================] - 316s 781ms/step - loss: 0.1110 - accuracy: 0.0249 - val_loss: 0.1159 - val_accuracy: 0.0264\n","\n","Epoch 00028: val_loss improved from 0.11601 to 0.11594, saving model to best_cnn_4fc.h5\n","Epoch 29/50\n","405/405 [==============================] - 315s 778ms/step - loss: 0.1115 - accuracy: 0.0274 - val_loss: 0.1159 - val_accuracy: 0.0264\n","\n","Epoch 00029: val_loss improved from 0.11594 to 0.11587, saving model to best_cnn_4fc.h5\n","Epoch 30/50\n","405/405 [==============================] - 315s 779ms/step - loss: 0.1130 - accuracy: 0.0262 - val_loss: 0.1158 - val_accuracy: 0.0264\n","\n","Epoch 00030: val_loss improved from 0.11587 to 0.11580, saving model to best_cnn_4fc.h5\n","Epoch 31/50\n","405/405 [==============================] - 313s 773ms/step - loss: 0.1132 - accuracy: 0.0273 - val_loss: 0.1157 - val_accuracy: 0.0283\n","\n","Epoch 00031: val_loss improved from 0.11580 to 0.11573, saving model to best_cnn_4fc.h5\n","Epoch 32/50\n","405/405 [==============================] - 316s 781ms/step - loss: 0.1127 - accuracy: 0.0272 - val_loss: 0.1157 - val_accuracy: 0.0369\n","\n","Epoch 00032: val_loss improved from 0.11573 to 0.11566, saving model to best_cnn_4fc.h5\n","Epoch 33/50\n","405/405 [==============================] - 314s 774ms/step - loss: 0.1131 - accuracy: 0.0266 - val_loss: 0.1156 - val_accuracy: 0.0359\n","\n","Epoch 00033: val_loss improved from 0.11566 to 0.11558, saving model to best_cnn_4fc.h5\n","Epoch 34/50\n","405/405 [==============================] - 313s 773ms/step - loss: 0.1113 - accuracy: 0.0269 - val_loss: 0.1155 - val_accuracy: 0.0364\n","\n","Epoch 00034: val_loss improved from 0.11558 to 0.11551, saving model to best_cnn_4fc.h5\n","Epoch 35/50\n","405/405 [==============================] - 314s 776ms/step - loss: 0.1117 - accuracy: 0.0267 - val_loss: 0.1154 - val_accuracy: 0.0362\n","\n","Epoch 00035: val_loss improved from 0.11551 to 0.11543, saving model to best_cnn_4fc.h5\n","Epoch 36/50\n","405/405 [==============================] - 316s 780ms/step - loss: 0.1103 - accuracy: 0.0282 - val_loss: 0.1154 - val_accuracy: 0.0362\n","\n","Epoch 00036: val_loss improved from 0.11543 to 0.11536, saving model to best_cnn_4fc.h5\n","Epoch 37/50\n","405/405 [==============================] - 314s 776ms/step - loss: 0.1111 - accuracy: 0.0279 - val_loss: 0.1153 - val_accuracy: 0.0359\n","\n","Epoch 00037: val_loss improved from 0.11536 to 0.11529, saving model to best_cnn_4fc.h5\n","Epoch 38/50\n","405/405 [==============================] - 317s 781ms/step - loss: 0.1111 - accuracy: 0.0258 - val_loss: 0.1152 - val_accuracy: 0.0359\n","\n","Epoch 00038: val_loss improved from 0.11529 to 0.11522, saving model to best_cnn_4fc.h5\n","Epoch 39/50\n","405/405 [==============================] - 316s 780ms/step - loss: 0.1110 - accuracy: 0.0253 - val_loss: 0.1151 - val_accuracy: 0.0359\n","\n","Epoch 00039: val_loss improved from 0.11522 to 0.11515, saving model to best_cnn_4fc.h5\n","Epoch 40/50\n","405/405 [==============================] - 324s 801ms/step - loss: 0.1101 - accuracy: 0.0271 - val_loss: 0.1151 - val_accuracy: 0.0359\n","\n","Epoch 00040: val_loss improved from 0.11515 to 0.11508, saving model to best_cnn_4fc.h5\n","Epoch 41/50\n","405/405 [==============================] - 318s 785ms/step - loss: 0.1124 - accuracy: 0.0269 - val_loss: 0.1150 - val_accuracy: 0.0359\n","\n","Epoch 00041: val_loss improved from 0.11508 to 0.11501, saving model to best_cnn_4fc.h5\n","Epoch 42/50\n","405/405 [==============================] - 318s 785ms/step - loss: 0.1103 - accuracy: 0.0304 - val_loss: 0.1149 - val_accuracy: 0.0359\n","\n","Epoch 00042: val_loss improved from 0.11501 to 0.11495, saving model to best_cnn_4fc.h5\n","Epoch 43/50\n","405/405 [==============================] - 319s 788ms/step - loss: 0.1107 - accuracy: 0.0266 - val_loss: 0.1149 - val_accuracy: 0.0359\n","\n","Epoch 00043: val_loss improved from 0.11495 to 0.11488, saving model to best_cnn_4fc.h5\n","Epoch 44/50\n","405/405 [==============================] - 318s 785ms/step - loss: 0.1102 - accuracy: 0.0254 - val_loss: 0.1148 - val_accuracy: 0.0359\n","\n","Epoch 00044: val_loss improved from 0.11488 to 0.11482, saving model to best_cnn_4fc.h5\n","Epoch 45/50\n","405/405 [==============================] - 318s 785ms/step - loss: 0.1117 - accuracy: 0.0287 - val_loss: 0.1148 - val_accuracy: 0.0359\n","\n","Epoch 00045: val_loss improved from 0.11482 to 0.11475, saving model to best_cnn_4fc.h5\n","Epoch 46/50\n","405/405 [==============================] - 318s 786ms/step - loss: 0.1113 - accuracy: 0.0247 - val_loss: 0.1147 - val_accuracy: 0.0359\n","\n","Epoch 00046: val_loss improved from 0.11475 to 0.11469, saving model to best_cnn_4fc.h5\n","Epoch 47/50\n","405/405 [==============================] - 316s 781ms/step - loss: 0.1112 - accuracy: 0.0289 - val_loss: 0.1146 - val_accuracy: 0.0359\n","\n","Epoch 00047: val_loss improved from 0.11469 to 0.11462, saving model to best_cnn_4fc.h5\n","Epoch 48/50\n","405/405 [==============================] - 315s 778ms/step - loss: 0.1092 - accuracy: 0.0286 - val_loss: 0.1146 - val_accuracy: 0.0357\n","\n","Epoch 00048: val_loss improved from 0.11462 to 0.11456, saving model to best_cnn_4fc.h5\n","Epoch 49/50\n","405/405 [==============================] - 319s 788ms/step - loss: 0.1117 - accuracy: 0.0257 - val_loss: 0.1145 - val_accuracy: 0.0355\n","\n","Epoch 00049: val_loss improved from 0.11456 to 0.11450, saving model to best_cnn_4fc.h5\n","Epoch 50/50\n","405/405 [==============================] - 315s 779ms/step - loss: 0.1113 - accuracy: 0.0235 - val_loss: 0.1144 - val_accuracy: 0.0355\n","\n","Epoch 00050: val_loss improved from 0.11450 to 0.11444, saving model to best_cnn_4fc.h5\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x7fdbadecc5c0>"]},"metadata":{"tags":[]},"execution_count":45}]},{"cell_type":"markdown","metadata":{"id":"7C6dJiECFMxL"},"source":["# ***If the model is generated before:***"]},{"cell_type":"code","metadata":{"id":"t5WEbk54E8qi","executionInfo":{"status":"ok","timestamp":1608954027997,"user_tz":-210,"elapsed":5380,"user":{"displayName":"zeinab taghavi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GheNU3ejtJBEFfDC_0W_JdLEuwkW7SKnnDuH80MRA=s64","userId":"07214630829740929140"}}},"source":["model = load_model('Lstm_3_just_accuracy.h5')\n","# model.save('Lstm_3_just_accuracy.h5')"],"execution_count":16,"outputs":[]},{"cell_type":"code","metadata":{"id":"sOSZspuCZuiI","executionInfo":{"status":"ok","timestamp":1608954049498,"user_tz":-210,"elapsed":26878,"user":{"displayName":"zeinab taghavi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GheNU3ejtJBEFfDC_0W_JdLEuwkW7SKnnDuH80MRA=s64","userId":"07214630829740929140"}}},"source":["pred=model.predict(X_test)\r\n","# For evaluation: If the probability > 0.5 you can say that it belong to the class."],"execution_count":17,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AF9qHTbECgVA","executionInfo":{"status":"ok","timestamp":1608954049500,"user_tz":-210,"elapsed":26875,"user":{"displayName":"zeinab taghavi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GheNU3ejtJBEFfDC_0W_JdLEuwkW7SKnnDuH80MRA=s64","userId":"07214630829740929140"}},"outputId":"f4bf355f-3b33-493d-9cbb-3c3baba993af"},"source":["print(pred[0])#example"],"execution_count":18,"outputs":[{"output_type":"stream","text":["[0.01452335 0.01598062 0.01668891 0.00816385 0.00879594 0.00781629\n"," 0.01716331 0.00862093 0.00828637 0.01350479 0.01709841 0.00971079\n"," 0.01524494 0.00811072 0.00793961 0.01610098 0.0123339  0.01652976\n"," 0.0132545  0.0097207  0.01374433 0.01548942 0.00877267 0.01651628\n"," 0.01084339 0.01815191 0.01612981 0.01727338 0.01447666 0.01596189\n"," 0.00964683 0.01132933 0.01538491 0.01666639 0.01175464 0.01710004\n"," 0.01527705 0.0101454  0.00815263 0.00834053 0.0166777  0.01195076\n"," 0.01005019 0.01644499 0.01784715 0.00797466 0.00817356 0.01583368\n"," 0.01560309 0.00985477 0.00808483 0.0082297  0.0089913  0.01151126\n"," 0.01495847 0.00834521 0.00902286 0.00930542 0.01595257 0.01638179\n"," 0.01652593 0.00874774 0.01590862 0.01652034 0.01062724 0.01764767\n"," 0.00889372 0.01239979 0.01647253 0.0163764  0.01558    0.01693973\n"," 0.01452838 0.00845623 0.00806998 0.01599721 0.00897282 0.01339554]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"_2P1QlQgCHfx","executionInfo":{"status":"ok","timestamp":1608954182305,"user_tz":-210,"elapsed":15747,"user":{"displayName":"zeinab taghavi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GheNU3ejtJBEFfDC_0W_JdLEuwkW7SKnnDuH80MRA=s64","userId":"07214630829740929140"}}},"source":["y_pred=[]\r\n","for l in pred:\r\n","  temp=[]\r\n","  for value in l:\r\n","    if value>=np.mean(pred[0]) + .5*np.sqrt(np.var(pred[0])):\r\n","      temp.append(1)\r\n","    else:\r\n","      temp.append(0)\r\n","  y_pred.append(temp)"],"execution_count":25,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZN9giZkICMRq","executionInfo":{"status":"ok","timestamp":1608954208317,"user_tz":-210,"elapsed":1211,"user":{"displayName":"zeinab taghavi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GheNU3ejtJBEFfDC_0W_JdLEuwkW7SKnnDuH80MRA=s64","userId":"07214630829740929140"}},"outputId":"025123b7-5d02-44d2-a8cf-04043a1fb927"},"source":["from sklearn.metrics import classification_report,accuracy_score\r\n","\r\n","print(\"accuracy=\",accuracy_score(y_test, y_pred))\r\n","print(classification_report(y_test, y_pred))"],"execution_count":27,"outputs":[{"output_type":"stream","text":["accuracy= 0.0\n","              precision    recall  f1-score   support\n","\n","           0       0.03      0.04      0.03       115\n","           1       0.04      1.00      0.08       177\n","           2       0.04      0.98      0.08       173\n","           3       0.00      0.00      0.00        20\n","           4       0.00      0.00      0.00        75\n","           5       0.00      0.00      0.00        13\n","           6       0.05      0.99      0.09       189\n","           7       0.00      0.00      0.00        38\n","           8       0.00      0.00      0.00        27\n","           9       0.00      0.00      0.00       124\n","          10       0.03      0.99      0.06       139\n","          11       0.00      0.00      0.00        66\n","          12       0.03      1.00      0.07       138\n","          13       0.00      0.00      0.00        20\n","          14       0.00      0.00      0.00        18\n","          15       0.04      0.96      0.07       156\n","          16       0.00      0.00      0.00       121\n","          17       0.04      1.00      0.07       159\n","          18       0.00      0.00      0.00       112\n","          19       0.00      0.00      0.00        77\n","          20       0.00      0.00      0.00       134\n","          21       0.03      0.97      0.06       130\n","          22       0.00      0.00      0.00        41\n","          23       0.03      0.89      0.06       136\n","          24       0.00      0.00      0.00        83\n","          25       0.03      0.99      0.07       142\n","          26       0.03      1.00      0.06       125\n","          27       0.03      0.99      0.06       136\n","          28       0.02      0.02      0.02       122\n","          29       0.03      0.96      0.06       140\n","          30       0.00      0.00      0.00        57\n","          31       0.00      0.00      0.00        89\n","          32       0.03      0.89      0.05       117\n","          33       0.04      1.00      0.08       165\n","          34       0.00      0.00      0.00        84\n","          35       0.03      0.99      0.07       142\n","          36       0.04      0.92      0.07       163\n","          37       0.00      0.00      0.00        70\n","          38       0.00      0.00      0.00        46\n","          39       0.00      0.00      0.00        26\n","          40       0.04      0.99      0.07       156\n","          41       0.00      0.00      0.00       125\n","          42       0.00      0.00      0.00        80\n","          43       0.03      0.97      0.07       146\n","          44       0.03      0.99      0.07       145\n","          45       0.00      0.00      0.00        23\n","          46       0.00      0.00      0.00        29\n","          47       0.04      0.98      0.07       150\n","          48       0.04      1.00      0.07       145\n","          49       0.00      0.00      0.00        56\n","          50       0.00      0.00      0.00        26\n","          51       0.00      0.00      0.00        28\n","          52       0.00      0.00      0.00        32\n","          53       0.00      0.00      0.00       107\n","          54       0.03      0.96      0.06       132\n","          55       0.00      0.00      0.00        32\n","          56       0.00      0.00      0.00        57\n","          57       0.00      0.00      0.00        55\n","          58       0.04      0.99      0.07       149\n","          59       0.04      0.92      0.07       160\n","          60       0.03      0.97      0.06       140\n","          61       0.00      0.00      0.00        58\n","          62       0.04      1.00      0.08       167\n","          63       0.03      0.98      0.06       130\n","          64       0.00      0.00      0.00        88\n","          65       0.03      0.95      0.06       134\n","          66       0.00      0.00      0.00        31\n","          67       0.00      0.00      0.00       115\n","          68       0.03      0.99      0.06       134\n","          69       0.04      1.00      0.08       180\n","          70       0.03      0.78      0.05       134\n","          71       0.04      1.00      0.07       153\n","          72       0.06      0.03      0.04       123\n","          73       0.00      0.00      0.00        47\n","          74       0.00      0.00      0.00        30\n","          75       0.03      0.90      0.06       154\n","          76       0.00      0.00      0.00        73\n","          77       0.00      0.00      0.00       133\n","\n","   micro avg       0.03      0.61      0.07      7962\n","   macro avg       0.02      0.42      0.03      7962\n","weighted avg       0.02      0.61      0.04      7962\n"," samples avg       0.03      0.63      0.06      7962\n","\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"qlVhFuBe1RXM"},"source":[""],"execution_count":null,"outputs":[]}]}