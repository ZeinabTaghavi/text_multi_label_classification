{"cells":[{"cell_type":"markdown","metadata":{"id":"j1LTPn7IjqTz"},"source":["Source:\r\n","\r\n","huggingface: https://huggingface.co/HooshvareLab/bert-fa-base-uncased-clf-persiannews\r\n","\r\n","Tutorial:https://towardsdatascience.com/fine-tuning-hugging-face-model-with-custom-dataset-82b8092f5333"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":65428,"status":"ok","timestamp":1610947210796,"user":{"displayName":"zeinab taghavi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GheNU3ejtJBEFfDC_0W_JdLEuwkW7SKnnDuH80MRA=s64","userId":"07214630829740929140"},"user_tz":-210},"id":"OmPFvCbSqyZF","outputId":"b14d622e-c9d3-44f4-f5c7-e7bd09bdea6e"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\r\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":3417,"status":"ok","timestamp":1610947214227,"user":{"displayName":"zeinab taghavi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GheNU3ejtJBEFfDC_0W_JdLEuwkW7SKnnDuH80MRA=s64","userId":"07214630829740929140"},"user_tz":-210},"id":"iRxC0Pz1qzKc"},"outputs":[],"source":["import os\r\n","os.chdir('/content/drive/MyDrive/sharif/FineTuning/ipython(guide)')"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9343,"status":"ok","timestamp":1610947220157,"user":{"displayName":"zeinab taghavi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GheNU3ejtJBEFfDC_0W_JdLEuwkW7SKnnDuH80MRA=s64","userId":"07214630829740929140"},"user_tz":-210},"id":"mCRkKc3NcgkX","outputId":"550ab853-d89a-4e8a-d61c-f5f91c7d4c3b"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting transformers\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/cd/40/866cbfac4601e0f74c7303d533a9c5d4a53858bd402e08e3e294dd271f25/transformers-4.2.1-py3-none-any.whl (1.8MB)\n","\u001b[K     |████████████████████████████████| 1.8MB 16.4MB/s \n","\u001b[?25hRequirement already satisfied: importlib-metadata; python_version \u003c \"3.8\" in /usr/local/lib/python3.6/dist-packages (from transformers) (3.3.0)\n","Collecting sacremoses\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n","\u001b[K     |████████████████████████████████| 890kB 53.5MB/s \n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n","Collecting tokenizers==0.9.4\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0f/1c/e789a8b12e28be5bc1ce2156cf87cb522b379be9cadc7ad8091a4cc107c4/tokenizers-0.9.4-cp36-cp36m-manylinux2010_x86_64.whl (2.9MB)\n","\u001b[K     |████████████████████████████████| 2.9MB 50.2MB/s \n","\u001b[?25hRequirement already satisfied: tqdm\u003e=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n","Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.8)\n","Requirement already satisfied: dataclasses; python_version \u003c \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.8)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.19.5)\n","Requirement already satisfied: typing-extensions\u003e=3.6.4; python_version \u003c \"3.8\" in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version \u003c \"3.8\"-\u003etransformers) (3.7.4.3)\n","Requirement already satisfied: zipp\u003e=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version \u003c \"3.8\"-\u003etransformers) (3.4.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses-\u003etransformers) (1.15.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses-\u003etransformers) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses-\u003etransformers) (1.0.0)\n","Requirement already satisfied: idna\u003c3,\u003e=2.5 in /usr/local/lib/python3.6/dist-packages (from requests-\u003etransformers) (2.10)\n","Requirement already satisfied: chardet\u003c4,\u003e=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests-\u003etransformers) (3.0.4)\n","Requirement already satisfied: certifi\u003e=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests-\u003etransformers) (2020.12.5)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,\u003c1.26,\u003e=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests-\u003etransformers) (1.24.3)\n","Requirement already satisfied: pyparsing\u003e=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging-\u003etransformers) (2.4.7)\n","Building wheels for collected packages: sacremoses\n","  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893261 sha256=921497e02e1706f85f31e93e63a0a50bb69644ce9cf85c252f139f7817923b3d\n","  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n","Successfully built sacremoses\n","Installing collected packages: sacremoses, tokenizers, transformers\n","Successfully installed sacremoses-0.0.43 tokenizers-0.9.4 transformers-4.2.1\n"]}],"source":["!pip install transformers"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12752,"status":"ok","timestamp":1610947223569,"user":{"displayName":"zeinab taghavi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GheNU3ejtJBEFfDC_0W_JdLEuwkW7SKnnDuH80MRA=s64","userId":"07214630829740929140"},"user_tz":-210},"id":"ODc44DglgNjZ","outputId":"ddbba0ac-8fbe-4a9d-f9bd-ce9ce36c8336"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting sentencepiece\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/14/67/e42bd1181472c95c8cda79305df848264f2a7f62740995a46945d9797b67/sentencepiece-0.1.95-cp36-cp36m-manylinux2014_x86_64.whl (1.2MB)\n","\r\u001b[K     |▎                               | 10kB 21.3MB/s eta 0:00:01\r\u001b[K     |▌                               | 20kB 28.0MB/s eta 0:00:01\r\u001b[K     |▉                               | 30kB 24.5MB/s eta 0:00:01\r\u001b[K     |█                               | 40kB 21.6MB/s eta 0:00:01\r\u001b[K     |█▍                              | 51kB 22.2MB/s eta 0:00:01\r\u001b[K     |█▋                              | 61kB 15.7MB/s eta 0:00:01\r\u001b[K     |██                              | 71kB 16.1MB/s eta 0:00:01\r\u001b[K     |██▏                             | 81kB 15.4MB/s eta 0:00:01\r\u001b[K     |██▌                             | 92kB 15.3MB/s eta 0:00:01\r\u001b[K     |██▊                             | 102kB 15.7MB/s eta 0:00:01\r\u001b[K     |███                             | 112kB 15.7MB/s eta 0:00:01\r\u001b[K     |███▎                            | 122kB 15.7MB/s eta 0:00:01\r\u001b[K     |███▌                            | 133kB 15.7MB/s eta 0:00:01\r\u001b[K     |███▉                            | 143kB 15.7MB/s eta 0:00:01\r\u001b[K     |████                            | 153kB 15.7MB/s eta 0:00:01\r\u001b[K     |████▍                           | 163kB 15.7MB/s eta 0:00:01\r\u001b[K     |████▋                           | 174kB 15.7MB/s eta 0:00:01\r\u001b[K     |█████                           | 184kB 15.7MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 194kB 15.7MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 204kB 15.7MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 215kB 15.7MB/s eta 0:00:01\r\u001b[K     |██████                          | 225kB 15.7MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 235kB 15.7MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 245kB 15.7MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 256kB 15.7MB/s eta 0:00:01\r\u001b[K     |███████                         | 266kB 15.7MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 276kB 15.7MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 286kB 15.7MB/s eta 0:00:01\r\u001b[K     |████████                        | 296kB 15.7MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 307kB 15.7MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 317kB 15.7MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 327kB 15.7MB/s eta 0:00:01\r\u001b[K     |█████████                       | 337kB 15.7MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 348kB 15.7MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 358kB 15.7MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 368kB 15.7MB/s eta 0:00:01\r\u001b[K     |██████████                      | 378kB 15.7MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 389kB 15.7MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 399kB 15.7MB/s eta 0:00:01\r\u001b[K     |███████████                     | 409kB 15.7MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 419kB 15.7MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 430kB 15.7MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 440kB 15.7MB/s eta 0:00:01\r\u001b[K     |████████████                    | 450kB 15.7MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 460kB 15.7MB/s eta 0:00:01\r\u001b[K     |████████████▌                   | 471kB 15.7MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 481kB 15.7MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 491kB 15.7MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 501kB 15.7MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 512kB 15.7MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 522kB 15.7MB/s eta 0:00:01\r\u001b[K     |██████████████▏                 | 532kB 15.7MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 542kB 15.7MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 552kB 15.7MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 563kB 15.7MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 573kB 15.7MB/s eta 0:00:01\r\u001b[K     |███████████████▌                | 583kB 15.7MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 593kB 15.7MB/s eta 0:00:01\r\u001b[K     |████████████████                | 604kB 15.7MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 614kB 15.7MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 624kB 15.7MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 634kB 15.7MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 645kB 15.7MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 655kB 15.7MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 665kB 15.7MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 675kB 15.7MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 686kB 15.7MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 696kB 15.7MB/s eta 0:00:01\r\u001b[K     |██████████████████▉             | 706kB 15.7MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 716kB 15.7MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 727kB 15.7MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 737kB 15.7MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 747kB 15.7MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 757kB 15.7MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 768kB 15.7MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 778kB 15.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 788kB 15.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 798kB 15.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████▌          | 808kB 15.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 819kB 15.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 829kB 15.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 839kB 15.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 849kB 15.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 860kB 15.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 870kB 15.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 880kB 15.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 890kB 15.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 901kB 15.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 911kB 15.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 921kB 15.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 931kB 15.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 942kB 15.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▎      | 952kB 15.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 962kB 15.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 972kB 15.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 983kB 15.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 993kB 15.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 1.0MB 15.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 1.0MB 15.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 1.0MB 15.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 1.0MB 15.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 1.0MB 15.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 1.1MB 15.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▎   | 1.1MB 15.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 1.1MB 15.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 1.1MB 15.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 1.1MB 15.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 1.1MB 15.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 1.1MB 15.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 1.1MB 15.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▏ | 1.1MB 15.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 1.1MB 15.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 1.2MB 15.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 1.2MB 15.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 1.2MB 15.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 1.2MB 15.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 1.2MB 15.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.2MB 15.7MB/s \n","\u001b[?25hInstalling collected packages: sentencepiece\n","Successfully installed sentencepiece-0.1.95\n"]}],"source":["!pip3 install sentencepiece"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12752,"status":"ok","timestamp":1610947223571,"user":{"displayName":"zeinab taghavi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GheNU3ejtJBEFfDC_0W_JdLEuwkW7SKnnDuH80MRA=s64","userId":"07214630829740929140"},"user_tz":-210},"id":"qJY_L2p9a0t0","outputId":"892f1024-f552-49d4-dc69-416e47418de9"},"outputs":[{"name":"stdout","output_type":"stream","text":["fatal: destination path 'bert-fa-base-uncased-clf-persiannews' already exists and is not an empty directory.\n"]}],"source":["!git clone https://huggingface.co/HooshvareLab/bert-fa-base-uncased-clf-persiannews\r\n","GIT_LFS_SKIP_SMUDGE=1"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":18403,"status":"ok","timestamp":1610947229224,"user":{"displayName":"zeinab taghavi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GheNU3ejtJBEFfDC_0W_JdLEuwkW7SKnnDuH80MRA=s64","userId":"07214630829740929140"},"user_tz":-210},"id":"Eg3Up037nThu"},"outputs":[],"source":["import torch\r\n","import numpy\r\n","import pandas\r\n","import re\r\n","from sklearn.preprocessing import MultiLabelBinarizer\r\n","from sklearn.model_selection import train_test_split\r\n","from transformers import AutoTokenizer, AutoModelForSequenceClassification,AutoConfig,TFAutoModel,AutoModel\r\n","from transformers import BertConfig, BertTokenizer\r\n","from transformers import TFBertModel, TFBertForSequenceClassification\r\n","from transformers import glue_convert_examples_to_features, InputExample\r\n","from sklearn.metrics import classification_report\r\n","\r\n","Model_name = \"HooshvareLab/bert-fa-base-uncased\""]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":18404,"status":"ok","timestamp":1610947229227,"user":{"displayName":"zeinab taghavi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GheNU3ejtJBEFfDC_0W_JdLEuwkW7SKnnDuH80MRA=s64","userId":"07214630829740929140"},"user_tz":-210},"id":"2Ur9wv1ytrZu"},"outputs":[],"source":["# specify GPU\r\n","device = torch.device(\"cuda\")"]},{"cell_type":"markdown","metadata":{"id":"xax4bHubzpMp"},"source":["## Data"]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":20316,"status":"ok","timestamp":1610947231141,"user":{"displayName":"zeinab taghavi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GheNU3ejtJBEFfDC_0W_JdLEuwkW7SKnnDuH80MRA=s64","userId":"07214630829740929140"},"user_tz":-210},"id":"TJf6T40glV5g"},"outputs":[],"source":["limit_number = 750\r\n","data = pandas.read_csv('../Data/ParsBert_600.csv')\r\n","data = data.dropna().reset_index(drop=True)\r\n","X = data[\"body\"].values.tolist()\r\n","y = pandas.read_csv('../Data/ParsBert_600.csv')\r\n","labels = []\r\n","tag=[]\r\n","for item in y['tag']:\r\n","  labels += [i for i in re.sub('\\\"|\\[|\\]|\\'| |=','',item.lower()).split(\",\") if i!='' and i!=' ']\r\n","  tag.append([i for i in re.sub('\\\"|\\[|\\]|\\'| |=','',item.lower()).split(\",\") if i!='' and i!=' '])\r\n","labels = list(set(labels))\r\n","mlb = MultiLabelBinarizer()\r\n","Y=mlb.fit_transform(tag)"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":20315,"status":"ok","timestamp":1610947231142,"user":{"displayName":"zeinab taghavi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GheNU3ejtJBEFfDC_0W_JdLEuwkW7SKnnDuH80MRA=s64","userId":"07214630829740929140"},"user_tz":-210},"id":"Q6yIfBbUIc3i","outputId":"7f6ca867-a94b-4878-b2d7-ead752023283"},"outputs":[{"data":{"text/plain":["(78, 14215)"]},"execution_count":9,"metadata":{"tags":[]},"output_type":"execute_result"}],"source":["len(labels) , len(X)"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":282},"executionInfo":{"elapsed":21023,"status":"ok","timestamp":1610947231859,"user":{"displayName":"zeinab taghavi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GheNU3ejtJBEFfDC_0W_JdLEuwkW7SKnnDuH80MRA=s64","userId":"07214630829740929140"},"user_tz":-210},"id":"A59_7YPmnZgA","outputId":"73df5151-dcf3-4dad-9fa2-4c8cd8e4369f"},"outputs":[{"data":{"text/plain":["\u003cmatplotlib.axes._subplots.AxesSubplot at 0x7f73cece89e8\u003e"]},"execution_count":10,"metadata":{"tags":[]},"output_type":"execute_result"},{"data":{"image/png":"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\n","text/plain":["\u003cFigure size 432x288 with 1 Axes\u003e"]},"metadata":{"tags":[]},"output_type":"display_data"}],"source":["seq_len = [len(i.split()) for i in X]\n","pandas.Series(seq_len).hist(bins = 30)"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":282},"executionInfo":{"elapsed":20114,"status":"ok","timestamp":1610947234547,"user":{"displayName":"zeinab taghavi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GheNU3ejtJBEFfDC_0W_JdLEuwkW7SKnnDuH80MRA=s64","userId":"07214630829740929140"},"user_tz":-210},"id":"1JEmlyFMm6Tf","outputId":"de5d2afb-2396-40cf-cc32-f8f9aa366aa8"},"outputs":[{"data":{"text/plain":["\u003cmatplotlib.axes._subplots.AxesSubplot at 0x7f73ceaf03c8\u003e"]},"execution_count":11,"metadata":{"tags":[]},"output_type":"execute_result"},{"data":{"image/png":"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\n","text/plain":["\u003cFigure size 432x288 with 1 Axes\u003e"]},"metadata":{"tags":[]},"output_type":"display_data"}],"source":["seq_len = [len([j for j in i.split() if len(j)\u003e2]) for i in X]\n","pandas.Series(seq_len).hist(bins = 30)"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":19775,"status":"ok","timestamp":1610947234549,"user":{"displayName":"zeinab taghavi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GheNU3ejtJBEFfDC_0W_JdLEuwkW7SKnnDuH80MRA=s64","userId":"07214630829740929140"},"user_tz":-210},"id":"PH3jCKaZsEWo","outputId":"3de24f54-ee83-4864-88dd-d877a3b55634"},"outputs":[{"name":"stdout","output_type":"stream","text":["train:  8529 \n","test:  2843 \n","val:  2843 \n","y_tain: 8529\n"]}],"source":["X_train, X_test, y_train, y_test = train_test_split(X,Y , test_size=0.2)\r\n","X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25)\r\n","print('train: ', len(X_train) , '\\ntest: ', len(X_test) , '\\nval: ', len(X_val) ,\"\\ny_tain:\",len(y_train) )"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":115},"executionInfo":{"elapsed":20069,"status":"ok","timestamp":1610947235217,"user":{"displayName":"zeinab taghavi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GheNU3ejtJBEFfDC_0W_JdLEuwkW7SKnnDuH80MRA=s64","userId":"07214630829740929140"},"user_tz":-210},"id":"Vei6iu9atmyd","outputId":"4cf51f03-b4cf-471d-d1d3-9fce572bec6b"},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"902eeca565dd4b928b514541f0b197c6","version_major":2,"version_minor":0},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=440.0, style=ProgressStyle(description_…"]},"metadata":{"tags":[]},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"1445d803b7ae4691b4f896a920c28889","version_major":2,"version_minor":0},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1198122.0, style=ProgressStyle(descript…"]},"metadata":{"tags":[]},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\n"]}],"source":["##we would load the tokenizer\r\n","tokenizer = AutoTokenizer.from_pretrained(\"HooshvareLab/bert-fa-base-uncased\")"]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":15677,"status":"ok","timestamp":1610947235218,"user":{"displayName":"zeinab taghavi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GheNU3ejtJBEFfDC_0W_JdLEuwkW7SKnnDuH80MRA=s64","userId":"07214630829740929140"},"user_tz":-210},"id":"C7wdU0zejDNq","outputId":"faf61c1e-d683-4ded-c193-1f8beae85dc6"},"outputs":[{"name":"stdout","output_type":"stream","text":["['به', 'نام', 'خداب', '##ا', 'سلام', 'امروز', 'با', 'اموزش', 'افزونه', 'advanced', '-', 'vip', 'در', 'خدمت', 'شم', '##ت', 'هستم', 'توسط', 'این', 'افزونه', 'شما', 'قادر', 'خواهید', 'بود', 'بخش', 'اشتراک', 'ویژه', 'برای', 'کاربران', 'سایت', '##تون', 'ایجاد', 'کنید', 'افزونه', 'نسبتا', 'کامل', 'و', 'خوبی', 'هست', 'اما', 'یکسری', 'مشکلات', 'جزيی', 'هم', 'داره', 'که', 'با', 'داشتن', 'کمی', 'دانش', 'برنامه', 'نویسی', 'میتونید', 'اونها', 'رو', 'برطرف', 'کنید', 'اما', 'در', 'کل', 'در', 'بین', 'تمام', 'افزونههای', 'رایگانی', 'که', 'در', 'این', 'زمینه', 'وجود', 'داره', 'کاملترین', 'بحساب', 'میاد', '.', 'این', 'افزونه', 'در', '[UNK]', 'ورژن', 'توسط', 'اقای', 'وحید', 'محمدی', 'طراحی', 'و', 'نوشته', 'شده', 'که', 'از', 'لینک', 'زیر', 'میتونید', 'جدیدترین', 'ورژن', 'ان', 'را', 'دانلود', 'نمایید', 'و', 'جا', 'داره', 'در', 'اینجا', 'از', 'ایشان', 'بخاطر', 'انتشار', 'رایگان', 'این', 'افزونه', 'تشکر', 'کنیم', '.', 'امکانات', 'این', 'افزونه', 'به', 'شرح', 'زیر', 'میباشد', ':']\n","[2789, 2967, 19418, 2006, 4285, 3767, 2799, 3911, 23639, 39292, 1011, 34223, 2786, 4879, 3195, 2009, 6794, 3158, 2802, 23639, 3124, 5311, 5655, 2834, 3108, 6468, 4000, 2831, 4816, 4394, 4957, 3280, 3116, 23639, 6674, 3985, 1379, 3949, 2952, 2949, 13222, 3966, 5659, 2820, 11231, 2800, 2799, 4653, 3744, 3100, 3329, 12035, 21280, 14458, 2840, 7502, 3116, 2949, 2786, 3142, 2786, 3016, 3437, 44732, 48506, 2800, 2786, 2802, 3665, 3022, 11231, 21362, 30798, 19994, 1012, 2802, 23639, 2786, 1, 21001, 3158, 4033, 13575, 9468, 3841, 1379, 4196, 2871, 2800, 2791, 11827, 3150, 21280, 8089, 21001, 2808, 2803, 7510, 7173, 1379, 3796, 11231, 2786, 4938, 2791, 4460, 8481, 3986, 6552, 2802, 23639, 9093, 3592, 1012, 5524, 2802, 23639, 2789, 5597, 3150, 3388, 1014]\n"]}],"source":["#example\r\n","text = \"ما در هوشواره معتقدیم با انتقال صحیح دانش و آگاهی، همه افراد میتوانند از ابزارهای هوشمند استفاده کنند. شعار ما هوش مصنوعی برای همه است.\"\r\n","tokenized=tokenizer.tokenize(X_train[0])\r\n","input_ids = tokenizer.convert_tokens_to_ids(tokenized)\r\n","print(tokenized)\r\n","print(input_ids)\r\n"]},{"cell_type":"code","execution_count":15,"metadata":{"executionInfo":{"elapsed":14754,"status":"ok","timestamp":1610947235219,"user":{"displayName":"zeinab taghavi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GheNU3ejtJBEFfDC_0W_JdLEuwkW7SKnnDuH80MRA=s64","userId":"07214630829740929140"},"user_tz":-210},"id":"Az4rwU0l5ECn"},"outputs":[],"source":["# encode text\r\n","sent_id = tokenizer.batch_encode_plus(X_train[:10], padding=True, return_token_type_ids=False)"]},{"cell_type":"code","execution_count":16,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":14240,"status":"ok","timestamp":1610947235219,"user":{"displayName":"zeinab taghavi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GheNU3ejtJBEFfDC_0W_JdLEuwkW7SKnnDuH80MRA=s64","userId":"07214630829740929140"},"user_tz":-210},"id":"oNRU-SH65ZEE","outputId":"88780ee2-8ff9-4a81-8425-1e986720d014"},"outputs":[{"data":{"text/plain":["{'input_ids': [[2, 2789, 2967, 19418, 2006, 4285, 3767, 2799, 3911, 23639, 39292, 1011, 34223, 2786, 4879, 3195, 2009, 6794, 3158, 2802, 23639, 3124, 5311, 5655, 2834, 3108, 6468, 4000, 2831, 4816, 4394, 4957, 3280, 3116, 23639, 6674, 3985, 1379, 3949, 2952, 2949, 13222, 3966, 5659, 2820, 11231, 2800, 2799, 4653, 3744, 3100, 3329, 12035, 21280, 14458, 2840, 7502, 3116, 2949, 2786, 3142, 2786, 3016, 3437, 44732, 48506, 2800, 2786, 2802, 3665, 3022, 11231, 21362, 30798, 19994, 1012, 2802, 23639, 2786, 1, 21001, 3158, 4033, 13575, 9468, 3841, 1379, 4196, 2871, 2800, 2791, 11827, 3150, 21280, 8089, 21001, 2808, 2803, 7510, 7173, 1379, 3796, 11231, 2786, 4938, 2791, 4460, 8481, 3986, 6552, 2802, 23639, 9093, 3592, 1012, 5524, 2802, 23639, 2789, 5597, 3150, 3388, 1014, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [2, 2786, 2802, 6012, 2791, 38031, 4790, 4314, 2786, 3050, 3131, 7578, 2786, 3351, 5825, 1350, 3660, 2964, 3013, 2786, 3351, 7578, 3151, 4793, 1350, 3051, 10762, 3457, 3280, 7578, 2786, 3351, 2793, 3073, 4386, 3592, 1012, 7578, 2786, 3473, 4082, 2806, 2800, 3124, 2803, 10476, 2789, 3940, 2980, 1012, 3594, 2800, 6815, 2829, 3320, 2786, 15144, 3096, 4820, 3805, 3337, 2806, 2848, 9791, 3051, 4082, 2964, 2803, 10476, 2789, 21671, 2980, 1012, 2789, 4998, 3177, 3406, 7290, 2924, 1379, 11697, 2802, 3444, 2800, 7578, 5495, 5042, 2924, 3177, 4418, 2924, 1012, 2799, 11697, 2802, 3444, 6027, 2791, 18656, 3541, 2808, 2786, 3351, 2988, 3592, 1012, 5089, 2848, 2789, 3035, 1064, 36039, 1078, 2789, 32177, 7533, 2806, 1012, 3786, 4109, 5621, 5939, 3376, 9126, 1379, 4710, 2786, 3351, 2806, 1379, 3036, 2791, 17876, 2800, 2789, 3786, 4109, 5621, 3469, 2980, 4920, 2808, 2806, 2800, 3051, 4082, 2789, 3124, 2786, 3351, 7578, 3238, 1012, 2791, 7688, 2800, 3398, 2791, 3155, 4467, 4908, 3426, 3060, 1348, 2789, 12028, 2786, 3050, 3510, 3274, 7578, 4386, 2886, 1012, 8039, 3805, 20401, 2787, 1348, 3124, 8455, 2800, 2829, 3736, 4717, 1379, 2831, 4765, 2789, 2808, 45753, 2910, 2789, 2937, 3972, 7796, 1012, 5310, 2802, 8026, 5972, 2831, 4765, 2789, 5100, 3225, 1379, 3937, 2820, 6173, 3238, 2949, 3732, 3148, 3803, 3152, 1012, 3064, 3124, 32682, 2800, 8490, 7578, 2786, 15144, 2791, 13558, 1348, 5995, 2799, 2988, 2791, 4290, 9361, 1348, 5621, 2803, 2789, 28089, 3620, 4736, 1012, 9361, 4124, 2806, 2949, 3013, 6429, 2800, 9361, 2829, 5392, 8976, 11081, 3152, 1379, 2789, 3241, 3804, 2806, 2800, 4063, 2791, 3109, 3271, 3155, 19399, 19250, 5598, 2803, 2789, 3559, 14228, 1012, 3064, 6815, 3430, 2802, 3109, 5302, 3892, 2800, 16040, 2803, 6728, 3380, 1348, 2789, 4082, 3130, 2791, 9361, 3422, 4717, 1012, 4082, 3331, 2829, 3329, 4242, 1379, 11514, 2800, 3040, 5093, 9622, 3124, 7425, 2871, 2806, 1012, 2831, 6388, 3251, 5071, 11827, 4062, 2803, 7843, 63913, 22651, 2029, 1014, 43428, 1014, 1013, 1013, 66296, 2032, 1012, 11975, 1013, 38592, 1011, 17659, 51645, 98758, 1011, 20303, 1013, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [2, 2802, 5117, 3951, 3067, 4484, 1442, 10132, 7164, 1002, 8464, 6921, 1002, 3388, 1012, 2802, 4484, 2786, 2829, 5117, 1442, 8451, 6767, 2871, 1379, 2789, 3951, 6343, 7126, 4629, 2871, 2806, 1012, 2786, 3559, 2802, 3951, 6343, 7126, 6921, 6343, 2802, 4484, 2786, 4209, 3124, 2959, 3201, 3153, 1012, 3598, 3892, 2802, 5071, 2829, 5117, 2791, 3511, 3329, 12035, 10132, 7563, 2793, 3048, 1379, 2831, 4482, 2808, 3013, 2786, 3511, 4002, 2967, 3116, 1012, 4002, 2967, 2786, 3511, 3329, 12035, 10132, 7563, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [2, 2786, 2802, 5071, 17953, 2829, 28918, 1035, 64606, 2048, 8094, 1035, 64606, 2048, 1011, 21813, 9465, 2840, 4879, 3124, 3852, 5400, 1379, 26749, 3911, 19910, 1012, 2799, 2988, 2791, 2802, 28918, 58164, 4516, 49225, 2840, 10884, 5714, 3229, 3116, 1012, 58164, 2799, 2988, 2791, 7843, 21708, 1348, 5939, 39947, 8679, 21708, 1348, 15447, 3683, 1379, 4062, 46785, 1379, 3111, 2786, 12304, 2799, 2988, 2791, 30759, 4516, 2840, 3320, 5362, 1012, 8146, 2800, 58164, 2799, 2937, 4979, 2791, 5124, 3683, 4516, 2840, 3320, 5362, 1012, 4309, 3013, 2789, 4863, 6937, 2786, 4394, 72768, 45356, 2049, 21961, 1379, 11837, 3050, 3138, 2840, 7510, 3116, 1012, 2786, 2802, 5071, 2964, 2789, 1035, 64606, 2048, 1012, 16623, 1012, 50466, 1379, 1035, 64606, 2048, 1012, 21813, 9465, 1012, 16623, 1012, 50466, 3422, 4314, 1012, 2842, 2802, 17759, 2827, 2786, 7191, 2802, 5071, 2959, 10315, 1379, 58164, 2791, 17687, 2988, 3116, 1012, 4888, 4642, 6921, 8094, 37745, 1012, 23460, 17358, 1379, 13197, 3150, 2840, 33336, 2959, 5362, 1014, 8146, 2800, 2848, 4938, 11837, 3050, 3138, 2840, 3332, 5334, 1012, 3111, 13197, 23460, 1379, 46227, 3050, 3138, 2840, 43711, 1012, 3064, 2848, 4938, 2786, 6945, 6820, 1348, 2829, 49225, 4613, 8146, 2800, 3805, 5484, 21981, 1012, 2831, 3320, 4516, 5536, 1348, 3013, 4563, 5536, 13113, 3116, 1348, 3362, 2799, 2988, 2791, 2802, 4766, 11904, 58164, 3557, 13113, 3274, 4516, 2840, 3320, 5362, 1012, 2786, 4309, 3013, 2829, 49225, 2959, 5362, 1379, 5732, 47003, 2840, 2789, 5536, 3368, 5362, 1012, 10884, 3150, 1014, 4888, 2786, 17790, 43586, 5035, 3013, 4366, 3150, 2840, 2959, 5362, 1014, 8146, 2800, 2786, 4309, 49225, 2840, 3229, 5334, 1379, 3082, 2791, 5536, 18009, 21813, 9465, 2840, 2831, 5536, 15766, 4279, 1012, 3064, 2786, 6945, 6820, 1014, 4888, 3064, 26749, 3320, 5362, 1348, 11123, 2800, 2786, 7661, 3022, 11231, 3320, 12702, 1014, 3111, 58164, 3040, 5444, 3050, 3138, 7843, 3116, 1379, 5444, 2840, 3320, 5362, 1379, 24281, 7796, 1012, 3111, 58164, 3082, 2791, 7843, 2801, 3040, 5444, 1348, 2799, 2988, 2791, 15447, 3683, 1379, 4062, 26749, 26402, 5362, 1012, 10884, 3150, 1014, 2802, 18009, 5230, 3406, 11231, 2800, 2842, 5198, 2791, 4139, 3472, 2840, 2959, 10315, 1012, 10884, 3150, 1014, 4836, 2937, 4979, 1014, 2831, 4893, 3130, 58164, 2789, 2802, 11827, 5563, 3116, 1012, 9966, 48476, 2816, 36711, 12139, 1012, 3598, 3892, 1012, 2880, 3366, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [2, 5574, 11378, 2800, 2786, 4407, 3067, 3331, 18478, 20249, 15425, 2026, 1379, 5574, 7043, 6343, 4942, 2972, 2952, 3362, 12160, 2800, 2786, 2802, 5574, 7043, 3496, 4482, 2952, 1348, 5232, 6343, 3683, 2786, 5266, 4248, 9678, 1379, 2786, 2820, 33029, 2806, 1348, 3546, 4790, 6052, 2800, 2786, 2802, 5071, 3237, 2791, 13343, 4016, 2800, 10672, 2799, 2802, 5574, 7043, 4242, 2830, 2840, 2789, 3124, 22367, 19910, 1012, 4909, 5289, 2800, 3013, 16604, 3211, 2830, 9225, 2800, 2802, 5574, 7043, 5232, 3043, 11837, 4461, 2840, 20516, 1379, 3124, 3013, 2802, 6921, 52394, 4788, 3116, 3649, 6921, 6343, 7317, 3331, 65847, 1010, 1012, 1012, 1012, 2840, 4788, 3116, 1012, 3546, 11748, 4175, 2786, 4166, 4207, 2802, 5574, 7043, 6335, 2871, 2800, 4360, 2842, 9225, 2800, 4175, 5929, 2840, 2820, 2789, 3080, 4655, 65847, 22914, 9405, 1379, 95425, 2962, 2988, 3116, 1012, 2789, 3897, 4183, 13343, 3150, 2799, 5574, 7043, 10826, 25400, 15180, 38174, 32088, 4242, 2871, 1379, 2786, 4407, 3067, 20867, 9977, 13637, 12139, 1012, 43428, 1014, 1013, 1013, 37643, 1012, 48654, 86407, 1012, 8596, 1013, 62705, 5806, 1013, 1, 4242, 3274, 2802, 13343, 2840, 2786, 15267, 3082, 2793, 5508, 3362, 3736, 2842, 2791, 2802, 4196, 2802, 2834, 2800, 18757, 2793, 14760, 2013, 16158, 4016, 2840, 4242, 3116, 2800, 7440, 2789, 5574, 48567, 2799, 4735, 3683, 20516, 1012, 3124, 2820, 2793, 14760, 2013, 4642, 13343, 2799, 2802, 5574, 7043, 17358, 1350, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [2, 2958, 4373, 8408, 2800, 20793, 6052, 26283, 2848, 69017, 2800, 10597, 10652, 3650, 3083, 70096, 2011, 1379, 12724, 2011, 1379, 2789, 6379, 61039, 1012, 1011, 52749, 6343, 21295, 1011, 11827, 8126, 13185, 4175, 5929, 1006, 2786, 3080, 4884, 20633, 2816, 2791, 3583, 2791, 2964, 4109, 2816, 1007, 1011, 39817, 13343, 6343, 2800, 31487, 33670, 60485, 19910, 1011, 2802, 52635, 2800, 84506, 2015, 2840, 2786, 5094, 4059, 18757, 21295, 10672, 1012, 1011, 2937, 3675, 2800, 2793, 19328, 21659, 17521, 36044, 14114, 1348, 4197, 3035, 22673, 3633, 5899, 3035, 1379, 15868, 9341, 1379, 5527, 2840, 9250, 1012, 3546, 4175, 4938, 2840, 2892, 2847, 36044, 48449, 17521, 8126, 13185, 3928, 44402, 2787, 3791, 1012, 1011, 4059, 3376, 2892, 4449, 1348, 13305, 1348, 9758, 4741, 88795, 1012, 43428, 1014, 1013, 1013, 72768, 45356, 2049, 1012, 8596, 1013, 31697, 38262, 22760, 4261, 75129, 11721, 1013, 21614, 1011, 64653, 1013, 10638, 9465, 1013, 32270, 1013, 22195, 1011, 1, 1012, 52811, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [2, 4467, 3711, 3460, 2798, 26283, 4580, 9713, 77742, 2793, 4373, 2015, 2802, 2800, 5536, 2991, 3051, 4082, 22292, 2840, 4908, 3027, 1379, 2842, 2789, 3387, 4031, 5501, 1379, 3082, 10672, 13635, 2831, 6597, 2015, 1012, 1006, 13635, 4655, 2791, 88736, 1007, 2880, 5002, 25321, 2794, 63050, 4642, 33732, 3510, 2793, 3168, 1379, 4642, 19446, 2793, 41169, 1379, 4642, 7182, 9838, 3395, 2861, 22292, 4659, 10672, 1012, 3546, 7618, 4642, 3593, 25321, 5929, 2820, 60069, 1012, 1012, 27987, 10207, 5676, 1348, 3633, 2842, 6558, 2799, 3437, 3022, 17687, 2840, 3192, 1379, 11093, 5165, 1012, 2842, 4031, 5165, 5317, 1006, 3466, 3241, 4196, 6343, 9454, 1007, 3013, 4388, 9329, 2008, 13689, 9656, 4748, 3798, 43034, 5536, 3192, 4666, 2840, 5373, 14114, 1012, 5002, 3387, 1379, 30681, 1350, 2842, 12516, 4110, 40131, 27052, 3424, 4110, 1379, 4892, 3584, 3584, 5043, 10821, 6651, 5536, 6518, 26283, 1012, 2842, 12516, 6484, 28613, 27052, 2791, 3192, 5536, 5863, 1379, 58098, 36870, 38548, 1379, 4659, 3322, 9838, 3395, 3810, 3919, 18466, 1012, 2880, 12516, 9166, 2840, 35131, 2015, 34802, 37930, 5971, 2802, 4082, 2800, 5121, 79770, 1379, 18706, 2005, 3541, 22146, 1379, 5121, 18706, 2799, 3878, 28313, 4642, 40794, 59729, 10672, 5536, 9166, 2787, 2800, 3013, 61165, 8595, 1012, 2802, 4103, 2791, 3250, 3873, 2786, 8457, 6649, 3681, 44302, 4116, 70291, 2908, 3218, 6651, 25612, 2816, 4892, 4314, 1379, 7146, 35370, 1348, 81444, 2816, 2802, 18382, 2800, 4031, 4279, 3082, 2791, 5536, 5863, 4630, 2840, 3821, 14760, 2015, 4352, 71442, 2840, 7363, 1012, 2949, 2786, 7503, 3304, 24715, 2791, 3437, 5536, 11817, 5238, 5334, 1350, 4124, 20133, 3035, 2789, 7621, 4031, 74375, 1350, 2842, 6558, 2968, 2798, 6748, 9524, 26481, 3254, 1012, 4642, 72153, 2003, 2800, 3805, 9231, 23086, 3460, 24333, 2015, 1012, 6500, 2015, 2789, 4826, 5536, 3790, 4216, 3578, 2800, 9838, 3395, 4642, 51676, 2793, 77110, 1379, 20793, 13868, 9146, 28613, 1012, 2802, 4642, 5137, 2834, 1012, 2786, 4029, 10422, 1379, 9560, 15407, 3929, 35046, 2848, 2802, 5863, 3765, 11389, 5501, 1012, 1379, 5536, 5863, 5466, 11190, 94426, 3192, 5501, 1012, 2842, 5668, 2791, 3437, 5043, 6343, 34958, 5466, 4892, 53574, 1012, 1379, 3082, 5536, 3929, 2008, 4440, 4928, 2842, 5983, 5019, 23086, 39770, 4888, 3660, 54026, 2802, 3218, 5137, 7621, 2840, 22367, 2008, 41939, 1350, 3633, 5763, 2015, 4639, 2871, 1350, 1379, 6558, 4246, 2938, 22531, 9250, 31746, 2014, 88145, 2005, 4033, 2910, 5783, 2799, 4997, 17904, 6421, 2861, 22292, 1012, 3082, 2842, 11020, 1379, 4639, 4033, 2910, 5783, 2840, 20305, 5501, 6651, 9172, 1012, 1379, 4642, 51676, 6173, 2791, 82690, 11038, 1014, 6173, 3124, 21628, 1350, 2848, 5971, 2786, 6173, 2789, 2802, 4639, 8065, 4642, 92702, 2003, 2793, 21825, 1012, 5089, 8926, 3256, 3692, 10672, 46088, 3460, 2798, 74601, 2816, 4788, 12139, 1012, 2965, 14744, 2789, 4639, 6173, 5362, 1001, 3063, 4113, 1014, 3437, 4134, 6939, 6343, 2802, 4175, 2791, 3250, 3873, 2786, 8457, 12179, 1348, 3250, 5019, 2800, 6052, 16249, 9113, 1379, 23317, 77626, 5441, 1012, 1012, 1012, 4], [2, 31100, 2831, 3475, 8381, 3422, 2789, 7275, 3188, 2848, 6177, 13197, 2847, 2803, 2786, 2808, 22788, 1012, 2831, 2802, 2867, 3918, 2791, 2897, 4766, 27864, 1379, 2880, 48374, 2988, 3168, 1012, 2831, 4183, 2829, 27864, 3581, 7240, 6604, 2789, 38702, 1348, 7623, 1379, 10554, 2824, 3329, 1348, 15185, 1379, 3898, 7240, 5850, 2806, 1012, 3937, 27864, 5929, 2831, 2829, 3419, 3643, 3475, 3171, 3811, 1379, 2799, 2829, 27864, 2800, 5256, 46558, 2952, 3936, 4366, 6259, 4113, 1012, 2786, 4029, 48374, 3581, 7240, 6617, 2806, 1379, 5995, 2831, 6597, 4366, 4006, 2806, 1379, 2944, 6311, 3431, 2803, 2786, 2808, 4113, 1012, 2786, 3251, 2789, 3640, 3102, 27864, 1379, 48374, 4387, 13002, 1012, 2786, 6295, 3150, 2789, 3640, 16477, 1379, 8369, 55436, 3364, 2871, 2806, 1012, 2786, 6295, 3150, 2789, 3640, 16477, 1379, 8369, 51760, 58674, 22451, 46217, 3364, 2871, 2806, 1012, 2786, 6295, 3150, 2789, 3640, 16477, 1379, 8369, 36108, 32088, 3364, 2871, 2806, 1012, 2786, 6295, 3150, 2789, 3640, 16477, 1379, 8369, 36108, 32088, 30765, 3364, 2871, 2806, 1012, 2786, 6295, 3150, 2789, 3640, 16477, 1379, 8369, 25691, 23000, 34567, 3364, 2871, 2806, 1012, 2786, 2802, 4997, 2789, 3640, 27864, 2809, 1379, 48374, 2794, 4387, 31041, 1012, 10336, 3450, 16004, 1379, 16477, 5256, 2789, 2847, 3060, 1012, 2786, 5426, 2800, 3124, 2829, 20026, 1012, 15241, 5271, 4109, 2806, 6757, 2988, 2791, 36108, 32088, 2786, 7358, 1379, 3672, 1379, 2786, 12617, 2789, 36108, 32088, 30765, 6337, 1012, 2786, 5426, 2800, 23679, 2791, 3437, 5524, 27864, 2809, 2988, 3116, 3732, 6917, 2831, 3124, 36108, 32088, 30765, 2806, 1012, 2786, 5426, 2800, 3422, 2789, 2829, 3952, 8451, 2831, 3475, 3329, 2847, 4717, 3845, 51760, 58674, 22451, 3732, 3229, 2831, 3124, 2806, 1012, 25303, 2800, 2802, 4997, 2840, 4893, 74375, 1348, 9472, 45560, 3124, 2820, 4246, 6789, 2799, 2964, 2789, 6468, 43641, 2788, 1014, 1007, 8223, 1053, 9172, 1053, 32573, 1053, 8488, 5434, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [2, 2786, 2802, 6012, 2793, 5690, 13222, 5812, 9826, 17915, 39298, 1379, 3475, 2786, 45147, 1012, 50466, 3096, 26040, 1012, 17915, 39298, 68095, 20984, 41250, 2908, 58677, 5929, 3013, 2829, 3983, 58565, 1011, 28653, 10884, 20984, 41250, 2959, 7486, 1012, 2829, 4082, 3826, 2802, 1014, 4467, 16614, 20984, 41250, 5929, 2840, 6828, 61130, 5520, 4109, 2802, 3444, 2800, 3660, 3013, 13459, 3096, 17420, 1010, 4309, 2799, 2829, 4183, 3772, 2793, 3592, 2800, 2786, 2937, 3910, 3529, 8987, 2871, 1006, 2789, 3404, 7533, 1007, 1379, 3854, 46463, 2840, 3803, 4279, 1012, 3404, 3067, 6312, 26154, 2078, 20804, 2952, 2800, 3371, 4244, 6828, 4338, 2800, 20867, 24124, 25637, 4129, 2958, 17521, 1012, 3124, 3013, 4467, 2802, 25675, 2840, 6828, 3116, 1012, 4207, 1442, 4055, 2871, 1014, 35667, 2786, 20984, 41250, 26978, 2003, 2791, 7430, 2800, 4614, 2786, 4366, 3683, 3022, 11231, 9225, 2800, 3064, 24124, 4440, 3791, 3329, 2786, 3517, 13946, 6176, 26702, 1379, 3251, 3510, 2793, 14114, 1012, 2802, 21659, 3457, 7551, 12814, 17420, 1012, 35088, 4467, 20984, 41250, 5929, 2840, 35667, 3116, 1014, 2988, 2791, 71743, 1011, 65307, 3765, 2786, 4366, 41747, 4232, 2791, 8408, 2800, 3013, 10099, 4793, 86822, 1012, 63162, 2033, 2952, 1012, 3064, 86822, 1012, 63162, 2033, 5311, 2789, 3724, 4336, 5641, 2789, 2829, 13809, 6832, 86822, 45243, 21659, 4536, 2789, 9529, 17420, 1012, 2829, 86822, 1012, 63162, 2033, 10884, 15190, 4129, 10672, 2965, 2964, 23116, 2791, 3626, 18087, 71743, 1011, 65307, 61666, 3592, 1012, 3211, 3116, 2800, 2802, 16698, 2831, 20984, 41250, 5929, 2867, 38999, 1012, 2791, 2988, 1442, 32071, 1379, 14745, 7965, 3116, 18071, 2798, 3547, 3798, 2829, 3444, 3643, 2786, 45147, 2829, 4965, 3152, 1010, 3633, 45147, 3686, 3406, 20984, 41250, 3629, 3083, 1379, 9988, 5758, 2791, 8012, 3634, 3683, 2988, 12702, 2848, 4393, 2840, 3916, 14114, 1012, 2988, 2791, 17915, 8012, 3124, 2840, 2848, 4253, 3406, 14106, 4106, 85861, 1012, 15799, 6343, 3970, 17358, 30012, 19055, 3445, 3116, 1014, 1002, 3475, 11176, 3013, 2829, 3329, 3581, 6072, 4613, 2938, 2800, 25584, 9774, 8953, 3589, 1010, 14244, 1010, 2965, 3966, 4645, 3060, 1379, 6072, 3329, 21659, 2786, 3944, 5594, 17420, 2848, 25005, 2862, 6343, 5019, 11080, 17521, 1012, 1002, 2867, 2840, 4216, 7864, 12840, 1011, 4613, 5940, 1010, 2829, 15799, 3013, 2829, 2867, 3096, 3791, 1010, 3362, 2789, 3732, 10146, 1001, 5392, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [2, 2842, 10951, 2786, 3035, 3802, 3130, 8941, 2786, 2802, 3665, 2786, 2802, 3050, 2806, 2800, 4117, 15619, 20936, 2803, 5594, 88887, 16766, 2880, 3254, 1350, 3064, 6173, 8170, 2806, 3310, 2808, 5825, 1350, 2949, 2802, 6012, 2799, 6379, 8695, 2924, 1012, 4309, 7394, 11384, 4461, 74701, 2803, 3096, 5994, 1348, 4309, 33103, 3050, 3138, 2847, 2803, 3229, 3116, 3854, 2802, 4366, 2803, 2786, 15185, 4129, 3116, 7559, 33103, 63703, 23344, 5276, 1014, 13743, 63703, 23344, 1012, 4888, 3329, 2803, 4129, 3116, 1014, 23709, 2050, 30750, 1012, 9966, 2800, 3329, 4129, 2871, 1379, 2786, 11999, 3124, 2799, 6914, 24954, 1014, 1013, 1013, 52248, 93789, 2040, 1014, 1, 1013, 3528, 3171, 3073, 1012, 2829, 28134, 4127, 28134, 62321, 2789, 4907, 45791, 17358, 1014, 13743, 62321, 1004, 1004, 43470, 43815, 2025, 45791, 1012, 2897, 6921, 2789, 34565, 37745, 1012, 50466, 1379, 98346, 2032, 1012, 50466, 4127, 28134, 45791, 17358, 1012, 4127, 2802, 6921, 37745, 1012, 50466, 2964, 16280, 20021, 2803, 3280, 4279, 1012, 12214, 98346, 2032, 2803, 4884, 2880, 4241, 2830, 2789, 5754, 4127, 28134, 45791, 3280, 3592, 1012, 6921, 37745, 1012, 50466, 4127, 28134, 62321, 2803, 10177, 3116, 1012, 5358, 3150, 2803, 4241, 3116, 1012, 2786, 33103, 62321, 28134, 88012, 2032, 2803, 3280, 3116, 1379, 4127, 88012, 2032, 3140, 6921, 2789, 5386, 52810, 2030, 1012, 50466, 1348, 52810, 32590, 78528, 2059, 1012, 50466, 1379, 52810, 61979, 8811, 2050, 1012, 50466, 17358, 1012, 3511, 5254, 3985, 15619, 20936, 2786, 4670, 4394, 15165, 3055, 52810, 2030, 1012, 50466, 2829, 71030, 3778, 17358, 2800, 2959, 2806, 28378, 9545, 14652, 2803, 4106, 2924, 1012, 70724, 2972, 3013, 5418, 2871, 3048, 1012, 4366, 3150, 2803, 2789, 52810, 32590, 78528, 2059, 1012, 50466, 4241, 3116, 1012, 2802, 4366, 2803, 2820, 2789, 52810, 61979, 8811, 2050, 1012, 50466, 4241, 3116, 26325, 2791, 4241, 3274, 3437, 17759, 1012, 3329, 3124, 3013, 3826, 2802, 2867, 3054, 1012, 3437, 8002, 2791, 45791, 3728, 3811, 1379, 2799, 2988, 2791, 98346, 2032, 3916, 3344, 1012, 4366, 4129, 2871, 2786, 30765, 93781, 26765, 27524, 18257, 3479, 3892, 1012, 5392, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}"]},"execution_count":16,"metadata":{"tags":[]},"output_type":"execute_result"}],"source":["sent_id"]},{"cell_type":"code","execution_count":17,"metadata":{"executionInfo":{"elapsed":13460,"status":"ok","timestamp":1610947235220,"user":{"displayName":"zeinab taghavi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GheNU3ejtJBEFfDC_0W_JdLEuwkW7SKnnDuH80MRA=s64","userId":"07214630829740929140"},"user_tz":-210},"id":"uF3FFsPzc6zD"},"outputs":[],"source":["sentence_maxlen=128"]},{"cell_type":"code","execution_count":18,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":24142,"status":"ok","timestamp":1610947246913,"user":{"displayName":"zeinab taghavi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GheNU3ejtJBEFfDC_0W_JdLEuwkW7SKnnDuH80MRA=s64","userId":"07214630829740929140"},"user_tz":-210},"id":"4m2Qc2IkrnEp","outputId":"4b242dcf-ad8b-4d6b-c869-c5ac25206faa"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2143: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n"]}],"source":["##Tokenize training and validation sentences:\r\n","train_encodings = tokenizer.batch_encode_plus(X_train,\r\n","    max_length = sentence_maxlen,\r\n","    pad_to_max_length=True,\r\n","    truncation=True,\r\n","    return_token_type_ids=False)\r\n","\r\n","val_encodings = tokenizer.batch_encode_plus(X_val,\r\n","    max_length = sentence_maxlen,\r\n","    pad_to_max_length=True,\r\n","    truncation=True,\r\n","    return_token_type_ids=False)\r\n","\r\n","test_encodings=tokenizer.batch_encode_plus(X_test,\r\n","    max_length = sentence_maxlen,\r\n","    pad_to_max_length=True,\r\n","    truncation=True,\r\n","    return_token_type_ids=False)"]},{"cell_type":"code","execution_count":19,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":23735,"status":"ok","timestamp":1610947246916,"user":{"displayName":"zeinab taghavi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GheNU3ejtJBEFfDC_0W_JdLEuwkW7SKnnDuH80MRA=s64","userId":"07214630829740929140"},"user_tz":-210},"id":"IwjkXARbetX-","outputId":"b7372730-a28d-42b7-c7d2-06d3e4ea9607"},"outputs":[{"data":{"text/plain":["Encoding(num_tokens=128, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing])"]},"execution_count":19,"metadata":{"tags":[]},"output_type":"execute_result"}],"source":["train_encodings[0]"]},{"cell_type":"code","execution_count":20,"metadata":{"executionInfo":{"elapsed":22934,"status":"ok","timestamp":1610947246917,"user":{"displayName":"zeinab taghavi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GheNU3ejtJBEFfDC_0W_JdLEuwkW7SKnnDuH80MRA=s64","userId":"07214630829740929140"},"user_tz":-210},"id":"-iCp2PUEupYK"},"outputs":[],"source":["import torch\r\n","import torch.nn as nn\r\n","\r\n","# for train set\r\n","train_seq = torch.tensor(train_encodings['input_ids'])\r\n","train_mask = torch.tensor(train_encodings['attention_mask'])\r\n","train_y = torch.tensor(y_train)\r\n","\r\n","# for validation set\r\n","val_seq = torch.tensor(val_encodings['input_ids'])\r\n","val_mask = torch.tensor(val_encodings['attention_mask'])\r\n","val_y = torch.tensor(y_val)\r\n","\r\n","# for test set\r\n","test_seq = torch.tensor(test_encodings['input_ids'])\r\n","test_mask = torch.tensor(test_encodings['attention_mask'])\r\n","test_y = torch.tensor(y_test)"]},{"cell_type":"code","execution_count":21,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":22595,"status":"ok","timestamp":1610947246918,"user":{"displayName":"zeinab taghavi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GheNU3ejtJBEFfDC_0W_JdLEuwkW7SKnnDuH80MRA=s64","userId":"07214630829740929140"},"user_tz":-210},"id":"h0JkQbxVBmbM","outputId":"c1e53d62-226b-40a7-a9e5-04e4ecf9ca90"},"outputs":[{"data":{"text/plain":["tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0])"]},"execution_count":21,"metadata":{"tags":[]},"output_type":"execute_result"}],"source":["train_y[0]"]},{"cell_type":"code","execution_count":22,"metadata":{"executionInfo":{"elapsed":22308,"status":"ok","timestamp":1610947246921,"user":{"displayName":"zeinab taghavi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GheNU3ejtJBEFfDC_0W_JdLEuwkW7SKnnDuH80MRA=s64","userId":"07214630829740929140"},"user_tz":-210},"id":"T2xiV6Nb0ddZ"},"outputs":[],"source":["from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\r\n","\r\n","#define a batch size\r\n","batch_size = 32\r\n","\r\n","# wrap tensors\r\n","train_data = TensorDataset(train_seq, train_mask, train_y)\r\n","\r\n","# sampler for sampling the data during training\r\n","train_sampler = RandomSampler(train_data)\r\n","\r\n","# dataLoader for train set\r\n","train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\r\n","\r\n","# wrap tensors\r\n","val_data = TensorDataset(val_seq, val_mask, val_y)\r\n","\r\n","# sampler for sampling the data during training\r\n","val_sampler = SequentialSampler(val_data)\r\n","\r\n","# dataLoader for validation set\r\n","val_dataloader = DataLoader(val_data, sampler = val_sampler, batch_size=batch_size)\r\n","\r\n","# wrap tensors\r\n","test_data = TensorDataset(test_seq, test_mask, test_y)\r\n","\r\n","# sampler for sampling the data during training\r\n","test_sampler = SequentialSampler(test_data)\r\n","\r\n","# dataLoader for validation set\r\n","test_dataloader = DataLoader(test_data, sampler = test_sampler, batch_size=batch_size)"]},{"cell_type":"code","execution_count":23,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":749},"executionInfo":{"elapsed":38324,"status":"ok","timestamp":1610947264608,"user":{"displayName":"zeinab taghavi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GheNU3ejtJBEFfDC_0W_JdLEuwkW7SKnnDuH80MRA=s64","userId":"07214630829740929140"},"user_tz":-210},"id":"UwGHXIjGfmaN","outputId":"6d446abb-15d5-4b5d-b8a8-70374f8b6f0f"},"outputs":[{"name":"stdout","output_type":"stream","text":["{'input_ids': [[2, 32071, 9574, 1026, 89390, 36260, 84378, 40908, 2041, 4, 0], [2, 13632, 25909, 70608, 1011, 40716, 2033, 1026, 89390, 36260, 4]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ad5ff9f784c140cfa2cb9a82a48dd26f","version_major":2,"version_minor":0},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=654226731.0, style=ProgressStyle(descri…"]},"metadata":{"tags":[]},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\n","BaseModelOutputWithPoolingAndCrossAttentions(last_hidden_state=tensor([[[-0.9919,  0.0981,  1.0746,  ...,  0.4275,  0.1416, -0.8444],\n","         [ 0.1278,  1.2993, -1.5561,  ..., -0.4052, -0.0262, -0.9568],\n","         [-0.4283, -0.5914, -0.0802,  ..., -0.1228, -0.5051,  0.2659],\n","         ...,\n","         [-0.7192, -0.7666, -0.7105,  ...,  1.2001,  0.6686, -0.7979],\n","         [-0.2818, -0.5135,  0.7244,  ...,  0.2886,  0.0698, -0.5266],\n","         [-1.3168,  0.0980, -0.4526,  ...,  0.3502, -0.2239, -0.7427]],\n","\n","        [[-0.4695, -0.4073,  0.8762,  ...,  0.7422, -0.2326, -0.7650],\n","         [ 0.2054, -0.4946, -0.5946,  ...,  0.6374, -0.3904, -0.4286],\n","         [ 0.0755, -0.6795, -0.2105,  ..., -0.2501,  0.0618, -0.7201],\n","         ...,\n","         [-0.2454, -0.1457, -0.9372,  ...,  0.4147, -0.0582, -1.3273],\n","         [-0.6755, -1.1889, -0.4421,  ...,  0.7833, -0.1249, -0.9160],\n","         [-0.2252, -1.2662,  0.7468,  ...,  0.3321, -0.0847, -0.2277]]],\n","       grad_fn=\u003cNativeLayerNormBackward\u003e), pooler_output=tensor([[ 0.5635,  0.9964, -0.1304,  ...,  0.2850, -0.1079, -0.1139],\n","        [ 0.7378,  0.9984,  0.2313,  ...,  0.1546, -0.1034, -0.5129]],\n","       grad_fn=\u003cTanhBackward\u003e), hidden_states=None, past_key_values=None, attentions=None, cross_attentions=None)\n","tensor([[[-0.9919,  0.0981,  1.0746,  ...,  0.4275,  0.1416, -0.8444],\n","         [ 0.1278,  1.2993, -1.5561,  ..., -0.4052, -0.0262, -0.9568],\n","         [-0.4283, -0.5914, -0.0802,  ..., -0.1228, -0.5051,  0.2659],\n","         ...,\n","         [-0.7192, -0.7666, -0.7105,  ...,  1.2001,  0.6686, -0.7979],\n","         [-0.2818, -0.5135,  0.7244,  ...,  0.2886,  0.0698, -0.5266],\n","         [-1.3168,  0.0980, -0.4526,  ...,  0.3502, -0.2239, -0.7427]],\n","\n","        [[-0.4695, -0.4073,  0.8762,  ...,  0.7422, -0.2326, -0.7650],\n","         [ 0.2054, -0.4946, -0.5946,  ...,  0.6374, -0.3904, -0.4286],\n","         [ 0.0755, -0.6795, -0.2105,  ..., -0.2501,  0.0618, -0.7201],\n","         ...,\n","         [-0.2454, -0.1457, -0.9372,  ...,  0.4147, -0.0582, -1.3273],\n","         [-0.6755, -1.1889, -0.4421,  ...,  0.7833, -0.1249, -0.9160],\n","         [-0.2252, -1.2662,  0.7468,  ...,  0.3321, -0.0847, -0.2277]]],\n","       grad_fn=\u003cNativeLayerNormBackward\u003e)\n","tensor([[ 0.5635,  0.9964, -0.1304,  ...,  0.2850, -0.1079, -0.1139],\n","        [ 0.7378,  0.9984,  0.2313,  ...,  0.1546, -0.1034, -0.5129]],\n","       grad_fn=\u003cTanhBackward\u003e)\n","torch.Size([2, 768])\n"]}],"source":["# example\r\n","\r\n","\r\n","text = [\"this is a bert model tutorial\", \"we will fine-tune a bert model\"]\r\n","\r\n","# encode text\r\n","sent_id = tokenizer.batch_encode_plus(text, padding=True, return_token_type_ids=False)\r\n","print(sent_id)\r\n","\r\n","seq = torch.tensor(sent_id['input_ids'])\r\n","mask = torch.tensor(sent_id['attention_mask'])\r\n","train_y = torch.tensor([0,1])\r\n","\r\n","transformer_model = AutoModel.from_pretrained(Model_name)\r\n","cls_hs=transformer_model(seq,mask)\r\n","print(cls_hs)\r\n","print(cls_hs[0])\r\n","print(cls_hs[1])\r\n","print(cls_hs[1].shape)"]},{"cell_type":"markdown","metadata":{"id":"ByUEn_v4zknn"},"source":["## Model"]},{"cell_type":"code","execution_count":24,"metadata":{"executionInfo":{"elapsed":40376,"status":"ok","timestamp":1610947268438,"user":{"displayName":"zeinab taghavi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GheNU3ejtJBEFfDC_0W_JdLEuwkW7SKnnDuH80MRA=s64","userId":"07214630829740929140"},"user_tz":-210},"id":"n3AjEaHcEMfb"},"outputs":[],"source":["transformer_model = AutoModel.from_pretrained(Model_name)"]},{"cell_type":"code","execution_count":25,"metadata":{"executionInfo":{"elapsed":40072,"status":"ok","timestamp":1610947268439,"user":{"displayName":"zeinab taghavi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GheNU3ejtJBEFfDC_0W_JdLEuwkW7SKnnDuH80MRA=s64","userId":"07214630829740929140"},"user_tz":-210},"id":"RaAlYydhxPTd"},"outputs":[],"source":["# freeze all the parameters\r\n","for param in transformer_model.parameters():\r\n","    param.requires_grad = False"]},{"cell_type":"code","execution_count":26,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1767,"status":"ok","timestamp":1610947270216,"user":{"displayName":"zeinab taghavi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GheNU3ejtJBEFfDC_0W_JdLEuwkW7SKnnDuH80MRA=s64","userId":"07214630829740929140"},"user_tz":-210},"id":"nUa1R1WQONe6","outputId":"66021302-3b8b-4199-94a9-2a931f018e94"},"outputs":[{"data":{"text/plain":["78"]},"execution_count":26,"metadata":{"tags":[]},"output_type":"execute_result"}],"source":["len(labels)"]},{"cell_type":"code","execution_count":27,"metadata":{"executionInfo":{"elapsed":1759,"status":"ok","timestamp":1610947270217,"user":{"displayName":"zeinab taghavi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GheNU3ejtJBEFfDC_0W_JdLEuwkW7SKnnDuH80MRA=s64","userId":"07214630829740929140"},"user_tz":-210},"id":"oyE_ThEms5aZ"},"outputs":[],"source":["class BERT_Arch(nn.Module):\r\n","\r\n","    def __init__(self, bert):\r\n","      \r\n","      super(BERT_Arch, self).__init__()\r\n","\r\n","      self.bert = bert \r\n","      \r\n","      # dropout layer\r\n","      self.dropout = nn.Dropout(0.1)\r\n","      \r\n","      # relu activation function\r\n","      self.relu =  nn.ReLU()\r\n","\r\n","      # dense layer 1\r\n","      self.fc1 = nn.Linear(768,512)\r\n","      \r\n","      # dense layer 2 (Output layer)\r\n","      self.fc2 = nn.Linear(512,78)\r\n","\r\n","      #sigmoid activation function\r\n","      self.sigmoid = nn.Sigmoid()\r\n","\r\n","    #define the forward pass\r\n","    def forward(self, sent_id, mask):\r\n","\r\n","      #pass the inputs to the model  \r\n","      cls_hs = self.bert(sent_id, attention_mask=mask)\r\n","      \r\n","      x = self.fc1(cls_hs[1])\r\n","\r\n","      x = self.relu(x)\r\n","\r\n","      x = self.dropout(x)\r\n","\r\n","      # output layer\r\n","      x = self.fc2(x)\r\n","      \r\n","      # apply sigmoid activation\r\n","      x = self.sigmoid(x)\r\n","\r\n","      return x"]},{"cell_type":"code","execution_count":28,"metadata":{"executionInfo":{"elapsed":16128,"status":"ok","timestamp":1610947284593,"user":{"displayName":"zeinab taghavi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GheNU3ejtJBEFfDC_0W_JdLEuwkW7SKnnDuH80MRA=s64","userId":"07214630829740929140"},"user_tz":-210},"id":"rDuHzo96z6z8"},"outputs":[],"source":["# pass the pre-trained BERT to our define architecture\n","model = BERT_Arch(transformer_model)\n","\n","# push the model to GPU\n","model = model.to(device)"]},{"cell_type":"code","execution_count":29,"metadata":{"executionInfo":{"elapsed":16122,"status":"ok","timestamp":1610947284595,"user":{"displayName":"zeinab taghavi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GheNU3ejtJBEFfDC_0W_JdLEuwkW7SKnnDuH80MRA=s64","userId":"07214630829740929140"},"user_tz":-210},"id":"FUNSLBYcLc9q"},"outputs":[],"source":["# optimizer from hugging face transformers\n","from transformers import AdamW\n","\n","# define the optimizer\n","optimizer = torch.optim.AdamW(model.parameters(), lr = 1e-3)"]},{"cell_type":"code","execution_count":30,"metadata":{"executionInfo":{"elapsed":16117,"status":"ok","timestamp":1610947284596,"user":{"displayName":"zeinab taghavi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GheNU3ejtJBEFfDC_0W_JdLEuwkW7SKnnDuH80MRA=s64","userId":"07214630829740929140"},"user_tz":-210},"id":"ArHmwhh7JrZh"},"outputs":[],"source":["loss_func =nn.MultiLabelSoftMarginLoss()"]},{"cell_type":"code","execution_count":31,"metadata":{"executionInfo":{"elapsed":16112,"status":"ok","timestamp":1610947284597,"user":{"displayName":"zeinab taghavi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GheNU3ejtJBEFfDC_0W_JdLEuwkW7SKnnDuH80MRA=s64","userId":"07214630829740929140"},"user_tz":-210},"id":"c8LjQyDXs0bG"},"outputs":[],"source":["# function to train the model\r\n","def train():\r\n","  \r\n","  model.train()\r\n","\r\n","  total_loss, total_accuracy = 0, 0\r\n","  \r\n","  # empty list to save model predictions\r\n","  total_preds=[]\r\n","  \r\n","  # iterate over batches\r\n","  for step,batch in enumerate(train_dataloader):\r\n","    \r\n","    # progress update after every 50 batches.\r\n","    if step % 50 == 0 and not step == 0:\r\n","      print('  Batch {:\u003e5,}  of  {:\u003e5,}.'.format(step, len(train_dataloader)))\r\n","\r\n","    # push the batch to gpu\r\n","    batch = [r.to(device) for r in batch]\r\n"," \r\n","    sent_id, mask, labels = batch\r\n","\r\n","    # clear previously calculated gradients \r\n","    model.zero_grad()        \r\n","\r\n","    # get model predictions for the current batch\r\n","    preds = model(sent_id, mask)\r\n","\r\n","    # compute the loss between actual and predicted values\r\n","    \r\n","    loss = loss_func(preds, labels)\r\n","    # add on to the total loss\r\n","    total_loss = total_loss + loss.item()\r\n","\r\n","    # backward pass to calculate the gradients\r\n","    loss.backward()\r\n","\r\n","    # clip the the gradients to 1.0. It helps in preventing the exploding gradient problem\r\n","    torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\r\n","\r\n","    # update parameters\r\n","    optimizer.step()\r\n","\r\n","    # model predictions are stored on GPU. So, push it to CPU\r\n","    preds=preds.detach().cpu().numpy()\r\n","\r\n","    # append the model predictions\r\n","    total_preds.append(preds)\r\n","\r\n","  # compute the training loss of the epoch\r\n","  avg_loss = total_loss / len(train_dataloader)\r\n","  \r\n","  # predictions are in the form of (no. of batches, size of batch, no. of classes).\r\n","  # reshape the predictions in form of (number of samples, no. of classes)\r\n","  total_preds  = numpy.concatenate(total_preds, axis=0)\r\n","\r\n","  #returns the loss and predictions\r\n","  return avg_loss, total_preds"]},{"cell_type":"code","execution_count":32,"metadata":{"executionInfo":{"elapsed":16109,"status":"ok","timestamp":1610947284598,"user":{"displayName":"zeinab taghavi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GheNU3ejtJBEFfDC_0W_JdLEuwkW7SKnnDuH80MRA=s64","userId":"07214630829740929140"},"user_tz":-210},"id":"XNBRQo9WMHey"},"outputs":[],"source":["# function for evaluating the model\r\n","def evaluate():\r\n","  \r\n","  print(\"\\nEvaluating...\")\r\n","  \r\n","  # deactivate dropout layers\r\n","  model.eval()\r\n","\r\n","  total_loss, total_accuracy = 0, 0\r\n","  \r\n","  # empty list to save the model predictions\r\n","  total_preds = []\r\n","\r\n","  # iterate over batches\r\n","  for step,batch in enumerate(val_dataloader):\r\n","    \r\n","    # Progress update every 50 batches.\r\n","    if step % 50 == 0 and not step == 0:\r\n","      \r\n","      # Calculate elapsed time in minutes.\r\n","      # elapsed = format_time(time.time() - t0)\r\n","            \r\n","      # Report progress.\r\n","      print('  Batch {:\u003e5,}  of  {:\u003e5,}.'.format(step, len(val_dataloader)))\r\n","\r\n","    # push the batch to gpu\r\n","    batch = [t.to(device) for t in batch]\r\n","\r\n","    sent_id, mask, labels = batch\r\n","\r\n","    # deactivate autograd\r\n","    with torch.no_grad():\r\n","      \r\n","      # model predictions\r\n","      preds = model(sent_id, mask)\r\n","\r\n","      # compute the validation loss between actual and predicted values\r\n","      loss = loss_func(preds,labels)\r\n","\r\n","      total_loss = total_loss + loss.item()\r\n","\r\n","      preds = preds.detach().cpu().numpy()\r\n","\r\n","      total_preds.append(preds)\r\n","\r\n","  # compute the validation loss of the epoch\r\n","  avg_loss = total_loss / len(val_dataloader) \r\n","\r\n","  # reshape the predictions in form of (number of samples, no. of classes)\r\n","  total_preds  = numpy.concatenate(total_preds, axis=0)\r\n","\r\n","  return avg_loss, total_preds"]},{"cell_type":"code","execution_count":33,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1179260,"status":"ok","timestamp":1610955773273,"user":{"displayName":"zeinab taghavi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GheNU3ejtJBEFfDC_0W_JdLEuwkW7SKnnDuH80MRA=s64","userId":"07214630829740929140"},"user_tz":-210},"id":"Qu5pfrJKtTc0"},"outputs":[{"name":"stdout","output_type":"stream","text":["\n"," Epoch 1 / 100\n","  Batch    50  of    267.\n","  Batch   100  of    267.\n","  Batch   150  of    267.\n","  Batch   200  of    267.\n","  Batch   250  of    267.\n","\n","Evaluating...\n","  Batch    50  of     89.\n","\n","Training Loss: 0.697\n","Validation Loss: 0.693\n","\n"," Epoch 2 / 100\n","  Batch    50  of    267.\n","  Batch   100  of    267.\n","  Batch   150  of    267.\n","  Batch   200  of    267.\n","  Batch   250  of    267.\n","\n","Evaluating...\n","  Batch    50  of     89.\n","\n","Training Loss: 0.693\n","Validation Loss: 0.693\n","\n"," Epoch 3 / 100\n","  Batch    50  of    267.\n","  Batch   100  of    267.\n","  Batch   150  of    267.\n","  Batch   200  of    267.\n","  Batch   250  of    267.\n","\n","Evaluating...\n","  Batch    50  of     89.\n","\n","Training Loss: 0.693\n","Validation Loss: 0.693\n","\n"," Epoch 4 / 100\n","  Batch    50  of    267.\n","  Batch   100  of    267.\n","  Batch   150  of    267.\n","  Batch   200  of    267.\n","  Batch   250  of    267.\n","\n","Evaluating...\n","  Batch    50  of     89.\n","\n","Training Loss: 0.693\n","Validation Loss: 0.693\n","\n"," Epoch 5 / 100\n","  Batch    50  of    267.\n","  Batch   100  of    267.\n","  Batch   150  of    267.\n","  Batch   200  of    267.\n","  Batch   250  of    267.\n","\n","Evaluating...\n","  Batch    50  of     89.\n","\n","Training Loss: 0.693\n","Validation Loss: 0.693\n","\n"," Epoch 6 / 100\n","  Batch    50  of    267.\n","  Batch   100  of    267.\n","  Batch   150  of    267.\n","  Batch   200  of    267.\n","  Batch   250  of    267.\n","\n","Evaluating...\n","  Batch    50  of     89.\n","\n","Training Loss: 0.693\n","Validation Loss: 0.693\n","\n"," Epoch 7 / 100\n","  Batch    50  of    267.\n","  Batch   100  of    267.\n","  Batch   150  of    267.\n","  Batch   200  of    267.\n","  Batch   250  of    267.\n","\n","Evaluating...\n","  Batch    50  of     89.\n","\n","Training Loss: 0.693\n","Validation Loss: 0.693\n","\n"," Epoch 8 / 100\n","  Batch    50  of    267.\n","  Batch   100  of    267.\n","  Batch   150  of    267.\n","  Batch   200  of    267.\n","  Batch   250  of    267.\n","\n","Evaluating...\n","  Batch    50  of     89.\n","\n","Training Loss: 0.693\n","Validation Loss: 0.693\n","\n"," Epoch 9 / 100\n","  Batch    50  of    267.\n","  Batch   100  of    267.\n","  Batch   150  of    267.\n","  Batch   200  of    267.\n","  Batch   250  of    267.\n","\n","Evaluating...\n","  Batch    50  of     89.\n","\n","Training Loss: 0.693\n","Validation Loss: 0.693\n","\n"," Epoch 10 / 100\n","  Batch    50  of    267.\n","  Batch   100  of    267.\n","  Batch   150  of    267.\n","  Batch   200  of    267.\n","  Batch   250  of    267.\n","\n","Evaluating...\n","  Batch    50  of     89.\n","\n","Training Loss: 0.693\n","Validation Loss: 0.693\n","\n"," Epoch 11 / 100\n","  Batch    50  of    267.\n","  Batch   100  of    267.\n","  Batch   150  of    267.\n","  Batch   200  of    267.\n","  Batch   250  of    267.\n","\n","Evaluating...\n","  Batch    50  of     89.\n","\n","Training Loss: 0.693\n","Validation Loss: 0.693\n","\n"," Epoch 12 / 100\n","  Batch    50  of    267.\n","  Batch   100  of    267.\n","  Batch   150  of    267.\n","  Batch   200  of    267.\n","  Batch   250  of    267.\n","\n","Evaluating...\n","  Batch    50  of     89.\n","\n","Training Loss: 0.693\n","Validation Loss: 0.693\n","\n"," Epoch 13 / 100\n","  Batch    50  of    267.\n","  Batch   100  of    267.\n","  Batch   150  of    267.\n","  Batch   200  of    267.\n","  Batch   250  of    267.\n","\n","Evaluating...\n","  Batch    50  of     89.\n","\n","Training Loss: 0.693\n","Validation Loss: 0.693\n","\n"," Epoch 14 / 100\n","  Batch    50  of    267.\n","  Batch   100  of    267.\n","  Batch   150  of    267.\n","  Batch   200  of    267.\n","  Batch   250  of    267.\n","\n","Evaluating...\n","  Batch    50  of     89.\n","\n","Training Loss: 0.693\n","Validation Loss: 0.693\n","\n"," Epoch 15 / 100\n","  Batch    50  of    267.\n","  Batch   100  of    267.\n","  Batch   150  of    267.\n","  Batch   200  of    267.\n","  Batch   250  of    267.\n","\n","Evaluating...\n","  Batch    50  of     89.\n","\n","Training Loss: 0.693\n","Validation Loss: 0.693\n","\n"," Epoch 16 / 100\n","  Batch    50  of    267.\n","  Batch   100  of    267.\n","  Batch   150  of    267.\n","  Batch   200  of    267.\n","  Batch   250  of    267.\n","\n","Evaluating...\n","  Batch    50  of     89.\n","\n","Training Loss: 0.693\n","Validation Loss: 0.693\n","\n"," Epoch 17 / 100\n","  Batch    50  of    267.\n","  Batch   100  of    267.\n","  Batch   150  of    267.\n","  Batch   200  of    267.\n","  Batch   250  of    267.\n","\n","Evaluating...\n","  Batch    50  of     89.\n","\n","Training Loss: 0.693\n","Validation Loss: 0.693\n","\n"," Epoch 18 / 100\n","  Batch    50  of    267.\n","  Batch   100  of    267.\n","  Batch   150  of    267.\n","  Batch   200  of    267.\n","  Batch   250  of    267.\n","\n","Evaluating...\n","  Batch    50  of     89.\n","\n","Training Loss: 0.693\n","Validation Loss: 0.693\n","\n"," Epoch 19 / 100\n","  Batch    50  of    267.\n","  Batch   100  of    267.\n","  Batch   150  of    267.\n","  Batch   200  of    267.\n","  Batch   250  of    267.\n","\n","Evaluating...\n","  Batch    50  of     89.\n","\n","Training Loss: 0.693\n","Validation Loss: 0.693\n","\n"," Epoch 20 / 100\n","  Batch    50  of    267.\n","  Batch   100  of    267.\n","  Batch   150  of    267.\n","  Batch   200  of    267.\n","  Batch   250  of    267.\n","\n","Evaluating...\n","  Batch    50  of     89.\n","\n","Training Loss: 0.693\n","Validation Loss: 0.693\n","\n"," Epoch 21 / 100\n","  Batch    50  of    267.\n","  Batch   100  of    267.\n","  Batch   150  of    267.\n","  Batch   200  of    267.\n","  Batch   250  of    267.\n","\n","Evaluating...\n","  Batch    50  of     89.\n","\n","Training Loss: 0.693\n","Validation Loss: 0.693\n","\n"," Epoch 22 / 100\n","  Batch    50  of    267.\n","  Batch   100  of    267.\n","  Batch   150  of    267.\n","  Batch   200  of    267.\n","  Batch   250  of    267.\n","\n","Evaluating...\n","  Batch    50  of     89.\n","\n","Training Loss: 0.693\n","Validation Loss: 0.693\n","\n"," Epoch 23 / 100\n","  Batch    50  of    267.\n","  Batch   100  of    267.\n","  Batch   150  of    267.\n","  Batch   200  of    267.\n","  Batch   250  of    267.\n","\n","Evaluating...\n","  Batch    50  of     89.\n","\n","Training Loss: 0.693\n","Validation Loss: 0.693\n","\n"," Epoch 24 / 100\n","  Batch    50  of    267.\n","  Batch   100  of    267.\n","  Batch   150  of    267.\n","  Batch   200  of    267.\n","  Batch   250  of    267.\n","\n","Evaluating...\n","  Batch    50  of     89.\n","\n","Training Loss: 0.693\n","Validation Loss: 0.693\n","\n"," Epoch 25 / 100\n","  Batch    50  of    267.\n","  Batch   100  of    267.\n","  Batch   150  of    267.\n","  Batch   200  of    267.\n","  Batch   250  of    267.\n","\n","Evaluating...\n","  Batch    50  of     89.\n","\n","Training Loss: 0.693\n","Validation Loss: 0.693\n","\n"," Epoch 26 / 100\n","  Batch    50  of    267.\n","  Batch   100  of    267.\n","  Batch   150  of    267.\n","  Batch   200  of    267.\n","  Batch   250  of    267.\n","\n","Evaluating...\n","  Batch    50  of     89.\n","\n","Training Loss: 0.693\n","Validation Loss: 0.693\n","\n"," Epoch 27 / 100\n","  Batch    50  of    267.\n","  Batch   100  of    267.\n","  Batch   150  of    267.\n","  Batch   200  of    267.\n","  Batch   250  of    267.\n","\n","Evaluating...\n","  Batch    50  of     89.\n","\n","Training Loss: 0.693\n","Validation Loss: 0.693\n","\n"," Epoch 28 / 100\n","  Batch    50  of    267.\n","  Batch   100  of    267.\n","  Batch   150  of    267.\n","  Batch   200  of    267.\n","  Batch   250  of    267.\n","\n","Evaluating...\n","  Batch    50  of     89.\n","\n","Training Loss: 0.693\n","Validation Loss: 0.693\n","\n"," Epoch 29 / 100\n","  Batch    50  of    267.\n","  Batch   100  of    267.\n","  Batch   150  of    267.\n","  Batch   200  of    267.\n","  Batch   250  of    267.\n","\n","Evaluating...\n","  Batch    50  of     89.\n","\n","Training Loss: 0.693\n","Validation Loss: 0.693\n","\n"," Epoch 30 / 100\n","  Batch    50  of    267.\n","  Batch   100  of    267.\n","  Batch   150  of    267.\n","  Batch   200  of    267.\n","  Batch   250  of    267.\n","\n","Evaluating...\n","  Batch    50  of     89.\n","\n","Training Loss: 0.693\n","Validation Loss: 0.693\n","\n"," Epoch 31 / 100\n","  Batch    50  of    267.\n","  Batch   100  of    267.\n","  Batch   150  of    267.\n","  Batch   200  of    267.\n","  Batch   250  of    267.\n","\n","Evaluating...\n","  Batch    50  of     89.\n","\n","Training Loss: 0.693\n","Validation Loss: 0.693\n","\n"," Epoch 32 / 100\n","  Batch    50  of    267.\n","  Batch   100  of    267.\n","  Batch   150  of    267.\n","  Batch   200  of    267.\n","  Batch   250  of    267.\n","\n","Evaluating...\n","  Batch    50  of     89.\n","\n","Training Loss: 0.693\n","Validation Loss: 0.693\n","\n"," Epoch 33 / 100\n","  Batch    50  of    267.\n","  Batch   100  of    267.\n","  Batch   150  of    267.\n","  Batch   200  of    267.\n","  Batch   250  of    267.\n","\n","Evaluating...\n","  Batch    50  of     89.\n","\n","Training Loss: 0.693\n","Validation Loss: 0.693\n","\n"," Epoch 34 / 100\n","  Batch    50  of    267.\n","  Batch   100  of    267.\n","  Batch   150  of    267.\n","  Batch   200  of    267.\n","  Batch   250  of    267.\n","\n","Evaluating...\n","  Batch    50  of     89.\n","\n","Training Loss: 0.693\n","Validation Loss: 0.693\n","\n"," Epoch 35 / 100\n","  Batch    50  of    267.\n","  Batch   100  of    267.\n","  Batch   150  of    267.\n","  Batch   200  of    267.\n","  Batch   250  of    267.\n","\n","Evaluating...\n","  Batch    50  of     89.\n","\n","Training Loss: 0.693\n","Validation Loss: 0.693\n","\n"," Epoch 36 / 100\n","  Batch    50  of    267.\n","  Batch   100  of    267.\n","  Batch   150  of    267.\n","  Batch   200  of    267.\n","  Batch   250  of    267.\n","\n","Evaluating...\n","  Batch    50  of     89.\n","\n","Training Loss: 0.693\n","Validation Loss: 0.693\n","\n"," Epoch 37 / 100\n","  Batch    50  of    267.\n","  Batch   100  of    267.\n","  Batch   150  of    267.\n","  Batch   200  of    267.\n","  Batch   250  of    267.\n","\n","Evaluating...\n","  Batch    50  of     89.\n","\n","Training Loss: 0.693\n","Validation Loss: 0.693\n","\n"," Epoch 38 / 100\n","  Batch    50  of    267.\n","  Batch   100  of    267.\n","  Batch   150  of    267.\n","  Batch   200  of    267.\n","  Batch   250  of    267.\n","\n","Evaluating...\n","  Batch    50  of     89.\n","\n","Training Loss: 0.693\n","Validation Loss: 0.693\n","\n"," Epoch 39 / 100\n","  Batch    50  of    267.\n","  Batch   100  of    267.\n","  Batch   150  of    267.\n","  Batch   200  of    267.\n","  Batch   250  of    267.\n","\n","Evaluating...\n","  Batch    50  of     89.\n","\n","Training Loss: 0.693\n","Validation Loss: 0.693\n","\n"," Epoch 40 / 100\n","  Batch    50  of    267.\n","  Batch   100  of    267.\n","  Batch   150  of    267.\n","  Batch   200  of    267.\n","  Batch   250  of    267.\n","\n","Evaluating...\n","  Batch    50  of     89.\n","\n","Training Loss: 0.693\n","Validation Loss: 0.693\n","\n"," Epoch 41 / 100\n","  Batch    50  of    267.\n","  Batch   100  of    267.\n","  Batch   150  of    267.\n","  Batch   200  of    267.\n","  Batch   250  of    267.\n","\n","Evaluating...\n","  Batch    50  of     89.\n","\n","Training Loss: 0.693\n","Validation Loss: 0.693\n","\n"," Epoch 42 / 100\n","  Batch    50  of    267.\n","  Batch   100  of    267.\n","  Batch   150  of    267.\n","  Batch   200  of    267.\n","  Batch   250  of    267.\n","\n","Evaluating...\n","  Batch    50  of     89.\n","\n","Training Loss: 0.693\n","Validation Loss: 0.693\n","\n"," Epoch 43 / 100\n","  Batch    50  of    267.\n","  Batch   100  of    267.\n","  Batch   150  of    267.\n","  Batch   200  of    267.\n","  Batch   250  of    267.\n","\n","Evaluating...\n","  Batch    50  of     89.\n","\n","Training Loss: 0.693\n","Validation Loss: 0.693\n","\n"," Epoch 44 / 100\n","  Batch    50  of    267.\n","  Batch   100  of    267.\n","  Batch   150  of    267.\n","  Batch   200  of    267.\n","  Batch   250  of    267.\n","\n","Evaluating...\n","  Batch    50  of     89.\n","\n","Training Loss: 0.693\n","Validation Loss: 0.693\n","\n"," Epoch 45 / 100\n","  Batch    50  of    267.\n","  Batch   100  of    267.\n","  Batch   150  of    267.\n","  Batch   200  of    267.\n","  Batch   250  of    267.\n","\n","Evaluating...\n","  Batch    50  of     89.\n","\n","Training Loss: 0.693\n","Validation Loss: 0.693\n","\n"," Epoch 46 / 100\n","  Batch    50  of    267.\n","  Batch   100  of    267.\n","  Batch   150  of    267.\n","  Batch   200  of    267.\n","  Batch   250  of    267.\n","\n","Evaluating...\n","  Batch    50  of     89.\n","\n","Training Loss: 0.693\n","Validation Loss: 0.693\n","\n"," Epoch 47 / 100\n","  Batch    50  of    267.\n","  Batch   100  of    267.\n","  Batch   150  of    267.\n","  Batch   200  of    267.\n","  Batch   250  of    267.\n","\n","Evaluating...\n","  Batch    50  of     89.\n","\n","Training Loss: 0.693\n","Validation Loss: 0.693\n","\n"," Epoch 48 / 100\n","  Batch    50  of    267.\n","  Batch   100  of    267.\n","  Batch   150  of    267.\n","  Batch   200  of    267.\n","  Batch   250  of    267.\n","\n","Evaluating...\n","  Batch    50  of     89.\n","\n","Training Loss: 0.693\n","Validation Loss: 0.693\n","\n"," Epoch 49 / 100\n","  Batch    50  of    267.\n","  Batch   100  of    267.\n","  Batch   150  of    267.\n","  Batch   200  of    267.\n","  Batch   250  of    267.\n","\n","Evaluating...\n","  Batch    50  of     89.\n","\n","Training Loss: 0.693\n","Validation Loss: 0.693\n","\n"," Epoch 50 / 100\n","  Batch    50  of    267.\n","  Batch   100  of    267.\n","  Batch   150  of    267.\n","  Batch   200  of    267.\n","  Batch   250  of    267.\n","\n","Evaluating...\n","  Batch    50  of     89.\n","\n","Training Loss: 0.693\n","Validation Loss: 0.693\n","\n"," Epoch 51 / 100\n","  Batch    50  of    267.\n","  Batch   100  of    267.\n","  Batch   150  of    267.\n","  Batch   200  of    267.\n","  Batch   250  of    267.\n","\n","Evaluating...\n","  Batch    50  of     89.\n","\n","Training Loss: 0.693\n","Validation Loss: 0.693\n","\n"," Epoch 52 / 100\n","  Batch    50  of    267.\n","  Batch   100  of    267.\n","  Batch   150  of    267.\n","  Batch   200  of    267.\n","  Batch   250  of    267.\n","\n","Evaluating...\n","  Batch    50  of     89.\n","\n","Training Loss: 0.693\n","Validation Loss: 0.693\n","\n"," Epoch 53 / 100\n","  Batch    50  of    267.\n","  Batch   100  of    267.\n","  Batch   150  of    267.\n","  Batch   200  of    267.\n","  Batch   250  of    267.\n","\n","Evaluating...\n","  Batch    50  of     89.\n","\n","Training Loss: 0.693\n","Validation Loss: 0.693\n","\n"," Epoch 54 / 100\n","  Batch    50  of    267.\n","  Batch   100  of    267.\n","  Batch   150  of    267.\n","  Batch   200  of    267.\n","  Batch   250  of    267.\n","\n","Evaluating...\n","  Batch    50  of     89.\n","\n","Training Loss: 0.693\n","Validation Loss: 0.693\n","\n"," Epoch 55 / 100\n","  Batch    50  of    267.\n","  Batch   100  of    267.\n","  Batch   150  of    267.\n","  Batch   200  of    267.\n","  Batch   250  of    267.\n","\n","Evaluating...\n","  Batch    50  of     89.\n","\n","Training Loss: 0.693\n","Validation Loss: 0.693\n","\n"," Epoch 56 / 100\n","  Batch    50  of    267.\n","  Batch   100  of    267.\n","  Batch   150  of    267.\n","  Batch   200  of    267.\n","  Batch   250  of    267.\n","\n","Evaluating...\n","  Batch    50  of     89.\n","\n","Training Loss: 0.693\n","Validation Loss: 0.693\n","\n"," Epoch 57 / 100\n","  Batch    50  of    267.\n","  Batch   100  of    267.\n","  Batch   150  of    267.\n","  Batch   200  of    267.\n","  Batch   250  of    267.\n","\n","Evaluating...\n","  Batch    50  of     89.\n","\n","Training Loss: 0.693\n","Validation Loss: 0.693\n","\n"," Epoch 58 / 100\n","  Batch    50  of    267.\n","  Batch   100  of    267.\n","  Batch   150  of    267.\n","  Batch   200  of    267.\n","  Batch   250  of    267.\n","\n","Evaluating...\n","  Batch    50  of     89.\n","\n","Training Loss: 0.693\n","Validation Loss: 0.693\n","\n"," Epoch 59 / 100\n","  Batch    50  of    267.\n","  Batch   100  of    267.\n","  Batch   150  of    267.\n","  Batch   200  of    267.\n","  Batch   250  of    267.\n","\n","Evaluating...\n","  Batch    50  of     89.\n","\n","Training Loss: 0.693\n","Validation Loss: 0.693\n","\n"," Epoch 60 / 100\n","  Batch    50  of    267.\n","  Batch   100  of    267.\n","  Batch   150  of    267.\n","  Batch   200  of    267.\n","  Batch   250  of    267.\n","\n","Evaluating...\n","  Batch    50  of     89.\n","\n","Training Loss: 0.693\n","Validation Loss: 0.693\n","\n"," Epoch 61 / 100\n","  Batch    50  of    267.\n","  Batch   100  of    267.\n","  Batch   150  of    267.\n","  Batch   200  of    267.\n","  Batch   250  of    267.\n","\n","Evaluating...\n","  Batch    50  of     89.\n","\n","Training Loss: 0.693\n","Validation Loss: 0.693\n","\n"," Epoch 62 / 100\n","  Batch    50  of    267.\n","  Batch   100  of    267.\n","  Batch   150  of    267.\n","  Batch   200  of    267.\n","  Batch   250  of    267.\n","\n","Evaluating...\n","  Batch    50  of     89.\n","\n","Training Loss: 0.693\n","Validation Loss: 0.693\n","\n"," Epoch 63 / 100\n","  Batch    50  of    267.\n","  Batch   100  of    267.\n","  Batch   150  of    267.\n","  Batch   200  of    267.\n","  Batch   250  of    267.\n","\n","Evaluating...\n","  Batch    50  of     89.\n","\n","Training Loss: 0.693\n","Validation Loss: 0.693\n","\n"," Epoch 64 / 100\n","  Batch    50  of    267.\n","  Batch   100  of    267.\n","  Batch   150  of    267.\n","  Batch   200  of    267.\n","  Batch   250  of    267.\n","\n","Evaluating...\n","  Batch    50  of     89.\n","\n","Training Loss: 0.693\n","Validation Loss: 0.693\n","\n"," Epoch 65 / 100\n","  Batch    50  of    267.\n","  Batch   100  of    267.\n","  Batch   150  of    267.\n","  Batch   200  of    267.\n","  Batch   250  of    267.\n","\n","Evaluating...\n","  Batch    50  of     89.\n","\n","Training Loss: 0.693\n","Validation Loss: 0.693\n","\n"," Epoch 66 / 100\n","  Batch    50  of    267.\n","  Batch   100  of    267.\n","  Batch   150  of    267.\n","  Batch   200  of    267.\n","  Batch   250  of    267.\n","\n","Evaluating...\n","  Batch    50  of     89.\n","\n","Training Loss: 0.693\n","Validation Loss: 0.693\n","\n"," Epoch 67 / 100\n","  Batch    50  of    267.\n","  Batch   100  of    267.\n","  Batch   150  of    267.\n","  Batch   200  of    267.\n","  Batch   250  of    267.\n","\n","Evaluating...\n","  Batch    50  of     89.\n","\n","Training Loss: 0.693\n","Validation Loss: 0.693\n","\n"," Epoch 68 / 100\n","  Batch    50  of    267.\n","  Batch   100  of    267.\n","  Batch   150  of    267.\n","  Batch   200  of    267.\n","  Batch   250  of    267.\n","\n","Evaluating...\n","  Batch    50  of     89.\n","\n","Training Loss: 0.693\n","Validation Loss: 0.693\n","\n"," Epoch 69 / 100\n","  Batch    50  of    267.\n","  Batch   100  of    267.\n","  Batch   150  of    267.\n","  Batch   200  of    267.\n","  Batch   250  of    267.\n","\n","Evaluating...\n","  Batch    50  of     89.\n","\n","Training Loss: 0.693\n","Validation Loss: 0.693\n","\n"," Epoch 70 / 100\n","  Batch    50  of    267.\n","  Batch   100  of    267.\n","  Batch   150  of    267.\n","  Batch   200  of    267.\n","  Batch   250  of    267.\n","\n","Evaluating...\n","  Batch    50  of     89.\n","\n","Training Loss: 0.693\n","Validation Loss: 0.693\n","\n"," Epoch 71 / 100\n","  Batch    50  of    267.\n","  Batch   100  of    267.\n","  Batch   150  of    267.\n","  Batch   200  of    267.\n","  Batch   250  of    267.\n","\n","Evaluating...\n","  Batch    50  of     89.\n","\n","Training Loss: 0.693\n","Validation Loss: 0.693\n","\n"," Epoch 72 / 100\n","  Batch    50  of    267.\n","  Batch   100  of    267.\n","  Batch   150  of    267.\n","  Batch   200  of    267.\n","  Batch   250  of    267.\n","\n","Evaluating...\n","  Batch    50  of     89.\n","\n","Training Loss: 0.693\n","Validation Loss: 0.693\n","\n"," Epoch 73 / 100\n","  Batch    50  of    267.\n","  Batch   100  of    267.\n","  Batch   150  of    267.\n","  Batch   200  of    267.\n","  Batch   250  of    267.\n","\n","Evaluating...\n","  Batch    50  of     89.\n","\n","Training Loss: 0.693\n","Validation Loss: 0.693\n","\n"," Epoch 74 / 100\n","  Batch    50  of    267.\n","  Batch   100  of    267.\n","  Batch   150  of    267.\n","  Batch   200  of    267.\n","  Batch   250  of    267.\n","\n","Evaluating...\n","  Batch    50  of     89.\n","\n","Training Loss: 0.693\n","Validation Loss: 0.693\n","\n"," Epoch 75 / 100\n","  Batch    50  of    267.\n","  Batch   100  of    267.\n","  Batch   150  of    267.\n","  Batch   200  of    267.\n","  Batch   250  of    267.\n","\n","Evaluating...\n","  Batch    50  of     89.\n","\n","Training Loss: 0.693\n","Validation Loss: 0.693\n","\n"," Epoch 76 / 100\n","  Batch    50  of    267.\n","  Batch   100  of    267.\n","  Batch   150  of    267.\n","  Batch   200  of    267.\n","  Batch   250  of    267.\n","\n","Evaluating...\n","  Batch    50  of     89.\n","\n","Training Loss: 0.693\n","Validation Loss: 0.693\n","\n"," Epoch 77 / 100\n","  Batch    50  of    267.\n","  Batch   100  of    267.\n","  Batch   150  of    267.\n","  Batch   200  of    267.\n","  Batch   250  of    267.\n","\n","Evaluating...\n","  Batch    50  of     89.\n","\n","Training Loss: 0.693\n","Validation Loss: 0.693\n","\n"," Epoch 78 / 100\n","  Batch    50  of    267.\n","  Batch   100  of    267.\n","  Batch   150  of    267.\n","  Batch   200  of    267.\n","  Batch   250  of    267.\n","\n","Evaluating...\n","  Batch    50  of     89.\n","\n","Training Loss: 0.693\n","Validation Loss: 0.693\n","\n"," Epoch 79 / 100\n","  Batch    50  of    267.\n","  Batch   100  of    267.\n","  Batch   150  of    267.\n","  Batch   200  of    267.\n","  Batch   250  of    267.\n","\n","Evaluating...\n","  Batch    50  of     89.\n","\n","Training Loss: 0.693\n","Validation Loss: 0.693\n","\n"," Epoch 80 / 100\n","  Batch    50  of    267.\n","  Batch   100  of    267.\n","  Batch   150  of    267.\n","  Batch   200  of    267.\n","  Batch   250  of    267.\n","\n","Evaluating...\n","  Batch    50  of     89.\n","\n","Training Loss: 0.693\n","Validation Loss: 0.693\n","\n"," Epoch 81 / 100\n","  Batch    50  of    267.\n","  Batch   100  of    267.\n","  Batch   150  of    267.\n","  Batch   200  of    267.\n","  Batch   250  of    267.\n","\n","Evaluating...\n","  Batch    50  of     89.\n","\n","Training Loss: 0.693\n","Validation Loss: 0.693\n","\n"," Epoch 82 / 100\n","  Batch    50  of    267.\n","  Batch   100  of    267.\n","  Batch   150  of    267.\n","  Batch   200  of    267.\n","  Batch   250  of    267.\n","\n","Evaluating...\n","  Batch    50  of     89.\n","\n","Training Loss: 0.693\n","Validation Loss: 0.693\n","\n"," Epoch 83 / 100\n","  Batch    50  of    267.\n","  Batch   100  of    267.\n","  Batch   150  of    267.\n","  Batch   200  of    267.\n","  Batch   250  of    267.\n","\n","Evaluating...\n","  Batch    50  of     89.\n","\n","Training Loss: 0.693\n","Validation Loss: 0.693\n","\n"," Epoch 84 / 100\n","  Batch    50  of    267.\n","  Batch   100  of    267.\n","  Batch   150  of    267.\n","  Batch   200  of    267.\n","  Batch   250  of    267.\n","\n","Evaluating...\n","  Batch    50  of     89.\n","\n","Training Loss: 0.693\n","Validation Loss: 0.693\n","\n"," Epoch 85 / 100\n","  Batch    50  of    267.\n","  Batch   100  of    267.\n","  Batch   150  of    267.\n","  Batch   200  of    267.\n","  Batch   250  of    267.\n","\n","Evaluating...\n","  Batch    50  of     89.\n","\n","Training Loss: 0.693\n","Validation Loss: 0.693\n","\n"," Epoch 86 / 100\n","  Batch    50  of    267.\n","  Batch   100  of    267.\n","  Batch   150  of    267.\n","  Batch   200  of    267.\n","  Batch   250  of    267.\n","\n","Evaluating...\n","  Batch    50  of     89.\n","\n","Training Loss: 0.693\n","Validation Loss: 0.693\n","\n"," Epoch 87 / 100\n","  Batch    50  of    267.\n","  Batch   100  of    267.\n","  Batch   150  of    267.\n","  Batch   200  of    267.\n","  Batch   250  of    267.\n","\n","Evaluating...\n","  Batch    50  of     89.\n","\n","Training Loss: 0.693\n","Validation Loss: 0.693\n","\n"," Epoch 88 / 100\n","  Batch    50  of    267.\n","  Batch   100  of    267.\n","  Batch   150  of    267.\n","  Batch   200  of    267.\n","  Batch   250  of    267.\n","\n","Evaluating...\n","  Batch    50  of     89.\n","\n","Training Loss: 0.693\n","Validation Loss: 0.693\n","\n"," Epoch 89 / 100\n","  Batch    50  of    267.\n","  Batch   100  of    267.\n","  Batch   150  of    267.\n","  Batch   200  of    267.\n","  Batch   250  of    267.\n","\n","Evaluating...\n","  Batch    50  of     89.\n","\n","Training Loss: 0.693\n","Validation Loss: 0.693\n","\n"," Epoch 90 / 100\n","  Batch    50  of    267.\n","  Batch   100  of    267.\n","  Batch   150  of    267.\n","  Batch   200  of    267.\n","  Batch   250  of    267.\n","\n","Evaluating...\n","  Batch    50  of     89.\n","\n","Training Loss: 0.693\n","Validation Loss: 0.693\n","\n"," Epoch 91 / 100\n","  Batch    50  of    267.\n","  Batch   100  of    267.\n","  Batch   150  of    267.\n","  Batch   200  of    267.\n","  Batch   250  of    267.\n","\n","Evaluating...\n","  Batch    50  of     89.\n","\n","Training Loss: 0.693\n","Validation Loss: 0.693\n","\n"," Epoch 92 / 100\n","  Batch    50  of    267.\n","  Batch   100  of    267.\n","  Batch   150  of    267.\n","  Batch   200  of    267.\n","  Batch   250  of    267.\n","\n","Evaluating...\n","  Batch    50  of     89.\n","\n","Training Loss: 0.693\n","Validation Loss: 0.693\n","\n"," Epoch 93 / 100\n","  Batch    50  of    267.\n","  Batch   100  of    267.\n","  Batch   150  of    267.\n","  Batch   200  of    267.\n","  Batch   250  of    267.\n","\n","Evaluating...\n","  Batch    50  of     89.\n","\n","Training Loss: 0.693\n","Validation Loss: 0.693\n","\n"," Epoch 94 / 100\n","  Batch    50  of    267.\n","  Batch   100  of    267.\n","  Batch   150  of    267.\n","  Batch   200  of    267.\n","  Batch   250  of    267.\n","\n","Evaluating...\n","  Batch    50  of     89.\n","\n","Training Loss: 0.693\n","Validation Loss: 0.693\n","\n"," Epoch 95 / 100\n","  Batch    50  of    267.\n","  Batch   100  of    267.\n","  Batch   150  of    267.\n","  Batch   200  of    267.\n","  Batch   250  of    267.\n","\n","Evaluating...\n","  Batch    50  of     89.\n","\n","Training Loss: 0.693\n","Validation Loss: 0.693\n","\n"," Epoch 96 / 100\n","  Batch    50  of    267.\n","  Batch   100  of    267.\n","  Batch   150  of    267.\n","  Batch   200  of    267.\n","  Batch   250  of    267.\n","\n","Evaluating...\n","  Batch    50  of     89.\n","\n","Training Loss: 0.693\n","Validation Loss: 0.693\n","\n"," Epoch 97 / 100\n","  Batch    50  of    267.\n","  Batch   100  of    267.\n","  Batch   150  of    267.\n","  Batch   200  of    267.\n","  Batch   250  of    267.\n","\n","Evaluating...\n","  Batch    50  of     89.\n","\n","Training Loss: 0.693\n","Validation Loss: 0.693\n","\n"," Epoch 98 / 100\n","  Batch    50  of    267.\n","  Batch   100  of    267.\n","  Batch   150  of    267.\n","  Batch   200  of    267.\n","  Batch   250  of    267.\n","\n","Evaluating...\n","  Batch    50  of     89.\n","\n","Training Loss: 0.693\n","Validation Loss: 0.693\n","\n"," Epoch 99 / 100\n","  Batch    50  of    267.\n","  Batch   100  of    267.\n","  Batch   150  of    267.\n","  Batch   200  of    267.\n","  Batch   250  of    267.\n","\n","Evaluating...\n","  Batch    50  of     89.\n","\n","Training Loss: 0.693\n","Validation Loss: 0.693\n","\n"," Epoch 100 / 100\n","  Batch    50  of    267.\n","  Batch   100  of    267.\n","  Batch   150  of    267.\n","  Batch   200  of    267.\n","  Batch   250  of    267.\n","\n","Evaluating...\n","  Batch    50  of     89.\n","\n","Training Loss: 0.693\n","Validation Loss: 0.693\n"]}],"source":["# number of training epochs\r\n","epochs = 100\r\n","\r\n","# set initial loss to infinite\r\n","best_valid_loss = float('inf')\r\n","\r\n","# empty lists to store training and validation loss of each epoch\r\n","train_losses=[]\r\n","valid_losses=[]\r\n","\r\n","#for each epoch\r\n","for epoch in range(epochs):\r\n","     \r\n","    print('\\n Epoch {:} / {:}'.format(epoch + 1, epochs))\r\n","    \r\n","    #train model\r\n","    train_loss, _ = train()\r\n","    \r\n","    #evaluate model\r\n","    valid_loss, _ = evaluate()\r\n","    \r\n","    #save the best model\r\n","    if valid_loss \u003c best_valid_loss:\r\n","        best_valid_loss = valid_loss\r\n","        torch.save(model.state_dict(), 'saved_weights.pt')\r\n","    \r\n","    # append training and validation loss\r\n","    train_losses.append(train_loss)\r\n","    valid_losses.append(valid_loss)\r\n","    \r\n","    print(f'\\nTraining Loss: {train_loss:.3f}')\r\n","    print(f'Validation Loss: {valid_loss:.3f}')"]},{"cell_type":"code","execution_count":34,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/","height":282},"executionInfo":{"elapsed":23,"status":"ok","timestamp":1610955773275,"user":{"displayName":"zeinab taghavi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GheNU3ejtJBEFfDC_0W_JdLEuwkW7SKnnDuH80MRA=s64","userId":"07214630829740929140"},"user_tz":-210},"id":"HK8GlmNcW0sa"},"outputs":[{"data":{"text/plain":["[\u003cmatplotlib.lines.Line2D at 0x7f73ca1a7e48\u003e]"]},"execution_count":null,"metadata":{},"output_type":"execute_result"},{"data":{"image/png":"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\n","text/plain":["\u003cFigure size 432x288 with 1 Axes\u003e"]},"metadata":{},"output_type":"display_data"}],"source":["import matplotlib.pyplot as plt\n","plt.plot(train_losses)"]},{"cell_type":"markdown","metadata":{"id":"cQ2_aS0zCLvp"},"source":["Loading saved model:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cvR-FhPpuLkR"},"outputs":[],"source":["# torch.cuda.empty_cache()\r\n","# pass the pre-trained BERT to our define architecture\r\n","model = BERT_Arch(transformer_model)\r\n","\r\n","# push the model to GPU\r\n","model = model.to(device)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4470,"status":"ok","timestamp":1610509380028,"user":{"displayName":"mohadese rahnama","photoUrl":"","userId":"03886626379062840142"},"user_tz":-210},"id":"3aOPRZ2jVvNR","outputId":"8b608ad9-767d-4856-fcbe-443cc3ea4356"},"outputs":[{"data":{"text/plain":["\u003cAll keys matched successfully\u003e"]},"execution_count":18,"metadata":{"tags":[]},"output_type":"execute_result"}],"source":["#load weights of best model\r\n","path = 'ParsBERT_pytorch_balanced.pt'\r\n","model.load_state_dict(torch.load(path))"]},{"cell_type":"markdown","metadata":{"id":"PM1uUcZFCPVg"},"source":["After loading model:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XZhHObMnzuws"},"outputs":[],"source":["y_pred=[]\r\n","y_true=[]\r\n","for step,batch in enumerate(test_dataloader):\r\n","    \r\n","    # Progress update every 50 batches.\r\n","    if step % 50 == 0 and not step == 0:\r\n","      \r\n","      # Calculate elapsed time in minutes.\r\n","      # elapsed = format_time(time.time() - t0)\r\n","            \r\n","      # Report progress.\r\n","      print('  Batch {:\u003e5,}  of  {:\u003e5,}.'.format(step, len(test_dataloader)))\r\n","\r\n","    # push the batch to gpu\r\n","    batch = [t.to(device) for t in batch]\r\n","\r\n","    sent_id, mask, labels = batch\r\n","\r\n","    # deactivate autograd\r\n","    with torch.no_grad():\r\n","      \r\n","      # model predictions\r\n","      preds = model(sent_id, mask)\r\n","      # print(preds)\r\n","      # print(preds.cpu().numpy())\r\n","      preds = preds.cpu().numpy()\r\n","      # model's performance\r\n","    # preds = numpy.argmax(preds, axis = 1)\r\n","    \r\n","    measure = numpy.mean(preds[0]) + 1.15*numpy.sqrt(numpy.var(preds[0]))\r\n","    for l in preds:\r\n","      temp=[]\r\n","      for value in l:\r\n","        if value \u003e= measure:\r\n","          temp.append(1)\r\n","        else:\r\n","          temp.append(0)\r\n","      y_pred.append(temp)\r\n","    y_true.extend(labels.cpu().numpy())\r\n","    # print(labels.cpu().numpy()[0], preds[0])\r\n","print(classification_report(y_true, y_pred))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"A7Idi8Eg8EqS"},"outputs":[],"source":[""]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"ParsBERT_pytorch_balanced_600_words.ipynb","provenance":[{"file_id":"1k6QLcPAJKT5H2yTy61U-YCB267inolmb","timestamp":1610512876213},{"file_id":"1AIm-KimERCJutlpyjiZ2IAwM-cCrVsWM","timestamp":1610440221899},{"file_id":"17mqUcShahUjZjQxywgKQSGU1jV-CZW8o","timestamp":1610336820188},{"file_id":"1FgtzYXY0CXNyE_2FU4IEqJTQzmVZNvDh","timestamp":1610105938882}],"version":""},"kernelspec":{"display_name":"Python 3","name":"python3"},"widgets":{"application/vnd.jupyter.widget-state+json":{"009e32d59b8e44a38e68b0ba82bbf82c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_48ac1b703c7a430f8512ec15e29bc8ad","placeholder":"​","style":"IPY_MODEL_aeebb6c05e144b2d876fd036b923e6de","value":" 654M/654M [00:14\u0026lt;00:00, 46.3MB/s]"}},"0613cec2311e462685c958134f0d6828":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"Downloading: 100%","description_tooltip":null,"layout":"IPY_MODEL_a2c3f56c5d5d4223b46f83be93955663","max":654226731,"min":0,"orientation":"horizontal","style":"IPY_MODEL_2f6f7b0df0614d9fbd800a321a1566dc","value":654226731}},"1262c1b27b85449a9ad038e4734469dd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1445d803b7ae4691b4f896a920c28889":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_ca576ece55ed4d1f9e086995fff3e05e","IPY_MODEL_d8d5061f72654a1189e9cd9d778183ba"],"layout":"IPY_MODEL_960b015cd5794c97b0a807a5a4c46833"}},"278d924b87c24397bfcaadc7d14fdd0f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ea358cb5a4aa4b289cf3e9cbc79a0b2f","placeholder":"​","style":"IPY_MODEL_45e23fa7beee42e7943efef3ed3beb37","value":" 440/440 [00:00\u0026lt;00:00, 1.38kB/s]"}},"2f6f7b0df0614d9fbd800a321a1566dc":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":"initial"}},"394e1a422bf745f9bc7aea249f35fac9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"45e23fa7beee42e7943efef3ed3beb37":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"48ac1b703c7a430f8512ec15e29bc8ad":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"747d6def099b4bd8aec054bde56e0fd4":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":"initial"}},"902eeca565dd4b928b514541f0b197c6":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_94b01460e6ef4621b9e7c1a82502d5fb","IPY_MODEL_278d924b87c24397bfcaadc7d14fdd0f"],"layout":"IPY_MODEL_bf9b2382456f4519881762539f12a764"}},"94b01460e6ef4621b9e7c1a82502d5fb":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"Downloading: 100%","description_tooltip":null,"layout":"IPY_MODEL_e7e10313cfea4972805d9f623c170a40","max":440,"min":0,"orientation":"horizontal","style":"IPY_MODEL_747d6def099b4bd8aec054bde56e0fd4","value":440}},"960b015cd5794c97b0a807a5a4c46833":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a056527ef56c48beaa0ed0746cebda62":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":"initial"}},"a2c3f56c5d5d4223b46f83be93955663":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ab41578503fc47d7a5ef10edd2175efd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ad5ff9f784c140cfa2cb9a82a48dd26f":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_0613cec2311e462685c958134f0d6828","IPY_MODEL_009e32d59b8e44a38e68b0ba82bbf82c"],"layout":"IPY_MODEL_ab41578503fc47d7a5ef10edd2175efd"}},"aeebb6c05e144b2d876fd036b923e6de":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"bf9b2382456f4519881762539f12a764":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ca576ece55ed4d1f9e086995fff3e05e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"Downloading: 100%","description_tooltip":null,"layout":"IPY_MODEL_1262c1b27b85449a9ad038e4734469dd","max":1198122,"min":0,"orientation":"horizontal","style":"IPY_MODEL_a056527ef56c48beaa0ed0746cebda62","value":1198122}},"d8d5061f72654a1189e9cd9d778183ba":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ec0ebbf227754e239df2af8bd9270ad2","placeholder":"​","style":"IPY_MODEL_394e1a422bf745f9bc7aea249f35fac9","value":" 1.20M/1.20M [00:00\u0026lt;00:00, 5.47MB/s]"}},"e7e10313cfea4972805d9f623c170a40":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ea358cb5a4aa4b289cf3e9cbc79a0b2f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ec0ebbf227754e239df2af8bd9270ad2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}}}}},"nbformat":4,"nbformat_minor":0}