{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"multilingualBERT_pytorch.ipynb","provenance":[{"file_id":"17Pz04rEo4Ru5mffLjXtdLPXDYz-O5RFP","timestamp":1610639409932},{"file_id":"1k6QLcPAJKT5H2yTy61U-YCB267inolmb","timestamp":1610512876213},{"file_id":"1AIm-KimERCJutlpyjiZ2IAwM-cCrVsWM","timestamp":1610440221899},{"file_id":"17mqUcShahUjZjQxywgKQSGU1jV-CZW8o","timestamp":1610336820188},{"file_id":"1FgtzYXY0CXNyE_2FU4IEqJTQzmVZNvDh","timestamp":1610105938882}],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"widgets":{"application/vnd.jupyter.widget-state+json":{"50d8c48d525b473faa63a0aa6af9bd05":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_021d451bf6c34eec935f6c7d6cfc6391","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_00be19b00bcc499fbe726ad2de81faac","IPY_MODEL_5e7937e333e143f4a6faa38f315c66ac"]}},"021d451bf6c34eec935f6c7d6cfc6391":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"00be19b00bcc499fbe726ad2de81faac":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_399c1c514fce43b4b67a3284ca5a6982","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":625,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":625,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_8e6598a2b64d4369bf64a4d052e46c99"}},"5e7937e333e143f4a6faa38f315c66ac":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_c0989ea39c3044e3950f765100a1fcf1","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 625/625 [00:01&lt;00:00, 593B/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_bdcd6152a498417bbf622b9705411dff"}},"399c1c514fce43b4b67a3284ca5a6982":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"8e6598a2b64d4369bf64a4d052e46c99":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"c0989ea39c3044e3950f765100a1fcf1":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"bdcd6152a498417bbf622b9705411dff":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"9e091847d6884effae467ea2e7f7a1ee":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_16a4ec0f64894ab2b7619ad1a151543e","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_f5d0a2f0e72d4b7d994a692a1903d42c","IPY_MODEL_7bf152815c684c23803cf3fe3bb70892"]}},"16a4ec0f64894ab2b7619ad1a151543e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"f5d0a2f0e72d4b7d994a692a1903d42c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_e34bf0f0217e4c0ab72aa2ab1deb9975","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":995526,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":995526,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_ffb1017e26534e65bd56f50761f25b72"}},"7bf152815c684c23803cf3fe3bb70892":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_5e5d90114fe04323ba3924adc88b1d3e","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 996k/996k [00:00&lt;00:00, 2.30MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_53a0e557cb224be599d86c93b3ccd32d"}},"e34bf0f0217e4c0ab72aa2ab1deb9975":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"ffb1017e26534e65bd56f50761f25b72":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"5e5d90114fe04323ba3924adc88b1d3e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"53a0e557cb224be599d86c93b3ccd32d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"d75d5f7418f04f1da7da9fb7f4c3e171":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_bc26bd67db1c44978a1f242d1480d7a8","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_c07bc7bfe83b490baa5ebc330714fa9f","IPY_MODEL_30367e4653cc4c6086d7c9258921c39b"]}},"bc26bd67db1c44978a1f242d1480d7a8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"c07bc7bfe83b490baa5ebc330714fa9f":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_7e556e759fa04591a4efc9c4e317084b","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":714314041,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":714314041,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_002e2eb8a0ad4443805e2751d3d0aeab"}},"30367e4653cc4c6086d7c9258921c39b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_f85d437a0ebc46a48eefaab29dd47851","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 714M/714M [00:16&lt;00:00, 44.6MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_037f4616524041c8bc94abde97f7ee2e"}},"7e556e759fa04591a4efc9c4e317084b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"002e2eb8a0ad4443805e2751d3d0aeab":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"f85d437a0ebc46a48eefaab29dd47851":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"037f4616524041c8bc94abde97f7ee2e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"markdown","metadata":{"id":"j1LTPn7IjqTz"},"source":["Source:\r\n","\r\n","huggingface: https://huggingface.co/HooshvareLab/bert-fa-base-uncased-clf-persiannews\r\n","\r\n","Tutorial:https://towardsdatascience.com/fine-tuning-hugging-face-model-with-custom-dataset-82b8092f5333"]},{"cell_type":"code","metadata":{"id":"OmPFvCbSqyZF","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1610645894768,"user_tz":-210,"elapsed":37250,"user":{"displayName":"mohadese rahnama","photoUrl":"","userId":"03886626379062840142"}},"outputId":"d685009d-45e3-48a6-93d3-3791d9f5e091"},"source":["from google.colab import drive\r\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"iRxC0Pz1qzKc","executionInfo":{"status":"ok","timestamp":1610645895292,"user_tz":-210,"elapsed":3124,"user":{"displayName":"mohadese rahnama","photoUrl":"","userId":"03886626379062840142"}}},"source":["import os\r\n","os.chdir('/content/drive/MyDrive/sharif/FineTuning/ipython(guide)')"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mCRkKc3NcgkX","executionInfo":{"status":"ok","timestamp":1610645903948,"user_tz":-210,"elapsed":10760,"user":{"displayName":"mohadese rahnama","photoUrl":"","userId":"03886626379062840142"}},"outputId":"f418aaeb-e5d4-4ffc-f488-04b8385649b7"},"source":["!pip install transformers==2.8"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Collecting transformers==2.8\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a3/78/92cedda05552398352ed9784908b834ee32a0bd071a9b32de287327370b7/transformers-2.8.0-py3-none-any.whl (563kB)\n","\u001b[K     |████████████████████████████████| 573kB 8.4MB/s \n","\u001b[?25hCollecting boto3\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7a/da/8d9a790f134b36f4e3c53f0fca330a6917a3091c61cb74d4ab1e15ee8940/boto3-1.16.54-py2.py3-none-any.whl (130kB)\n","\u001b[K     |████████████████████████████████| 133kB 17.6MB/s \n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers==2.8) (1.19.5)\n","Collecting tokenizers==0.5.2\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d1/3f/73c881ea4723e43c1e9acf317cf407fab3a278daab3a69c98dcac511c04f/tokenizers-0.5.2-cp36-cp36m-manylinux1_x86_64.whl (3.7MB)\n","\u001b[K     |████████████████████████████████| 3.7MB 18.5MB/s \n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers==2.8) (3.0.12)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers==2.8) (2019.12.20)\n","Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers==2.8) (0.8)\n","Collecting sacremoses\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n","\u001b[K     |████████████████████████████████| 890kB 59.4MB/s \n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers==2.8) (4.41.1)\n","Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers==2.8) (2.23.0)\n","Collecting sentencepiece\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/14/67/e42bd1181472c95c8cda79305df848264f2a7f62740995a46945d9797b67/sentencepiece-0.1.95-cp36-cp36m-manylinux2014_x86_64.whl (1.2MB)\n","\u001b[K     |████████████████████████████████| 1.2MB 53.5MB/s \n","\u001b[?25hCollecting botocore<1.20.0,>=1.19.54\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/83/b5/c9c91206814b35b18d8e187cea17a084a1ab24a8596764d2549de900ac83/botocore-1.19.54-py2.py3-none-any.whl (7.2MB)\n","\u001b[K     |████████████████████████████████| 7.2MB 45.5MB/s \n","\u001b[?25hCollecting s3transfer<0.4.0,>=0.3.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ea/43/4b4a1b26eb03a429a4c37ca7fdf369d938bd60018fc194e94b8379b0c77c/s3transfer-0.3.4-py2.py3-none-any.whl (69kB)\n","\u001b[K     |████████████████████████████████| 71kB 10.7MB/s \n","\u001b[?25hCollecting jmespath<1.0.0,>=0.7.1\n","  Downloading https://files.pythonhosted.org/packages/07/cb/5f001272b6faeb23c1c9e0acc04d48eaaf5c862c17709d20e3469c6e0139/jmespath-0.10.0-py2.py3-none-any.whl\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==2.8) (1.15.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==2.8) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==2.8) (1.0.0)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.8) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.8) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.8) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.8) (2020.12.5)\n","Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.20.0,>=1.19.54->boto3->transformers==2.8) (2.8.1)\n","Building wheels for collected packages: sacremoses\n","  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893261 sha256=d57bb8e3cc416cf3acaa7883b1b9bb7b67868353250fa98dffcabd0f49dd810f\n","  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n","Successfully built sacremoses\n","\u001b[31mERROR: botocore 1.19.54 has requirement urllib3<1.27,>=1.25.4; python_version != \"3.4\", but you'll have urllib3 1.24.3 which is incompatible.\u001b[0m\n","Installing collected packages: jmespath, botocore, s3transfer, boto3, tokenizers, sacremoses, sentencepiece, transformers\n","Successfully installed boto3-1.16.54 botocore-1.19.54 jmespath-0.10.0 s3transfer-0.3.4 sacremoses-0.0.43 sentencepiece-0.1.95 tokenizers-0.5.2 transformers-2.8.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ODc44DglgNjZ","executionInfo":{"status":"ok","timestamp":1610645906102,"user_tz":-210,"elapsed":10314,"user":{"displayName":"mohadese rahnama","photoUrl":"","userId":"03886626379062840142"}},"outputId":"96e757f3-d436-4176-95bd-a5ec30dff447"},"source":["!pip3 install sentencepiece"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: sentencepiece in /usr/local/lib/python3.6/dist-packages (0.1.95)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qJY_L2p9a0t0","executionInfo":{"status":"ok","timestamp":1610606267975,"user_tz":-210,"elapsed":8951,"user":{"displayName":"zeinab taghavi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GheNU3ejtJBEFfDC_0W_JdLEuwkW7SKnnDuH80MRA=s64","userId":"07214630829740929140"}},"outputId":"707b84b3-d593-4e6c-d973-c7c478b9215c"},"source":["!git clone https://huggingface.co/HooshvareLab/bert-fa-base-uncased-clf-persiannews\r\n","GIT_LFS_SKIP_SMUDGE=1"],"execution_count":null,"outputs":[{"output_type":"stream","text":["fatal: destination path 'bert-fa-base-uncased-clf-persiannews' already exists and is not an empty directory.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Eg3Up037nThu","executionInfo":{"status":"ok","timestamp":1610645911761,"user_tz":-210,"elapsed":14712,"user":{"displayName":"mohadese rahnama","photoUrl":"","userId":"03886626379062840142"}}},"source":["import torch\r\n","import numpy\r\n","import pandas\r\n","import re\r\n","from sklearn.preprocessing import MultiLabelBinarizer\r\n","from sklearn.model_selection import train_test_split\r\n","from transformers import AutoTokenizer, AutoModelForSequenceClassification,AutoConfig,TFAutoModel,AutoModel\r\n","from transformers import BertConfig, BertTokenizer\r\n","from transformers import TFBertModel, TFBertForSequenceClassification\r\n","from transformers import glue_convert_examples_to_features, InputExample\r\n","from sklearn.metrics import classification_report"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"2Ur9wv1ytrZu","executionInfo":{"status":"ok","timestamp":1610645911769,"user_tz":-210,"elapsed":13388,"user":{"displayName":"mohadese rahnama","photoUrl":"","userId":"03886626379062840142"}}},"source":["# specify GPU\r\n","device = torch.device(\"cuda\")"],"execution_count":6,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xax4bHubzpMp"},"source":["## Data"]},{"cell_type":"code","metadata":{"id":"TJf6T40glV5g","executionInfo":{"status":"ok","timestamp":1610645914063,"user_tz":-210,"elapsed":14929,"user":{"displayName":"mohadese rahnama","photoUrl":"","userId":"03886626379062840142"}}},"source":["limit_number = 750\r\n","data = pandas.read_csv('../Data/limited_to_'+str(limit_number)+'.csv',index_col=0)\r\n","data = data.dropna().reset_index(drop=True)\r\n","X = data[\"body\"].values.tolist()\r\n","y = pandas.read_csv('../Data/limited_to_'+str(limit_number)+'.csv')\r\n","labels = []\r\n","tag=[]\r\n","for item in y['tag']:\r\n","  labels += [i for i in re.sub('\\\"|\\[|\\]|\\'| |=','',item.lower()).split(\",\") if i!='' and i!=' ']\r\n","  tag.append([i for i in re.sub('\\\"|\\[|\\]|\\'| |=','',item.lower()).split(\",\") if i!='' and i!=' '])\r\n","labels = list(set(labels))\r\n","mlb = MultiLabelBinarizer()\r\n","Y=mlb.fit_transform(tag)"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":283},"id":"A59_7YPmnZgA","executionInfo":{"status":"ok","timestamp":1610639644072,"user_tz":-210,"elapsed":2607,"user":{"displayName":"mohadese rahnama","photoUrl":"","userId":"03886626379062840142"}},"outputId":"58799b18-8c18-4690-97fb-c2faf114e8b1"},"source":["seq_len = [len(i.split()) for i in X]\n","pandas.Series(seq_len).hist(bins = 30)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<matplotlib.axes._subplots.AxesSubplot at 0x7f6c4df87ef0>"]},"metadata":{"tags":[]},"execution_count":8},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":283},"id":"1JEmlyFMm6Tf","executionInfo":{"status":"ok","timestamp":1610639647385,"user_tz":-210,"elapsed":1812,"user":{"displayName":"mohadese rahnama","photoUrl":"","userId":"03886626379062840142"}},"outputId":"4540255b-aa24-4b12-ca17-3232dff4d6c4"},"source":["seq_len = [len([j for j in i.split() if len(j)>2]) for i in X]\n","pandas.Series(seq_len).hist(bins = 30)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<matplotlib.axes._subplots.AxesSubplot at 0x7f6c4dd06278>"]},"metadata":{"tags":[]},"execution_count":9},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"code","metadata":{"id":"PH3jCKaZsEWo","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1610645914071,"user_tz":-210,"elapsed":12214,"user":{"displayName":"mohadese rahnama","photoUrl":"","userId":"03886626379062840142"}},"outputId":"9b69b200-2e9c-483b-a7bd-642ee876e5ed"},"source":["X_train, X_test, y_train, y_test = train_test_split(X,Y , test_size=0.2)\r\n","X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25)\r\n","print('train: ', len(X_train) , '\\ntest: ', len(X_test) , '\\nval: ', len(X_val) ,\"\\ny_tain:\",len(y_train) )"],"execution_count":8,"outputs":[{"output_type":"stream","text":["train:  12896 \n","test:  4299 \n","val:  4299 \n","y_tain: 12896\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Vei6iu9atmyd","colab":{"base_uri":"https://localhost:8080/","height":118,"referenced_widgets":["50d8c48d525b473faa63a0aa6af9bd05","021d451bf6c34eec935f6c7d6cfc6391","00be19b00bcc499fbe726ad2de81faac","5e7937e333e143f4a6faa38f315c66ac","399c1c514fce43b4b67a3284ca5a6982","8e6598a2b64d4369bf64a4d052e46c99","c0989ea39c3044e3950f765100a1fcf1","bdcd6152a498417bbf622b9705411dff","9e091847d6884effae467ea2e7f7a1ee","16a4ec0f64894ab2b7619ad1a151543e","f5d0a2f0e72d4b7d994a692a1903d42c","7bf152815c684c23803cf3fe3bb70892","e34bf0f0217e4c0ab72aa2ab1deb9975","ffb1017e26534e65bd56f50761f25b72","5e5d90114fe04323ba3924adc88b1d3e","53a0e557cb224be599d86c93b3ccd32d"]},"executionInfo":{"status":"ok","timestamp":1610645915708,"user_tz":-210,"elapsed":12446,"user":{"displayName":"mohadese rahnama","photoUrl":"","userId":"03886626379062840142"}},"outputId":"44ea5e02-04b9-47db-deff-47f26ae1291b"},"source":["##we would load the tokenizer\r\n","tokenizer = AutoTokenizer.from_pretrained(\"bert-base-multilingual-cased\")"],"execution_count":9,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"50d8c48d525b473faa63a0aa6af9bd05","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=625.0, style=ProgressStyle(description_…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"9e091847d6884effae467ea2e7f7a1ee","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=995526.0, style=ProgressStyle(descripti…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"C7wdU0zejDNq","executionInfo":{"elapsed":1080,"status":"ok","timestamp":1610445646323,"user":{"displayName":"mohadese rahnama","photoUrl":"","userId":"03886626379062840142"},"user_tz":-210},"outputId":"ac1884a3-45c6-475a-c09b-11363003e47c"},"source":["#example\r\n","text = \"ما در هوشواره معتقدیم با انتقال صحیح دانش و آگاهی، همه افراد میتوانند از ابزارهای هوشمند استفاده کنند. شعار ما هوش مصنوعی برای همه است.\"\r\n","tokenized=tokenizer.tokenize(X_train[0])\r\n","input_ids = tokenizer.convert_tokens_to_ids(tokenized)\r\n","print(tokenized)\r\n","print(input_ids)\r\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["['نمی', 'دونم', 'واقعی', '##ه', 'خونده', 'می', 'خوا', '##ی', 'مطمين', 'بشی', 'تصمیم', '##ت', 'ببین', 'گرفتی', '##ش', 'جهان', 'طوری', 'باهات', 'می', 'کنه', 'داره', 'برنامه', 'می', 'ره', 'سنگ', '##ای', 'ریز', 'درشت', 'پات', 'می', 'افت', '##ه', 'قدرتی', 'می', 'خواد', 'جلوت', 'بایسته', 'می', 'تونی', 'امیدوار', 'قدما', '##ی', 'اولو', 'برداشتی', 'شبیه', 'قصه', 'ی', 'اکت', 'نیتی', '##و', 'روزی', 'بسم', 'الله', 'درگیر', 'اتفاقا', '##یی', 'قاعدتا', 'هفته', 'می', 'افتادن', 'صفحه', 'کلید', 'تاپ', 'مقدمه', 'کار', 'افتاد', 'روزای', 'اسفند', 'بتونه', 'درستش', 'کنه', 'بشه', 'صفحه', 'کلید', 'خرید', 'اندازه', 'ی', 'کشف', 'واکسن', 'کرونا', 'می', 'رسید', 'کیبورد', 'قدیمی', 'امانت', 'اونم', 'دکمه', 'ی', 'اسپیس', 'مجبور', 'تیکه', 'پاک', 'توش', 'کار', 'بذارم', 'اونم', 'کار', 'افتاد', 'بعدم', 'تعمیرکار', 'اومدم', 'دیدم', 'کیبورد', '##و', 'تعمیر', 'ویندوز', '##مم', 'پریده', 'الله', 'اکبر', 'اقبال', 'بلند', 'خونسردی', '##مو', 'حفظ', 'بگم', 'خیال', 'دست', 'برمی', 'تاپ', 'حالش', 'نشد', 'مهمی', 'اطلاعاتم', 'دست', 'عوضش', 'کیبورد', 'خریدم', 'فلاکت', '##ی', 'خوشم', 'گم', '##ونم', 'می', 'تون', '##م', 'خط', 'ها', 'بنویسم', 'سلام', 're', '##act', 'nat', '##ive', 'جهان', 'سرش', 'چسب', '##وندم']\n","[2510, 89453, 4023, 1177, 90712, 2044, 68139, 1158, 6097, 30885, 3013, 1174, 4462, 32415, 1176, 2685, 4624, 63173, 2044, 14678, 11723, 2385, 2044, 2796, 3369, 2026, 6900, 12695, 11374, 2044, 2694, 1177, 13070, 2044, 81898, 87203, 31519, 2044, 16845, 3763, 57321, 1158, 85106, 20869, 5617, 8468, 382, 5630, 35805, 1154, 5146, 15397, 3323, 5616, 8809, 14822, 14018, 2759, 2044, 11062, 4203, 5772, 8628, 10859, 2109, 5178, 81286, 3997, 49069, 47603, 14678, 16437, 4203, 5772, 2637, 4224, 382, 4628, 11903, 28114, 2044, 2621, 15089, 5320, 12315, 35100, 11868, 382, 29011, 5187, 42484, 3778, 36375, 2109, 66978, 35100, 2109, 5178, 66201, 37190, 40154, 7827, 15089, 1154, 7530, 6647, 10535, 34661, 3323, 6706, 9651, 3929, 27849, 21325, 3530, 19193, 8636, 2166, 6109, 8628, 21875, 4030, 4656, 73631, 2166, 67814, 15089, 26403, 27283, 1158, 11752, 7136, 14339, 2044, 6662, 1155, 2624, 5526, 22541, 3132, 10880, 19122, 31017, 14111, 2685, 10969, 10482, 67195]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Az4rwU0l5ECn"},"source":["# encode text\r\n","sent_id = tokenizer.batch_encode_plus(X_train[:10], padding=True, return_token_type_ids=False)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oNRU-SH65ZEE","executionInfo":{"status":"ok","timestamp":1610510956416,"user_tz":-210,"elapsed":1393,"user":{"displayName":"mohadese rahnama","photoUrl":"","userId":"03886626379062840142"}},"outputId":"05ce4767-dd4d-42bb-88e1-569ecfe0e8d1"},"source":["sent_id"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'input_ids': [[2, 5071, 4790, 32701, 3911, 19910, 74701, 3329, 52810, 2030, 4613, 57968, 7341, 4957, 3916, 3911, 4613, 9607, 39230, 4378, 28724, 36539, 5929, 15619, 20936, 41215, 2002, 5102, 57637, 6012, 74701, 5565, 2867, 5929, 26040, 6501, 4484, 64198, 5438, 13334, 23344, 58164, 6012, 6820, 58164, 4766, 6667, 33103, 35204, 6921, 37745, 23460, 4366, 5929, 2959, 45309, 8146, 4856, 4613, 2938, 5782, 4394, 2959, 45098, 60379, 2061, 45309, 8146, 29511, 5929, 52446, 11231, 2867, 6921, 8094, 52810, 64831, 35138, 33103, 62321, 4366, 5929, 2959, 27409, 45309, 8146, 23460, 4613, 35667, 33103, 62321, 6921, 37745, 4366, 5929, 33336, 2959, 27409, 45309, 8146, 52810, 64831, 35138, 4484, 18009, 92228, 74701, 37458, 48687, 52446, 22157, 45498, 29420, 4090, 23709, 2050, 30750, 7796, 6945, 11999, 32701, 3528, 10672, 35428, 17389, 5655, 3030, 5071, 3329, 52810, 2030, 4613, 44594, 18230, 4790, 52248, 7120, 28678, 10741, 3531, 3916, 45309, 62071, 88012, 5929, 74701, 3462, 5289, 7222, 5071, 96817, 88012, 67519, 70473, 11332, 54934, 5690, 3328, 6945, 3329, 10884, 39230, 45309, 8146, 5754, 4459, 88012, 5929, 52810, 64831, 35138, 17687, 3796, 5929, 98322, 33103, 88012, 2032, 6921, 8094, 98322, 17358, 4366, 5929, 2959, 45309, 8146, 88012, 54176, 2032, 8094, 45309, 8146, 5444, 22367, 10672, 43300, 28724, 88012, 43815, 47224, 11721, 54934, 4366, 5929, 2959, 42528, 45309, 8146, 52810, 5642, 52248, 7120, 28678, 10741, 11231, 12139, 4296, 28724, 2959, 54729, 23116, 17687, 9706, 44594, 71030, 3778, 52810, 32590, 29048, 5717, 7152, 52810, 2030, 18230, 13459, 4366, 5929, 6921, 52810, 32590, 29048, 33103, 88012, 2959, 42528, 45309, 8146, 88012, 54176, 2032, 8094, 28807, 19921, 30304, 11231, 5731, 3629, 10672, 4856, 32701, 4836, 27409, 71030, 3778, 4613, 49225, 89243, 11802, 7843, 10672, 18009, 28807, 19921, 30304, 15766, 10672, 5503, 49225, 3629, 10672, 88012, 38793, 3318, 3528, 5754, 6749, 71030, 3778, 52810, 60791, 2040, 13459, 4366, 5929, 71030, 3778, 2959, 42528, 45309, 8146, 71030, 3778, 52810, 2030, 3251, 5690, 4070, 4856, 71030, 3778, 52810, 2030, 10884, 8146, 52810, 2030, 12182, 13453, 14142, 4568, 7843, 18009, 96566, 5731, 3629, 67682, 2959, 35814, 18009, 28807, 19921, 30304, 10884, 45309, 8146, 52248, 7120, 28678, 10741, 11231, 18430, 3629, 10672, 7162, 10672, 12139, 10672, 18009, 98346, 96109, 18489, 10884, 45309, 8146, 52810, 2030, 28724, 8543, 10672, 28724, 52248, 7120, 28678, 10741, 7162, 10207, 4459, 88292, 88012, 5929, 6921, 52810, 64831, 35138, 10884, 32717, 45309, 17979, 23116, 74701, 5842, 88292, 88012, 5929, 19089, 4629, 5842, 50317, 28552, 5796, 71442, 4], [2, 5071, 8456, 23639, 5929, 25625, 36108, 32088, 30765, 13870, 86836, 24091, 4209, 4957, 2959, 42528, 4713, 48212, 4089, 3475, 28552, 4957, 19791, 5891, 39298, 88184, 86836, 24091, 25625, 6552, 4175, 58164, 3521, 10602, 25625, 3780, 3329, 12035, 8387, 3841, 3475, 5224, 7178, 11231, 25625, 58164, 23639, 5929, 11231, 5232, 5929, 3191, 58164, 16958, 2795, 79566, 2011, 15615, 39298, 5891, 7765, 24578, 35088, 7223, 68981, 6839, 22338, 2816, 4158, 2805, 7579, 23639, 25625, 5224, 17687, 4241, 10672, 7164, 15407, 23639, 5929, 32701, 3852, 35088, 13443, 10130, 25554, 23639, 5484, 4366, 5929, 25625, 17802, 13113, 12702, 6945, 22367, 3083, 3404, 70724, 2003, 12139, 17802, 3642, 22367, 10672, 8152, 12702, 23639, 5596, 58164, 5939, 5929, 6777, 50980, 14878, 22394, 2061, 7796, 45498, 82343, 46718, 25625, 86836, 24091, 3528, 17420, 21503, 6310, 13443, 10130, 25554, 13113, 15307, 15611, 23639, 6820, 5754, 6917, 14745, 48212, 28817, 3229, 6921, 48212, 4274, 17420, 58164, 6921, 4366, 5929, 27989, 14599, 13113, 6945, 4366, 5929, 3528, 10672, 70724, 2003, 32701, 22367, 3083, 23639, 5929, 4942, 45309, 62071, 33192, 4179, 8340, 20208, 3419, 5929, 3329, 12035, 6921, 4366, 5929, 48212, 2959, 64856, 19327, 10672, 18781, 46158, 5350, 5929, 6492, 5929, 11231, 74701, 23157, 26604, 98637, 2033, 3419, 5929, 3329, 12035, 1876, 3064, 48212, 2867, 4360, 18781, 46158, 5350, 5929, 4089, 39298, 27989, 3191, 9567, 5929, 3852, 61145, 19994, 6312, 24003, 2805, 27989, 7106, 2867, 8417, 81884, 52810, 2030, 53895, 2032, 38793, 13334, 47489, 23169, 28552, 4957, 4241, 27989, 7098, 84506, 2805, 29121, 4366, 5929, 6537, 81884, 5929, 6575, 28552, 4957, 3952, 54570, 65740, 4816, 24843, 23639, 52810, 2030, 22821, 36649, 3647, 3929, 3821, 43481, 2008, 23639, 52810, 2030, 28552, 4957, 2959, 10514, 10884, 8076, 57941, 58164, 17687, 4482, 6917, 8094, 32458, 22821, 36649, 5806, 37400, 30387, 32538, 3903, 11231, 52810, 2030, 5929, 5754, 10207, 58164, 17687, 4482, 23639, 5929, 4942, 23639, 50145, 46614, 22367, 3083, 96291, 77626, 4735, 11231, 23639, 3469, 12702, 8417, 4766, 10884, 5954, 4957, 15305, 15305, 12101, 28552, 4957, 4062, 17521, 3475, 5839, 36189, 11231, 22930, 23180, 2867, 14114, 14829, 12139, 3640, 3910, 5929, 3640, 6173, 17687, 9258, 23116, 17476, 26029, 12453, 23639, 22930, 49722, 13654, 4209, 4957, 2959, 3083, 26029, 12453, 12702, 23639, 22930, 49722, 58164, 4905, 5929, 24954, 9258, 28302, 6173, 86836, 24091, 4482, 5071, 23639, 5929, 11904, 2938, 32701, 3852, 48476, 2816, 36711, 12139, 50715, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [2, 65312, 8478, 1457, 1393, 1460, 1392, 65312, 8478, 1460, 1393, 1457, 1392, 1455, 2034, 65312, 8478, 1462, 1393, 1462, 1392, 43428, 41740, 8596, 40506, 2077, 18481, 61527, 2041, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [2, 4900, 41086, 3351, 4172, 3381, 11424, 3318, 4485, 4900, 3948, 3432, 15186, 4900, 3948, 4179, 7879, 8179, 72591, 2793, 3689, 4238, 3916, 7602, 2967, 5929, 7154, 72591, 4449, 4900, 3640, 76537, 6604, 7154, 5929, 6914, 5929, 3432, 5939, 5929, 4209, 3432, 8872, 9060, 2871, 3145, 3404, 3432, 5939, 5929, 3625, 3634, 5725, 78884, 2783, 5939, 5929, 7882, 4586, 5929, 5725, 2793, 3188, 4449, 3270, 72591, 15826, 35425, 47607, 10197, 17989, 94808, 83327, 42629, 2032, 3211, 5817, 3521, 5725, 4900, 5484, 6429, 5939, 5939, 5929, 2959, 2793, 9933, 5939, 3376, 32270, 23921, 47308, 6825, 3381, 3630, 2793, 6414, 4639, 7129, 5823, 16020, 3027, 3145, 3905, 4639, 9913, 6262, 67486, 4238, 3531, 6951, 3561, 13191, 5725, 8179, 23921, 68115, 42985, 2048, 3470, 37039, 41627, 12454, 63493, 4484, 4188, 3439, 2844, 5117, 2938, 3221, 2793, 10941, 3361, 78884, 2783, 13038, 42703, 4449, 78884, 2783, 5973, 2930, 5929, 8204, 3561, 3632, 4463, 5973, 3171, 19319, 3474, 3952, 2867, 3270, 5725, 4386, 9310, 3821, 74489, 10871, 3733, 2867, 3473, 4247, 18586, 24201, 5929, 5042, 3525, 24201, 10307, 24201, 5108, 4980, 8349, 5140, 37142, 3364, 4459, 4247, 18586, 4108, 2793, 6414, 5484, 6429, 3926, 10023, 18586, 5850, 37039, 41627, 3270, 5101, 11002, 5983, 8097, 7971, 43624, 72591, 3280, 5399, 4872, 6637, 6825, 12330, 3310, 5939, 5929, 3432, 2871, 3145, 6378, 3661, 2910, 3504, 4912, 6198, 6724, 4449, 4900, 18275, 3201, 9324, 5426, 4002, 6189, 5154, 7843, 11802, 4247, 5469, 7273, 4002, 7173, 5426, 4002, 6189, 5154, 7843, 11802, 4247, 5469, 7273, 4002, 7173, 37620, 4884, 10755, 9258, 5929, 19911, 6596, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [2, 53615, 5224, 15407, 3521, 3916, 9825, 3810, 4160, 2904, 3073, 3444, 4924, 3521, 6542, 22201, 29808, 22686, 4816, 62030, 43059, 6022, 7065, 5834, 5929, 3521, 53615, 3043, 7285, 25029, 2793, 5655, 6429, 16477, 53615, 31792, 3916, 4394, 5929, 3251, 5071, 3287, 6012, 2938, 6629, 4139, 8369, 53615, 3640, 16004, 3000, 2811, 9622, 3521, 31041, 6012, 3835, 3347, 5733, 3521, 3916, 7443, 53615, 9706, 53615, 3786, 5524, 8369, 16477, 6734, 4139, 16477, 53615, 2793, 3689, 3251, 3640, 2793, 17355, 2015, 4532, 9585, 4139, 16477, 53615, 5785, 6012, 6629, 4139, 8369, 53615, 3364, 3439, 3475, 5839, 53615, 3444, 4449, 6095, 2959, 3171, 3145, 5209, 5455, 4244, 3821, 3435, 4449, 5302, 4386, 4449, 5209, 4900, 8052, 4639, 4816, 53615, 53615, 3828, 2793, 74489, 4449, 53615, 6378, 63432, 4639, 3525, 3905, 53615, 3828, 7580, 4605, 5725, 5522, 4485, 53615, 3521, 5929, 3114, 9825, 6748, 7580, 5725, 8246, 22880, 4449, 4394, 53615, 2003, 4347, 7688, 53615, 3521, 4175, 3780, 5020, 3475, 3810, 3310, 8872, 5455, 7276, 53615, 3280, 5076, 4089, 4816, 4367, 3905, 8707, 4909, 2938, 3211, 4394, 7078, 5418, 2910, 2867, 5418, 3404, 7670, 3100, 4981, 3966, 4394, 5102, 57637, 12512, 4394, 5655, 3390, 5717, 12512, 3640, 4394, 7502, 3966, 12512, 6839, 3640, 4394, 6137, 4001, 4316, 5040, 3100, 12512, 4394, 4084, 13294, 36465, 3531, 3927, 2867, 4482, 5399, 7212, 3475, 11176, 53615, 6542, 7919, 4816, 4394, 5929, 53615, 2003, 7934, 4394, 4084, 6501, 4394, 4995, 6206, 3422, 5929, 23763, 2793, 70933, 4394, 5842, 5596, 5094, 23639, 92809, 4816, 12218, 8417, 2910, 2867, 4995, 21250, 39298, 79757, 2783, 5054, 62346, 13459, 3329, 17012, 3475, 11176, 53615, 4001, 3486, 15615, 5094, 5929, 23639, 5929, 53615, 2003, 3100, 4981, 3419, 5929, 46558, 30466, 23460, 46227, 48212, 3329, 4373, 53615, 6947, 4856, 5520, 4995, 7014, 2938, 4394, 3280, 6012, 3347, 5733, 3521, 3916, 3381, 16477, 3640, 2959, 54074, 3966, 53615, 5369, 5145, 2793, 8096, 66823, 3810, 3494, 8369, 16477, 8204, 4383, 53615, 7152, 4394, 5929, 4360, 4909, 3211, 3966, 53615, 6672, 3625, 3318, 4459, 3229, 2793, 31149, 4394, 3521, 53615, 5040, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [2, 6506, 4712, 4565, 5929, 4428, 7254, 5574, 7043, 6506, 10783, 5506, 5206, 7332, 7648, 3873, 3469, 6506, 4712, 3665, 5929, 2959, 6168, 13883, 3475, 3329, 5929, 7164, 6545, 4565, 3541, 5929, 5042, 5054, 6506, 4712, 3329, 6259, 4006, 15407, 3469, 9321, 8246, 2793, 5655, 3469, 6506, 4712, 7502, 12158, 6907, 5929, 6506, 13533, 7060, 4683, 7649, 5929, 4656, 5988, 4905, 5929, 7670, 3625, 29082, 5223, 3329, 5929, 4663, 6160, 5407, 3287, 4778, 3169, 4869, 3768, 9730, 38930, 88706, 2959, 13394, 4603, 6712, 4778, 6802, 7316, 2793, 31149, 10132, 5407, 3287, 4241, 3329, 23211, 53967, 8357, 4454, 4883, 73527, 46634, 81397, 49349, 2039, 3179, 3553, 6506, 4712, 2844, 5797, 7001, 1455, 1393, 1458, 3700, 8108, 5473, 2904, 3073, 2844, 30791, 1462, 1393, 1462, 3700, 5493, 8973, 4066, 3205, 3329, 6259, 4321, 7670, 7014, 11748, 12132, 46567, 8457, 7456, 7670, 4816, 4390, 7332, 2838, 13375, 2838, 3475, 11176, 3329, 5929, 6545, 7753, 20638, 2938, 6506, 4712, 9859, 3639, 3625, 3971, 3927, 3310, 4992, 5929, 4981, 3329, 5929, 5407, 3287, 3280, 3983, 7273, 5574, 3088, 9713, 10287, 9321, 4274, 5929, 6076, 3625, 17048, 5757, 3661, 7755, 25548, 7401, 4497, 4472, 3088, 4348, 6506, 3945, 3911, 3911, 6404, 7152, 3945, 3911, 3777, 6029, 4820, 2013, 35065, 2003, 6506, 4712, 3211, 3052, 5929, 23180, 6506, 13533, 3911, 3280, 3027, 3145, 2793, 31149, 14792, 3434, 3376, 6506, 13533, 16917, 16764, 34151, 58212, 3280, 3318, 4924, 3475, 11176, 6259, 4875, 5929, 3329, 5929, 16917, 2032, 40176, 45671, 23180, 4723, 3475, 11176, 5311, 2793, 9868, 4834, 10937, 4778, 6802, 3640, 37990, 5076, 4175, 22930, 3911, 2867, 5929, 4980, 4788, 4875, 5929, 22930, 6917, 6552, 5859, 2793, 3689, 11107, 5934, 5582, 4778, 11014, 74978, 23180, 5929, 5754, 2867, 4207, 22930, 3318, 11107, 16917, 4206, 16917, 40176, 58964, 4247, 23180, 22930, 45671, 4303, 4905, 5929, 3531, 9938, 5929, 4175, 4274, 5929, 5861, 6506, 13533, 3521, 4383, 5929, 4980, 5311, 2793, 9868, 3280, 3911, 10755, 3945, 5929, 5506, 3469, 2910, 3521, 4383, 5929, 5574, 16477, 3789, 5783, 9408, 6907, 5929, 7878, 11384, 3329, 6506, 13533, 15720, 3100, 3475, 6506, 4712, 4875, 5929, 6783, 3625, 5077, 8359, 9007, 7060, 4683, 4411, 3171, 5929, 5506, 5929, 4411, 2959, 5392, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [2, 79317, 5929, 3329, 3972, 10953, 79317, 5896, 5929, 9227, 3928, 11809, 11742, 7440, 3329, 5102, 18421, 79317, 3047, 2793, 4564, 3927, 16069, 3598, 3329, 2938, 2844, 3972, 2793, 5655, 3927, 16069, 4554, 2844, 3944, 5781, 4788, 62735, 2844, 3378, 5071, 14313, 5929, 5020, 3329, 5929, 5020, 3927, 16069, 3351, 6258, 14313, 5929, 5100, 5323, 2904, 3939, 4370, 5929, 6095, 2959, 2793, 9933, 14313, 5676, 3329, 3927, 16069, 91722, 3620, 3088, 7440, 3329, 6325, 4977, 13809, 13216, 25643, 5754, 5140, 4613, 8963, 7764, 5000, 3351, 4224, 3972, 3280, 5653, 3640, 2844, 28140, 15233, 6428, 6428, 3385, 15407, 4014, 3972, 5891, 2793, 39316, 16417, 5929, 2844, 6734, 3821, 3168, 7690, 13248, 5158, 3944, 3640, 4788, 5100, 3927, 16069, 2844, 3944, 5100, 6650, 5757, 3789, 5783, 3940, 5100, 27285, 12179, 5100, 5597, 1044, 7291, 89216, 1038, 24839, 4205, 12376, 5114, 25136, 23687, 1026, 24839, 6471, 90653, 19324, 1043, 24219, 3465, 62197, 36456, 2040, 17395, 16799, 14320, 3280, 3792, 5659, 2910, 47684, 4713, 3789, 5783, 15723, 4196, 12266, 36132, 5100, 7478, 12266, 4238, 6429, 6839, 3473, 24810, 16650, 3736, 12822, 12822, 5781, 2844, 3944, 2793, 11543, 3125, 6180, 4790, 32573, 10153, 2938, 3777, 9719, 2793, 11543, 2867, 15490, 3280, 4825, 3625, 2793, 6150, 2844, 19987, 3789, 5783, 5100, 3521, 5100, 5653, 5929, 3850, 3280, 5358, 4630, 3521, 5929, 4386, 5690, 3328, 3287, 3280, 2844, 3972, 3469, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [2, 3500, 4060, 4259, 7358, 67913, 7834, 3821, 5398, 2013, 8707, 8900, 4207, 7358, 4816, 11080, 65925, 3186, 67913, 3625, 3573, 4801, 3286, 3521, 4383, 5224, 7358, 2930, 11080, 55355, 2006, 13222, 5342, 21308, 5680, 4139, 4884, 12675, 10357, 19209, 4825, 18571, 5929, 4219, 16047, 7358, 5094, 4207, 2793, 3689, 1876, 2949, 5484, 6429, 7753, 94425, 3841, 20411, 9497, 4207, 7358, 33962, 3251, 5369, 5690, 2881, 1876, 2949, 7358, 23073, 8757, 5524, 3573, 14273, 67913, 5574, 7043, 3205, 7358, 2959, 3171, 2822, 1876, 3035, 3852, 2793, 17355, 2015, 3500, 4060, 7358, 3205, 3091, 5929, 11457, 5929, 3205, 3625, 6542, 5929, 6909, 3525, 3205, 9508, 5929, 9255, 7010, 5200, 4157, 23073, 7358, 14335, 5929, 3151, 3145, 23120, 36537, 18903, 84081, 25837, 3205, 7358, 4735, 38611, 3205, 20424, 4207, 5929, 9111, 4816, 4360, 14686, 3318, 3205, 7358, 2044, 7510, 5574, 7043, 11827, 6937, 16945, 6921, 65745, 4497, 7843, 4390, 3205, 3500, 7214, 11384, 79249, 5596, 3521, 72642, 4321, 3205, 5770, 2793, 31149, 5524, 7358, 2044, 11817, 5891, 4246, 5891, 4246, 32717, 3521, 6676, 12944, 9545, 6201, 67948, 7214, 6029, 7843, 17914, 21396, 6075, 17914, 19209, 3229, 6917, 67509, 5785, 4497, 4482, 7358, 3205, 32717, 94425, 5311, 42375, 12675, 4565, 10357, 7358, 7510, 94425, 16945, 17914, 6921, 91942, 4497, 7843, 4321, 5596, 3500, 4426, 12675, 10357, 5655, 3290, 1876, 12675, 10357, 7358, 5596, 94425, 3499, 39230, 7843, 17914, 11384, 3528, 4305, 5929, 19209, 4209, 2959, 5596, 5596, 94425, 2793, 31149, 12675, 18571, 5929, 7358, 3205, 7173, 7164, 15407, 18571, 5929, 7358, 2793, 31149, 19209, 70122, 1876, 2965, 7510, 94425, 4497, 16945, 6921, 91942, 7843, 4280, 5596, 3500, 1876, 2965, 3559, 12958, 5596, 7843, 17914, 19209, 4482, 5655, 3328, 18430, 65819, 2032, 14233, 4241, 3318, 5596, 5596, 2793, 31149, 7494, 5929, 11827, 13854, 60976, 7173, 55159, 37643, 1461, 5028, 65517, 8596, 5071, 3211, 2959, 3296, 10061, 3598, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [2, 14322, 23772, 2991, 5929, 9655, 29257, 3419, 5929, 3329, 12035, 13229, 11987, 22614, 5929, 6492, 5929, 6362, 3310, 6506, 3419, 2793, 17355, 2015, 3419, 3419, 11999, 5929, 3419, 15024, 3795, 3972, 6815, 11999, 7440, 4766, 5929, 8398, 17031, 3911, 2867, 3419, 5224, 15407, 29257, 3419, 3329, 12035, 3810, 3052, 5929, 4484, 5929, 3419, 5819, 3419, 3329, 17012, 3229, 9258, 45147, 3346, 3919, 7494, 5929, 6166, 6545, 20553, 2881, 3795, 3419, 3795, 4900, 9963, 7494, 5929, 14369, 11107, 3419, 4113, 48212, 6163, 3419, 5929, 3329, 12035, 6506, 14322, 23772, 5086, 3218, 1442, 11883, 6198, 4935, 4461, 1442, 3419, 6429, 4183, 1035, 64606, 2048, 53076, 3419, 6506, 4613, 11373, 2922, 9678, 5929, 3419, 5929, 3329, 12035, 3329, 12035, 2867, 10871, 5161, 10260, 16253, 3768, 5526, 3329, 4373, 14322, 23772, 3052, 3777, 7525, 3329, 4373, 3329, 4373, 14322, 23772, 21250, 5175, 5966, 10622, 5161, 11710, 5929, 3768, 5526, 3329, 17012, 7924, 5001, 74701, 11987, 22614, 14322, 23772, 10968, 3475, 45147, 86365, 14322, 23772, 3329, 12035, 9258, 3795, 3419, 21457, 3841, 9811, 5929, 11324, 11999, 8223, 30078, 8505, 6492, 14322, 23772, 32580, 18481, 23000, 3114, 3318, 3795, 3419, 4394, 10595, 7273, 8505, 3280, 4394, 22056, 10822, 23122, 28938, 61319, 91584, 66580, 9977, 11999, 7551, 11757, 5082, 7179, 3795, 3057, 10153, 2938, 13713, 14322, 23772, 14829, 12958, 3057, 3494, 3795, 62755, 14322, 23772, 3057, 48650, 7899, 33911, 2040, 3057, 5413, 4049, 17358, 3795, 48212, 62755, 46227, 2043, 13874, 8223, 12369, 17358, 4875, 5929, 7333, 5929, 9367, 4875, 53615, 28933, 2846, 4988, 20922, 8223, 13874, 3280, 9678, 5929, 5524, 6132, 3504, 4394, 13874, 2910, 5929, 3114, 3331, 13543, 52046, 22631, 30361, 59894, 1, 1044, 80971, 30784, 20845, 26018, 79061, 12907, 1, 1044, 80971, 68034, 21857, 23376, 54912, 93648, 54934, 1, 1044, 80971, 68034, 21857, 23376, 28654, 48774, 95380, 2025, 1, 1044, 80971, 68034, 21857, 23376, 4384, 69010, 3795, 11408, 6506, 3419, 3329, 12035, 14322, 23772, 4411, 3088, 6865, 3088, 8751, 3419, 3494, 24664, 4394, 5574, 7043, 5929, 3052, 5929, 3361, 3928, 3552, 14322, 23772, 4219, 6378, 3419, 3329, 12035, 30687, 3201, 3463, 6012, 3280, 7578, 6506, 14322, 23772, 4868, 6575, 4997, 7560, 14322, 23772, 7171, 5392, 43030, 57345, 18172, 21849, 3106, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [2, 3434, 5929, 6386, 5929, 4431, 9450, 7563, 3426, 3665, 5929, 5042, 4908, 44821, 5929, 6386, 5929, 17539, 3777, 5757, 6177, 3469, 13200, 2905, 5929, 6386, 2973, 3191, 3148, 5929, 3535, 13200, 2905, 7563, 3052, 8523, 4790, 3535, 13200, 2905, 6386, 7563, 3384, 3535, 13200, 2905, 6804, 6917, 5676, 5071, 4394, 53839, 22999, 4790, 3640, 13200, 2905, 6804, 7563, 8369, 14280, 3287, 3929, 21276, 7026, 2867, 7563, 19645, 4863, 6545, 3528, 9916, 2793, 3201, 6386, 3434, 17539, 14020, 5016, 3434, 5929, 6386, 5929, 17539, 6804, 4855, 36019, 4816, 5442, 7563, 7333, 2904, 3073, 6500, 6386, 3434, 17539, 25599, 3535, 13200, 2905, 45585, 5101, 4157, 13200, 2905, 6949, 6386, 5929, 4179, 32717, 4909, 70122, 3535, 13200, 2905, 6804, 7563, 11568, 7563, 7532, 4108, 3191, 13200, 2905, 5929, 6804, 6386, 17539, 8369, 3287, 8369, 13200, 2905, 5929, 4727, 3318, 3251, 8369, 3535, 13200, 2905, 6804, 5369, 5690, 3328, 44821, 6386, 3569, 4080, 5042, 7563, 3426, 6429, 13200, 43184, 2003, 6269, 4418, 13200, 2905, 5929, 5850, 3535, 4080, 10217, 3625, 5351, 8122, 3535, 13200, 2905, 5929, 30197, 19338, 6386, 5929, 10151, 13200, 2905, 5929, 19338, 3535, 3821, 3168, 3680, 14979, 3287, 9861, 3390, 13200, 2905, 5929, 4997, 5929, 6386, 5589, 6810, 5972, 9871, 13200, 2905, 5929, 6386, 32717, 3535, 13200, 2905, 7563, 6804, 6386, 5929, 5850, 5670, 3444, 6386, 17539, 4605, 3885, 3541, 5929, 6380, 3088, 3191, 13200, 2905, 5929, 6386, 17539, 3384, 9871, 13200, 2905, 6386, 5929, 3885, 6386, 4912, 3426, 13101, 4912, 4816, 7563, 6804, 3191, 13200, 2905, 11416, 3535, 13200, 2905, 8755, 7563, 20412, 3955, 6386, 5929, 6106, 6386, 5929, 6106, 5351, 3504, 18850, 2003, 4241, 6839, 7443, 4219, 4183, 6386, 17539, 3569, 4968, 4891, 3426, 13200, 43184, 2003, 5850, 4181, 17019, 36132, 5781, 10538, 6386, 4400, 2871, 3145, 5458, 5670, 4001, 3535, 13200, 2905, 6804, 3541, 5929, 5178, 18275, 5700, 6804, 6386, 2871, 3145, 44821, 4296, 4299, 6771, 6839, 13200, 2905, 5929, 6804, 4296, 16428, 3229, 15352, 5850, 4997, 5929, 6386, 3384, 3271, 96094, 6386, 12126, 5739, 3905, 2793, 31149, 6839, 13200, 2905, 5929, 6386, 3191, 4296, 6386, 3535, 13200, 2905, 7563, 3541, 5929, 5042, 4108, 3535, 13200, 2905, 6804, 3541, 5929, 3191, 13200, 2905, 6386, 5929, 17539, 6386, 3569, 4080, 7563, 3426, 5850, 13200, 43184, 2003, 6804, 6386, 5929, 17539, 9871, 4296, 6386, 4062, 3088, 16477, 3535, 13200, 2905, 6804, 4001, 3541, 5929, 3364, 4, 0, 0, 0, 0, 0, 0]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]]}"]},"metadata":{"tags":[]},"execution_count":12}]},{"cell_type":"code","metadata":{"id":"uF3FFsPzc6zD","executionInfo":{"status":"ok","timestamp":1610645915714,"user_tz":-210,"elapsed":8458,"user":{"displayName":"mohadese rahnama","photoUrl":"","userId":"03886626379062840142"}}},"source":["sentence_maxlen=128"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"4m2Qc2IkrnEp","executionInfo":{"status":"ok","timestamp":1610646017362,"user_tz":-210,"elapsed":109432,"user":{"displayName":"mohadese rahnama","photoUrl":"","userId":"03886626379062840142"}}},"source":["##Tokenize training and validation sentences:\r\n","train_encodings = tokenizer.batch_encode_plus(X_train,\r\n","    max_length = sentence_maxlen,\r\n","    pad_to_max_length=True,\r\n","    truncation=True,\r\n","    return_token_type_ids=False)\r\n","\r\n","val_encodings = tokenizer.batch_encode_plus(X_val,\r\n","    max_length = sentence_maxlen,\r\n","    pad_to_max_length=True,\r\n","    truncation=True,\r\n","    return_token_type_ids=False)\r\n","\r\n","test_encodings=tokenizer.batch_encode_plus(X_test,\r\n","    max_length = sentence_maxlen,\r\n","    pad_to_max_length=True,\r\n","    truncation=True,\r\n","    return_token_type_ids=False)"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IwjkXARbetX-","executionInfo":{"status":"ok","timestamp":1610510986454,"user_tz":-210,"elapsed":17675,"user":{"displayName":"mohadese rahnama","photoUrl":"","userId":"03886626379062840142"}},"outputId":"7a0d4997-5314-453f-c7f0-48412a1b987b"},"source":["train_encodings[0]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Encoding(num_tokens=128, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing])"]},"metadata":{"tags":[]},"execution_count":15}]},{"cell_type":"code","metadata":{"id":"-iCp2PUEupYK","executionInfo":{"status":"ok","timestamp":1610646017373,"user_tz":-210,"elapsed":106990,"user":{"displayName":"mohadese rahnama","photoUrl":"","userId":"03886626379062840142"}}},"source":["import torch\r\n","import torch.nn as nn\r\n","\r\n","# for train set\r\n","train_seq = torch.tensor(train_encodings['input_ids'])\r\n","train_mask = torch.tensor(train_encodings['attention_mask'])\r\n","train_y = torch.tensor(y_train)\r\n","\r\n","# for validation set\r\n","val_seq = torch.tensor(val_encodings['input_ids'])\r\n","val_mask = torch.tensor(val_encodings['attention_mask'])\r\n","val_y = torch.tensor(y_val)\r\n","\r\n","# for test set\r\n","test_seq = torch.tensor(test_encodings['input_ids'])\r\n","test_mask = torch.tensor(test_encodings['attention_mask'])\r\n","test_y = torch.tensor(y_test)"],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"h0JkQbxVBmbM","executionInfo":{"status":"ok","timestamp":1610510996763,"user_tz":-210,"elapsed":1015,"user":{"displayName":"mohadese rahnama","photoUrl":"","userId":"03886626379062840142"}},"outputId":"b828bf2e-a36b-47c9-cf44-90296e85c7ac"},"source":["train_y[0]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n","        0, 0, 0, 0, 0, 0])"]},"metadata":{"tags":[]},"execution_count":17}]},{"cell_type":"code","metadata":{"id":"T2xiV6Nb0ddZ","executionInfo":{"status":"ok","timestamp":1610646017376,"user_tz":-210,"elapsed":103419,"user":{"displayName":"mohadese rahnama","photoUrl":"","userId":"03886626379062840142"}}},"source":["from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\r\n","\r\n","#define a batch size\r\n","batch_size = 32\r\n","\r\n","# wrap tensors\r\n","train_data = TensorDataset(train_seq, train_mask, train_y)\r\n","\r\n","# sampler for sampling the data during training\r\n","train_sampler = RandomSampler(train_data)\r\n","\r\n","# dataLoader for train set\r\n","train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\r\n","\r\n","# wrap tensors\r\n","val_data = TensorDataset(val_seq, val_mask, val_y)\r\n","\r\n","# sampler for sampling the data during training\r\n","val_sampler = SequentialSampler(val_data)\r\n","\r\n","# dataLoader for validation set\r\n","val_dataloader = DataLoader(val_data, sampler = val_sampler, batch_size=batch_size)\r\n","\r\n","# wrap tensors\r\n","test_data = TensorDataset(test_seq, test_mask, test_y)\r\n","\r\n","# sampler for sampling the data during training\r\n","test_sampler = SequentialSampler(test_data)\r\n","\r\n","# dataLoader for validation set\r\n","test_dataloader = DataLoader(test_data, sampler = test_sampler, batch_size=batch_size)"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":284},"id":"UwGHXIjGfmaN","executionInfo":{"status":"error","timestamp":1610640254285,"user_tz":-210,"elapsed":1080,"user":{"displayName":"mohadese rahnama","photoUrl":"","userId":"03886626379062840142"}},"outputId":"94929825-5aad-485c-8353-082b33d83cda"},"source":["# example\r\n","\r\n","\r\n","text = [\"this is a bert model tutorial\", \"we will fine-tune a bert model\"]\r\n","\r\n","# encode text\r\n","sent_id = tokenizer.batch_encode_plus(text, padding=True, return_token_type_ids=False)\r\n","print(sent_id)\r\n","\r\n","seq = torch.tensor(sent_id['input_ids'])\r\n","mask = torch.tensor(sent_id['attention_mask'])\r\n","train_y = torch.tensor([0,1])\r\n","\r\n","transformer_model = AutoModel.from_pretrained(\"bert-base-multilingual-cased\")\r\n","cls_hs=transformer_model(seq,mask)\r\n","print(cls_hs)\r\n","print(cls_hs[0])\r\n","print(cls_hs[1])\r\n","print(cls_hs[1].shape)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["{'input_ids': [[101, 10531, 10124, 169, 10347, 10976, 13192, 69635, 34108, 102], [101, 11951, 11337, 13435, 118, 91695, 169, 10347, 10976, 13192, 102]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}\n"],"name":"stdout"},{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-16-bed8945474be>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msent_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mseq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msent_id\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'input_ids'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msent_id\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'attention_mask'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mtrain_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: expected sequence of length 10 at dim 1 (got 11)"]}]},{"cell_type":"markdown","metadata":{"id":"ByUEn_v4zknn"},"source":["## Model"]},{"cell_type":"code","metadata":{"id":"n3AjEaHcEMfb","colab":{"base_uri":"https://localhost:8080/","height":67,"referenced_widgets":["d75d5f7418f04f1da7da9fb7f4c3e171","bc26bd67db1c44978a1f242d1480d7a8","c07bc7bfe83b490baa5ebc330714fa9f","30367e4653cc4c6086d7c9258921c39b","7e556e759fa04591a4efc9c4e317084b","002e2eb8a0ad4443805e2751d3d0aeab","f85d437a0ebc46a48eefaab29dd47851","037f4616524041c8bc94abde97f7ee2e"]},"executionInfo":{"status":"ok","timestamp":1610646038878,"user_tz":-210,"elapsed":120795,"user":{"displayName":"mohadese rahnama","photoUrl":"","userId":"03886626379062840142"}},"outputId":"098305da-9868-4631-ef5f-a1c6684fa8c1"},"source":["transformer_model = AutoModel.from_pretrained(\"bert-base-multilingual-cased\")"],"execution_count":14,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d75d5f7418f04f1da7da9fb7f4c3e171","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=714314041.0, style=ProgressStyle(descri…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"RaAlYydhxPTd","executionInfo":{"status":"ok","timestamp":1610646038888,"user_tz":-210,"elapsed":119294,"user":{"displayName":"mohadese rahnama","photoUrl":"","userId":"03886626379062840142"}}},"source":["# freeze all the parameters\r\n","for param in transformer_model.parameters():\r\n","    param.requires_grad = False"],"execution_count":15,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nUa1R1WQONe6","executionInfo":{"status":"ok","timestamp":1610640335871,"user_tz":-210,"elapsed":1082,"user":{"displayName":"mohadese rahnama","photoUrl":"","userId":"03886626379062840142"}},"outputId":"dfd09fa7-fdbd-4a09-d5b2-f8ac2bf7132e"},"source":["len(labels)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["78"]},"metadata":{"tags":[]},"execution_count":20}]},{"cell_type":"code","metadata":{"id":"oyE_ThEms5aZ","executionInfo":{"status":"ok","timestamp":1610647899427,"user_tz":-210,"elapsed":972,"user":{"displayName":"mohadese rahnama","photoUrl":"","userId":"03886626379062840142"}}},"source":["class BERT_Arch(nn.Module):\r\n","\r\n","    def __init__(self, bert):\r\n","      \r\n","      super(BERT_Arch, self).__init__()\r\n","\r\n","      self.bert = bert \r\n","      \r\n","      # dropout layer\r\n","      self.dropout = nn.Dropout(0.1)\r\n","      \r\n","      # relu activation function\r\n","      self.relu =  nn.ReLU()\r\n","\r\n","      # dense layer 1\r\n","      self.fc1 = nn.Linear(768,512)\r\n","      \r\n","      # dense layer 2 (Output layer)\r\n","      self.fc2 = nn.Linear(512,78)\r\n","\r\n","\r\n","      #sigmoid activation function\r\n","      self.sigmoid = nn.Sigmoid()\r\n","\r\n","    #define the forward pass\r\n","    def forward(self, sent_id, mask):\r\n","\r\n","      #pass the inputs to the model  \r\n","      cls_hs = self.bert(sent_id, attention_mask=mask)\r\n","      \r\n","      x = self.fc1(cls_hs[1])\r\n","\r\n","      x = self.relu(x)\r\n","\r\n","      x = self.dropout(x)\r\n","\r\n","      # output layer\r\n","      x = self.fc2(x)\r\n","      \r\n","      # apply sigmoid activation\r\n","      x = self.sigmoid(x)\r\n","\r\n","      return x"],"execution_count":26,"outputs":[]},{"cell_type":"code","metadata":{"id":"rDuHzo96z6z8","executionInfo":{"status":"ok","timestamp":1610647902439,"user_tz":-210,"elapsed":999,"user":{"displayName":"mohadese rahnama","photoUrl":"","userId":"03886626379062840142"}}},"source":["# pass the pre-trained BERT to our define architecture\n","model = BERT_Arch(transformer_model)\n","\n","# push the model to GPU\n","model = model.to(device)"],"execution_count":27,"outputs":[]},{"cell_type":"code","metadata":{"id":"FUNSLBYcLc9q","executionInfo":{"status":"ok","timestamp":1610647904315,"user_tz":-210,"elapsed":1351,"user":{"displayName":"mohadese rahnama","photoUrl":"","userId":"03886626379062840142"}}},"source":["# optimizer from hugging face transformers\n","from transformers import AdamW\n","\n","# optimizer = AdamW(model.parameters(), lr = 1e-3)\n","optimizer = torch.optim.SGD(model.parameters(), lr=5e-3)"],"execution_count":28,"outputs":[]},{"cell_type":"code","metadata":{"id":"ArHmwhh7JrZh","executionInfo":{"status":"ok","timestamp":1610647905879,"user_tz":-210,"elapsed":1535,"user":{"displayName":"mohadese rahnama","photoUrl":"","userId":"03886626379062840142"}}},"source":["loss_func =nn.MultiLabelSoftMarginLoss()"],"execution_count":29,"outputs":[]},{"cell_type":"code","metadata":{"id":"c8LjQyDXs0bG","executionInfo":{"status":"ok","timestamp":1610647906258,"user_tz":-210,"elapsed":1125,"user":{"displayName":"mohadese rahnama","photoUrl":"","userId":"03886626379062840142"}}},"source":["# function to train the model\r\n","def train():\r\n","  \r\n","  model.train()\r\n","\r\n","  total_loss, total_accuracy = 0, 0\r\n","  \r\n","  # empty list to save model predictions\r\n","  total_preds=[]\r\n","  \r\n","  # iterate over batches\r\n","  for step,batch in enumerate(train_dataloader):\r\n","    \r\n","    # progress update after every 50 batches.\r\n","    if step % 50 == 0 and not step == 0:\r\n","      print('  Batch {:>5,}  of  {:>5,}.'.format(step, len(train_dataloader)))\r\n","\r\n","    # push the batch to gpu\r\n","    batch = [r.to(device) for r in batch]\r\n"," \r\n","    sent_id, mask, labels = batch\r\n","\r\n","    # clear previously calculated gradients \r\n","    model.zero_grad()        \r\n","\r\n","    # get model predictions for the current batch\r\n","    preds = model(sent_id, mask)\r\n","\r\n","    # compute the loss between actual and predicted values\r\n","    \r\n","    loss = loss_func(preds, labels)\r\n","    # add on to the total loss\r\n","    total_loss = total_loss + loss.item()\r\n","\r\n","    # backward pass to calculate the gradients\r\n","    loss.backward()\r\n","\r\n","    # clip the the gradients to 1.0. It helps in preventing the exploding gradient problem\r\n","    torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\r\n","\r\n","    # update parameters\r\n","    optimizer.step()\r\n","\r\n","    # model predictions are stored on GPU. So, push it to CPU\r\n","    preds=preds.detach().cpu().numpy()\r\n","\r\n","    # append the model predictions\r\n","    total_preds.append(preds)\r\n","\r\n","  # compute the training loss of the epoch\r\n","  avg_loss = total_loss / len(train_dataloader)\r\n","  \r\n","  # predictions are in the form of (no. of batches, size of batch, no. of classes).\r\n","  # reshape the predictions in form of (number of samples, no. of classes)\r\n","  total_preds  = numpy.concatenate(total_preds, axis=0)\r\n","\r\n","  #returns the loss and predictions\r\n","  return avg_loss, total_preds"],"execution_count":30,"outputs":[]},{"cell_type":"code","metadata":{"id":"XNBRQo9WMHey","executionInfo":{"status":"ok","timestamp":1610647910113,"user_tz":-210,"elapsed":1231,"user":{"displayName":"mohadese rahnama","photoUrl":"","userId":"03886626379062840142"}}},"source":["# function for evaluating the model\r\n","def evaluate():\r\n","  \r\n","  print(\"\\nEvaluating...\")\r\n","  \r\n","  # deactivate dropout layers\r\n","  model.eval()\r\n","\r\n","  total_loss, total_accuracy = 0, 0\r\n","  \r\n","  # empty list to save the model predictions\r\n","  total_preds = []\r\n","\r\n","  # iterate over batches\r\n","  for step,batch in enumerate(val_dataloader):\r\n","    \r\n","    # Progress update every 50 batches.\r\n","    if step % 50 == 0 and not step == 0:\r\n","      \r\n","      # Calculate elapsed time in minutes.\r\n","      # elapsed = format_time(time.time() - t0)\r\n","            \r\n","      # Report progress.\r\n","      print('  Batch {:>5,}  of  {:>5,}.'.format(step, len(val_dataloader)))\r\n","\r\n","    # push the batch to gpu\r\n","    batch = [t.to(device) for t in batch]\r\n","\r\n","    sent_id, mask, labels = batch\r\n","\r\n","    # deactivate autograd\r\n","    with torch.no_grad():\r\n","      \r\n","      # model predictions\r\n","      preds = model(sent_id, mask)\r\n","\r\n","      # compute the validation loss between actual and predicted values\r\n","      loss = loss_func(preds,labels)\r\n","\r\n","      total_loss = total_loss + loss.item()\r\n","\r\n","      preds = preds.detach().cpu().numpy()\r\n","\r\n","      total_preds.append(preds)\r\n","\r\n","  # compute the validation loss of the epoch\r\n","  avg_loss = total_loss / len(val_dataloader) \r\n","\r\n","  # reshape the predictions in form of (number of samples, no. of classes)\r\n","  total_preds  = numpy.concatenate(total_preds, axis=0)\r\n","\r\n","  return avg_loss, total_preds"],"execution_count":31,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Qu5pfrJKtTc0","executionInfo":{"status":"ok","timestamp":1610649230264,"user_tz":-210,"elapsed":1318272,"user":{"displayName":"mohadese rahnama","photoUrl":"","userId":"03886626379062840142"}},"outputId":"e2266099-4363-4797-ec3d-67739343d3f4"},"source":["# number of training epochs\r\n","epochs = 10\r\n","\r\n","# set initial loss to infinite\r\n","best_valid_loss = float('inf')\r\n","\r\n","# empty lists to store training and validation loss of each epoch\r\n","train_losses=[]\r\n","valid_losses=[]\r\n","\r\n","#for each epoch\r\n","for epoch in range(epochs):\r\n","     \r\n","    print('\\n Epoch {:} / {:}'.format(epoch + 1, epochs))\r\n","    \r\n","    #train model\r\n","    train_loss, _ = train()\r\n","    \r\n","    #evaluate model\r\n","    valid_loss, _ = evaluate()\r\n","    \r\n","    #save the best model\r\n","    if valid_loss < best_valid_loss:\r\n","        best_valid_loss = valid_loss\r\n","        torch.save(model.state_dict(), 'saved_weights_multi.pt')\r\n","    \r\n","    # append training and validation loss\r\n","    train_losses.append(train_loss)\r\n","    valid_losses.append(valid_loss)\r\n","    \r\n","    print(f'\\nTraining Loss: {train_loss:.3f}')\r\n","    print(f'Validation Loss: {valid_loss:.3f}')"],"execution_count":32,"outputs":[{"output_type":"stream","text":["\n"," Epoch 1 / 10\n","  Batch    50  of    403.\n","  Batch   100  of    403.\n","  Batch   150  of    403.\n","  Batch   200  of    403.\n","  Batch   250  of    403.\n","  Batch   300  of    403.\n","  Batch   350  of    403.\n","  Batch   400  of    403.\n","\n","Evaluating...\n","  Batch    50  of    135.\n","  Batch   100  of    135.\n","\n","Training Loss: 0.962\n","Validation Loss: 0.961\n","\n"," Epoch 2 / 10\n","  Batch    50  of    403.\n","  Batch   100  of    403.\n","  Batch   150  of    403.\n","  Batch   200  of    403.\n","  Batch   250  of    403.\n","  Batch   300  of    403.\n","  Batch   350  of    403.\n","  Batch   400  of    403.\n","\n","Evaluating...\n","  Batch    50  of    135.\n","  Batch   100  of    135.\n","\n","Training Loss: 0.961\n","Validation Loss: 0.960\n","\n"," Epoch 3 / 10\n","  Batch    50  of    403.\n","  Batch   100  of    403.\n","  Batch   150  of    403.\n","  Batch   200  of    403.\n","  Batch   250  of    403.\n","  Batch   300  of    403.\n","  Batch   350  of    403.\n","  Batch   400  of    403.\n","\n","Evaluating...\n","  Batch    50  of    135.\n","  Batch   100  of    135.\n","\n","Training Loss: 0.960\n","Validation Loss: 0.959\n","\n"," Epoch 4 / 10\n","  Batch    50  of    403.\n","  Batch   100  of    403.\n","  Batch   150  of    403.\n","  Batch   200  of    403.\n","  Batch   250  of    403.\n","  Batch   300  of    403.\n","  Batch   350  of    403.\n","  Batch   400  of    403.\n","\n","Evaluating...\n","  Batch    50  of    135.\n","  Batch   100  of    135.\n","\n","Training Loss: 0.959\n","Validation Loss: 0.958\n","\n"," Epoch 5 / 10\n","  Batch    50  of    403.\n","  Batch   100  of    403.\n","  Batch   150  of    403.\n","  Batch   200  of    403.\n","  Batch   250  of    403.\n","  Batch   300  of    403.\n","  Batch   350  of    403.\n","  Batch   400  of    403.\n","\n","Evaluating...\n","  Batch    50  of    135.\n","  Batch   100  of    135.\n","\n","Training Loss: 0.958\n","Validation Loss: 0.958\n","\n"," Epoch 6 / 10\n","  Batch    50  of    403.\n","  Batch   100  of    403.\n","  Batch   150  of    403.\n","  Batch   200  of    403.\n","  Batch   250  of    403.\n","  Batch   300  of    403.\n","  Batch   350  of    403.\n","  Batch   400  of    403.\n","\n","Evaluating...\n","  Batch    50  of    135.\n","  Batch   100  of    135.\n","\n","Training Loss: 0.957\n","Validation Loss: 0.957\n","\n"," Epoch 7 / 10\n","  Batch    50  of    403.\n","  Batch   100  of    403.\n","  Batch   150  of    403.\n","  Batch   200  of    403.\n","  Batch   250  of    403.\n","  Batch   300  of    403.\n","  Batch   350  of    403.\n","  Batch   400  of    403.\n","\n","Evaluating...\n","  Batch    50  of    135.\n","  Batch   100  of    135.\n","\n","Training Loss: 0.957\n","Validation Loss: 0.956\n","\n"," Epoch 8 / 10\n","  Batch    50  of    403.\n","  Batch   100  of    403.\n","  Batch   150  of    403.\n","  Batch   200  of    403.\n","  Batch   250  of    403.\n","  Batch   300  of    403.\n","  Batch   350  of    403.\n","  Batch   400  of    403.\n","\n","Evaluating...\n","  Batch    50  of    135.\n","  Batch   100  of    135.\n","\n","Training Loss: 0.956\n","Validation Loss: 0.955\n","\n"," Epoch 9 / 10\n","  Batch    50  of    403.\n","  Batch   100  of    403.\n","  Batch   150  of    403.\n","  Batch   200  of    403.\n","  Batch   250  of    403.\n","  Batch   300  of    403.\n","  Batch   350  of    403.\n","  Batch   400  of    403.\n","\n","Evaluating...\n","  Batch    50  of    135.\n","  Batch   100  of    135.\n","\n","Training Loss: 0.955\n","Validation Loss: 0.954\n","\n"," Epoch 10 / 10\n","  Batch    50  of    403.\n","  Batch   100  of    403.\n","  Batch   150  of    403.\n","  Batch   200  of    403.\n","  Batch   250  of    403.\n","  Batch   300  of    403.\n","  Batch   350  of    403.\n","  Batch   400  of    403.\n","\n","Evaluating...\n","  Batch    50  of    135.\n","  Batch   100  of    135.\n","\n","Training Loss: 0.954\n","Validation Loss: 0.953\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"cQ2_aS0zCLvp"},"source":["Loading saved model:"]},{"cell_type":"code","metadata":{"id":"cvR-FhPpuLkR"},"source":["# torch.cuda.empty_cache()\r\n","# pass the pre-trained BERT to our define architecture\r\n","model = BERT_Arch(transformer_model)\r\n","\r\n","# push the model to GPU\r\n","model = model.to(device)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3aOPRZ2jVvNR","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1610509380028,"user_tz":-210,"elapsed":4470,"user":{"displayName":"mohadese rahnama","photoUrl":"","userId":"03886626379062840142"}},"outputId":"8b608ad9-767d-4856-fcbe-443cc3ea4356"},"source":["#load weights of best model\r\n","path = 'saved_weights.pt'\r\n","model.load_state_dict(torch.load(path))"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<All keys matched successfully>"]},"metadata":{"tags":[]},"execution_count":18}]},{"cell_type":"markdown","metadata":{"id":"PM1uUcZFCPVg"},"source":["After loading model:"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XZhHObMnzuws","executionInfo":{"status":"ok","timestamp":1610650237072,"user_tz":-210,"elapsed":33578,"user":{"displayName":"mohadese rahnama","photoUrl":"","userId":"03886626379062840142"}},"outputId":"b2bb8f54-63ee-4c96-b51e-e4473540447f"},"source":["y_pred=[]\r\n","y_true=[]\r\n","for step,batch in enumerate(test_dataloader):\r\n","    \r\n","    # Progress update every 50 batches.\r\n","    if step % 50 == 0 and not step == 0:\r\n","      \r\n","      # Calculate elapsed time in minutes.\r\n","      # elapsed = format_time(time.time() - t0)\r\n","            \r\n","      # Report progress.\r\n","      print('  Batch {:>5,}  of  {:>5,}.'.format(step, len(test_dataloader)))\r\n","\r\n","    # push the batch to gpu\r\n","    batch = [t.to(device) for t in batch]\r\n","\r\n","    sent_id, mask, labels = batch\r\n","\r\n","    # deactivate autograd\r\n","    with torch.no_grad():\r\n","      \r\n","      # model predictions\r\n","      preds = model(sent_id, mask)\r\n","      # print(preds)\r\n","      # print(preds.cpu().numpy())\r\n","      preds = preds.cpu().numpy()\r\n","      # model's performance\r\n","    # preds = numpy.argmax(preds, axis = 1)\r\n","    \r\n","    measure = numpy.mean(preds[0]) + 1.15*numpy.sqrt(numpy.var(preds[0]))\r\n","    for l in preds:\r\n","      temp=[]\r\n","      for value in l:\r\n","        if value >= measure:\r\n","          temp.append(1)\r\n","        else:\r\n","          temp.append(0)\r\n","      y_pred.append(temp)\r\n","    y_true.extend(labels.cpu().numpy())\r\n","    # print(labels.cpu().numpy()[0], preds[0])\r\n","print(classification_report(y_true, y_pred))"],"execution_count":33,"outputs":[{"output_type":"stream","text":["  Batch    50  of    135.\n","  Batch   100  of    135.\n","              precision    recall  f1-score   support\n","\n","           0       0.00      0.00      0.00       118\n","           1       0.00      0.00      0.00       167\n","           2       0.00      0.00      0.00       162\n","           3       0.00      0.00      0.00        15\n","           4       0.00      0.00      0.00        80\n","           5       0.00      0.00      0.00        10\n","           6       0.00      0.00      0.00       160\n","           7       0.00      0.00      0.00        51\n","           8       0.00      0.00      0.00        27\n","           9       0.00      0.00      0.00       108\n","          10       0.00      0.00      0.00       146\n","          11       0.00      0.00      0.00        84\n","          12       0.00      0.00      0.00       154\n","          13       0.00      0.00      0.00        20\n","          14       0.00      0.00      0.00        18\n","          15       0.00      0.00      0.00       147\n","          16       0.00      0.00      0.00       139\n","          17       0.00      0.00      0.00       149\n","          18       0.02      1.00      0.05       106\n","          19       0.00      0.00      0.00        76\n","          20       0.00      0.00      0.00       127\n","          21       0.00      0.00      0.00       137\n","          22       0.01      1.00      0.02        39\n","          23       0.03      0.69      0.06       137\n","          24       0.00      0.00      0.00        75\n","          25       0.04      1.00      0.07       158\n","          26       0.00      0.00      0.00       152\n","          27       0.03      0.84      0.06       137\n","          28       0.00      0.00      0.00       136\n","          29       0.00      0.00      0.00       103\n","          30       0.00      0.00      0.00        64\n","          31       0.00      0.00      0.00        73\n","          32       0.00      0.00      0.00       136\n","          33       0.00      0.00      0.00       155\n","          34       0.02      1.00      0.03        73\n","          35       0.00      0.00      0.00       156\n","          36       0.00      0.00      0.00       140\n","          37       0.02      0.99      0.03        67\n","          38       0.00      0.00      0.00        46\n","          39       0.00      0.00      0.00        26\n","          40       0.00      0.00      0.00       148\n","          41       0.00      0.00      0.00       105\n","          42       0.00      0.00      0.00        78\n","          43       0.00      0.00      0.00       155\n","          44       0.00      0.00      0.00       154\n","          45       0.00      0.00      0.00        23\n","          46       0.00      0.00      0.00        38\n","          47       0.00      0.00      0.00       137\n","          48       0.04      1.00      0.07       151\n","          49       0.00      0.00      0.00        73\n","          50       0.00      0.00      0.00        25\n","          51       0.00      0.00      0.00        24\n","          52       0.00      0.00      0.00        43\n","          53       0.00      0.00      0.00        81\n","          54       0.03      1.00      0.06       132\n","          55       0.00      0.00      0.00        37\n","          56       0.00      0.00      0.00        66\n","          57       0.00      0.00      0.00        61\n","          58       0.00      0.00      0.00       130\n","          59       0.00      0.00      0.00       142\n","          60       0.00      0.00      0.00       150\n","          61       0.01      1.00      0.02        47\n","          62       0.00      0.00      0.00       158\n","          63       0.00      0.00      0.00       160\n","          64       0.00      0.00      0.00        87\n","          65       0.00      0.00      0.00       179\n","          66       0.00      0.00      0.00        37\n","          67       0.00      0.00      0.00       112\n","          68       0.00      0.00      0.00       165\n","          69       0.00      0.00      0.00       150\n","          70       0.04      1.00      0.07       151\n","          71       0.00      0.00      0.00       164\n","          72       0.00      0.00      0.00       138\n","          73       0.01      1.00      0.02        44\n","          74       0.00      0.00      0.00        24\n","          75       0.00      0.00      0.00       141\n","          76       0.00      0.00      0.00        54\n","          77       0.00      0.00      0.00       125\n","\n","   micro avg       0.02      0.15      0.04      7963\n","   macro avg       0.00      0.15      0.01      7963\n","weighted avg       0.00      0.15      0.01      7963\n"," samples avg       0.02      0.15      0.04      7963\n","\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"],"name":"stderr"}]}]}