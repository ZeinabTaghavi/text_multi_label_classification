{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"ParsBERT_pytorch.ipynb","provenance":[{"file_id":"1k6QLcPAJKT5H2yTy61U-YCB267inolmb","timestamp":1610512876213},{"file_id":"1AIm-KimERCJutlpyjiZ2IAwM-cCrVsWM","timestamp":1610440221899},{"file_id":"17mqUcShahUjZjQxywgKQSGU1jV-CZW8o","timestamp":1610336820188},{"file_id":"1FgtzYXY0CXNyE_2FU4IEqJTQzmVZNvDh","timestamp":1610105938882}],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"widgets":{"application/vnd.jupyter.widget-state+json":{"a3ef5416a82648b39dcbf8474f46f227":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_3422f153ea184233bf0617f0f1a513f0","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_1aacb0e2adf1405d802cb9180b3a5af3","IPY_MODEL_46f6362309d84914bfbd5bbb6622e901"]}},"3422f153ea184233bf0617f0f1a513f0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"1aacb0e2adf1405d802cb9180b3a5af3":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_8fd11ab7d682429cbdb9e77ed2f570a8","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":1441,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1441,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_c2a6b2445c47452fab5d52d34dc5cec4"}},"46f6362309d84914bfbd5bbb6622e901":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_73ef083ebb184ecd9c96c74ebd1eb6c3","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 1.44k/1.44k [00:01&lt;00:00, 850B/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_285f79d166a44e579c276ee8ae2fd3bd"}},"8fd11ab7d682429cbdb9e77ed2f570a8":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"c2a6b2445c47452fab5d52d34dc5cec4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"73ef083ebb184ecd9c96c74ebd1eb6c3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"285f79d166a44e579c276ee8ae2fd3bd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"3098bf1a584a40fb9caadc5e4dc4dab5":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_ae91aebab8aa4c86ba5863ea9670f3f9","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_bdf4bbaedff14ad49613ecf7c4bc0f06","IPY_MODEL_f0a718c958d141b3a065ca53ea200ddf"]}},"ae91aebab8aa4c86ba5863ea9670f3f9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"bdf4bbaedff14ad49613ecf7c4bc0f06":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_2d8f953b8ded45d0b03335bff6c231d5","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":1198122,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1198122,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_2759100a4ab64f85b629699f2c53ee64"}},"f0a718c958d141b3a065ca53ea200ddf":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_f709d56fd40443b5b16904776eecd8da","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 1.20M/1.20M [00:01&lt;00:00, 969kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_b0b732988a9d4be69d02adf071fb4e67"}},"2d8f953b8ded45d0b03335bff6c231d5":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"2759100a4ab64f85b629699f2c53ee64":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"f709d56fd40443b5b16904776eecd8da":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"b0b732988a9d4be69d02adf071fb4e67":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"e06ce99100374fc3a298bb34a0cbd227":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_9dccad7199cc42e5a80187d624f64dca","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_e9f1fd800d114be1ba4d25c5e76c1fa3","IPY_MODEL_3c8e0000cfca4224a8927f1068932cb5"]}},"9dccad7199cc42e5a80187d624f64dca":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"e9f1fd800d114be1ba4d25c5e76c1fa3":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_e618797f3d484eb48a701275247dfc5c","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":112,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":112,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_35c8b63ed9db434ca778ae9cf9029778"}},"3c8e0000cfca4224a8927f1068932cb5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_744daed459c2484cbb8a51c6c2733257","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 112/112 [00:00&lt;00:00, 189B/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_e4200f2882f5470bb537e745c00658c4"}},"e618797f3d484eb48a701275247dfc5c":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"35c8b63ed9db434ca778ae9cf9029778":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"744daed459c2484cbb8a51c6c2733257":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"e4200f2882f5470bb537e745c00658c4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"1e9700db8ef14d3488233cb06d2dfec0":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_b1b7d223f973430285f2496b0d83d4c1","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_f1e89acfc98546ff9c8078bc3add7a6e","IPY_MODEL_9a253da73a374944914683de75a72cdd"]}},"b1b7d223f973430285f2496b0d83d4c1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"f1e89acfc98546ff9c8078bc3add7a6e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_0c96cc82e51d4c9da009a7c20c97192f","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":62,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":62,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_75ba87174de34502be7bc6e877e2c7bc"}},"9a253da73a374944914683de75a72cdd":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_585efae4980a4942ae8521c438f52782","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 62.0/62.0 [00:00&lt;00:00, 468B/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_9e07d5c1c2334009a45b5b974c0e7d57"}},"0c96cc82e51d4c9da009a7c20c97192f":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"75ba87174de34502be7bc6e877e2c7bc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"585efae4980a4942ae8521c438f52782":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"9e07d5c1c2334009a45b5b974c0e7d57":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"9cad5d68b43f4467915ed12fe1a52be4":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_b0e63ae99ed44a4cb8256f6d6efb2af1","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_a040a51a09d441349344877bc1f4ad04","IPY_MODEL_55703f2bc7564bc380d78250434d7da0"]}},"b0e63ae99ed44a4cb8256f6d6efb2af1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"a040a51a09d441349344877bc1f4ad04":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_4d4a5ce3325b48819c77349587df29e8","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":651477729,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":651477729,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_32ad198bdc2a404fa1a5224f0bceeb49"}},"55703f2bc7564bc380d78250434d7da0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_8157e1185f0e4f2aa94675bec5522b93","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 651M/651M [00:34&lt;00:00, 18.8MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_255b5b7d0ff34605bde86f7577ce0626"}},"4d4a5ce3325b48819c77349587df29e8":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"32ad198bdc2a404fa1a5224f0bceeb49":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"8157e1185f0e4f2aa94675bec5522b93":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"255b5b7d0ff34605bde86f7577ce0626":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"markdown","metadata":{"id":"j1LTPn7IjqTz"},"source":["Source:\r\n","\r\n","huggingface: https://huggingface.co/HooshvareLab/bert-fa-base-uncased-clf-persiannews\r\n","\r\n","Tutorial:https://towardsdatascience.com/fine-tuning-hugging-face-model-with-custom-dataset-82b8092f5333"]},{"cell_type":"code","metadata":{"id":"OmPFvCbSqyZF","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1610606236105,"user_tz":-210,"elapsed":87470,"user":{"displayName":"zeinab taghavi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GheNU3ejtJBEFfDC_0W_JdLEuwkW7SKnnDuH80MRA=s64","userId":"07214630829740929140"}},"outputId":"4ac67e9a-0283-483f-c298-aa500434e7e2"},"source":["from google.colab import drive\r\n","drive.mount('/content/drive')"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"iRxC0Pz1qzKc","executionInfo":{"status":"ok","timestamp":1610606258587,"user_tz":-210,"elapsed":1203,"user":{"displayName":"zeinab taghavi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GheNU3ejtJBEFfDC_0W_JdLEuwkW7SKnnDuH80MRA=s64","userId":"07214630829740929140"}}},"source":["import os\r\n","os.chdir('/content/drive/MyDrive/sharif/FineTuning/ipython(guide)')"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mCRkKc3NcgkX","executionInfo":{"status":"ok","timestamp":1610606265225,"user_tz":-210,"elapsed":7484,"user":{"displayName":"zeinab taghavi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GheNU3ejtJBEFfDC_0W_JdLEuwkW7SKnnDuH80MRA=s64","userId":"07214630829740929140"}},"outputId":"903fbe31-c657-444c-da61-c3958dbdf246"},"source":["!pip install transformers"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Collecting transformers\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/84/ea/634945faff8ad6984b98f7f3d98f6d83083a18af44e349744d90bde81f80/transformers-4.2.0-py3-none-any.whl (1.8MB)\n","\u001b[K     |████████████████████████████████| 1.8MB 29.2MB/s \n","\u001b[?25hRequirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.8)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.8)\n","Collecting sacremoses\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n","\u001b[K     |████████████████████████████████| 890kB 49.7MB/s \n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.19.5)\n","Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from transformers) (3.3.0)\n","Collecting tokenizers==0.9.4\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0f/1c/e789a8b12e28be5bc1ce2156cf87cb522b379be9cadc7ad8091a4cc107c4/tokenizers-0.9.4-cp36-cp36m-manylinux2010_x86_64.whl (2.9MB)\n","\u001b[K     |████████████████████████████████| 2.9MB 39.2MB/s \n","\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.15.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.0.0)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.12.5)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.0)\n","Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n","Building wheels for collected packages: sacremoses\n","  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893261 sha256=a2f98157ab959c4ba6bbf227c26c29891e0b752698e97bf915d8113ffccc3c4c\n","  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n","Successfully built sacremoses\n","Installing collected packages: sacremoses, tokenizers, transformers\n","Successfully installed sacremoses-0.0.43 tokenizers-0.9.4 transformers-4.2.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ODc44DglgNjZ","executionInfo":{"status":"ok","timestamp":1610606267974,"user_tz":-210,"elapsed":9463,"user":{"displayName":"zeinab taghavi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GheNU3ejtJBEFfDC_0W_JdLEuwkW7SKnnDuH80MRA=s64","userId":"07214630829740929140"}},"outputId":"6c54f1b5-08a6-44f0-c954-9b3bb8bea1b6"},"source":["!pip3 install sentencepiece"],"execution_count":5,"outputs":[{"output_type":"stream","text":["Collecting sentencepiece\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/14/67/e42bd1181472c95c8cda79305df848264f2a7f62740995a46945d9797b67/sentencepiece-0.1.95-cp36-cp36m-manylinux2014_x86_64.whl (1.2MB)\n","\r\u001b[K     |▎                               | 10kB 21.5MB/s eta 0:00:01\r\u001b[K     |▌                               | 20kB 29.5MB/s eta 0:00:01\r\u001b[K     |▉                               | 30kB 25.6MB/s eta 0:00:01\r\u001b[K     |█                               | 40kB 21.0MB/s eta 0:00:01\r\u001b[K     |█▍                              | 51kB 19.1MB/s eta 0:00:01\r\u001b[K     |█▋                              | 61kB 15.3MB/s eta 0:00:01\r\u001b[K     |██                              | 71kB 15.9MB/s eta 0:00:01\r\u001b[K     |██▏                             | 81kB 16.0MB/s eta 0:00:01\r\u001b[K     |██▌                             | 92kB 15.0MB/s eta 0:00:01\r\u001b[K     |██▊                             | 102kB 14.6MB/s eta 0:00:01\r\u001b[K     |███                             | 112kB 14.6MB/s eta 0:00:01\r\u001b[K     |███▎                            | 122kB 14.6MB/s eta 0:00:01\r\u001b[K     |███▌                            | 133kB 14.6MB/s eta 0:00:01\r\u001b[K     |███▉                            | 143kB 14.6MB/s eta 0:00:01\r\u001b[K     |████                            | 153kB 14.6MB/s eta 0:00:01\r\u001b[K     |████▍                           | 163kB 14.6MB/s eta 0:00:01\r\u001b[K     |████▋                           | 174kB 14.6MB/s eta 0:00:01\r\u001b[K     |█████                           | 184kB 14.6MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 194kB 14.6MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 204kB 14.6MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 215kB 14.6MB/s eta 0:00:01\r\u001b[K     |██████                          | 225kB 14.6MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 235kB 14.6MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 245kB 14.6MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 256kB 14.6MB/s eta 0:00:01\r\u001b[K     |███████                         | 266kB 14.6MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 276kB 14.6MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 286kB 14.6MB/s eta 0:00:01\r\u001b[K     |████████                        | 296kB 14.6MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 307kB 14.6MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 317kB 14.6MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 327kB 14.6MB/s eta 0:00:01\r\u001b[K     |█████████                       | 337kB 14.6MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 348kB 14.6MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 358kB 14.6MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 368kB 14.6MB/s eta 0:00:01\r\u001b[K     |██████████                      | 378kB 14.6MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 389kB 14.6MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 399kB 14.6MB/s eta 0:00:01\r\u001b[K     |███████████                     | 409kB 14.6MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 419kB 14.6MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 430kB 14.6MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 440kB 14.6MB/s eta 0:00:01\r\u001b[K     |████████████                    | 450kB 14.6MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 460kB 14.6MB/s eta 0:00:01\r\u001b[K     |████████████▌                   | 471kB 14.6MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 481kB 14.6MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 491kB 14.6MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 501kB 14.6MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 512kB 14.6MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 522kB 14.6MB/s eta 0:00:01\r\u001b[K     |██████████████▏                 | 532kB 14.6MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 542kB 14.6MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 552kB 14.6MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 563kB 14.6MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 573kB 14.6MB/s eta 0:00:01\r\u001b[K     |███████████████▌                | 583kB 14.6MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 593kB 14.6MB/s eta 0:00:01\r\u001b[K     |████████████████                | 604kB 14.6MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 614kB 14.6MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 624kB 14.6MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 634kB 14.6MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 645kB 14.6MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 655kB 14.6MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 665kB 14.6MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 675kB 14.6MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 686kB 14.6MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 696kB 14.6MB/s eta 0:00:01\r\u001b[K     |██████████████████▉             | 706kB 14.6MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 716kB 14.6MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 727kB 14.6MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 737kB 14.6MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 747kB 14.6MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 757kB 14.6MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 768kB 14.6MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 778kB 14.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 788kB 14.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 798kB 14.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████▌          | 808kB 14.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 819kB 14.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 829kB 14.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 839kB 14.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 849kB 14.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 860kB 14.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 870kB 14.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 880kB 14.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 890kB 14.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 901kB 14.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 911kB 14.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 921kB 14.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 931kB 14.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 942kB 14.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▎      | 952kB 14.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 962kB 14.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 972kB 14.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 983kB 14.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 993kB 14.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 1.0MB 14.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 1.0MB 14.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 1.0MB 14.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 1.0MB 14.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 1.0MB 14.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 1.1MB 14.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▎   | 1.1MB 14.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 1.1MB 14.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 1.1MB 14.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 1.1MB 14.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 1.1MB 14.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 1.1MB 14.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 1.1MB 14.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▏ | 1.1MB 14.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 1.1MB 14.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 1.2MB 14.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 1.2MB 14.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 1.2MB 14.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 1.2MB 14.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 1.2MB 14.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.2MB 14.6MB/s \n","\u001b[?25hInstalling collected packages: sentencepiece\n","Successfully installed sentencepiece-0.1.95\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qJY_L2p9a0t0","executionInfo":{"status":"ok","timestamp":1610606267975,"user_tz":-210,"elapsed":8951,"user":{"displayName":"zeinab taghavi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GheNU3ejtJBEFfDC_0W_JdLEuwkW7SKnnDuH80MRA=s64","userId":"07214630829740929140"}},"outputId":"707b84b3-d593-4e6c-d973-c7c478b9215c"},"source":["!git clone https://huggingface.co/HooshvareLab/bert-fa-base-uncased-clf-persiannews\r\n","GIT_LFS_SKIP_SMUDGE=1"],"execution_count":6,"outputs":[{"output_type":"stream","text":["fatal: destination path 'bert-fa-base-uncased-clf-persiannews' already exists and is not an empty directory.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Eg3Up037nThu","executionInfo":{"status":"ok","timestamp":1610606274433,"user_tz":-210,"elapsed":15021,"user":{"displayName":"zeinab taghavi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GheNU3ejtJBEFfDC_0W_JdLEuwkW7SKnnDuH80MRA=s64","userId":"07214630829740929140"}}},"source":["import torch\r\n","import numpy\r\n","import pandas\r\n","import re\r\n","from sklearn.preprocessing import MultiLabelBinarizer\r\n","from sklearn.model_selection import train_test_split\r\n","from transformers import AutoTokenizer, AutoModelForSequenceClassification,AutoConfig,TFAutoModel,AutoModel\r\n","from transformers import BertConfig, BertTokenizer\r\n","from transformers import TFBertModel, TFBertForSequenceClassification\r\n","from transformers import glue_convert_examples_to_features, InputExample\r\n","from sklearn.metrics import classification_report"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"2Ur9wv1ytrZu","executionInfo":{"status":"ok","timestamp":1610606274434,"user_tz":-210,"elapsed":14731,"user":{"displayName":"zeinab taghavi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GheNU3ejtJBEFfDC_0W_JdLEuwkW7SKnnDuH80MRA=s64","userId":"07214630829740929140"}}},"source":["# specify GPU\r\n","device = torch.device(\"cuda\")"],"execution_count":8,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xax4bHubzpMp"},"source":["## Data"]},{"cell_type":"code","metadata":{"id":"TJf6T40glV5g","executionInfo":{"status":"ok","timestamp":1610606276972,"user_tz":-210,"elapsed":14152,"user":{"displayName":"zeinab taghavi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GheNU3ejtJBEFfDC_0W_JdLEuwkW7SKnnDuH80MRA=s64","userId":"07214630829740929140"}}},"source":["limit_number = 750\r\n","data = pandas.read_csv('../Data/limited_to_'+str(limit_number)+'.csv',index_col=0)\r\n","data = data.dropna().reset_index(drop=True)\r\n","X = data[\"body\"].values.tolist()\r\n","y = pandas.read_csv('../Data/limited_to_'+str(limit_number)+'.csv')\r\n","labels = []\r\n","tag=[]\r\n","for item in y['tag']:\r\n","  labels += [i for i in re.sub('\\\"|\\[|\\]|\\'| |=','',item.lower()).split(\",\") if i!='' and i!=' ']\r\n","  tag.append([i for i in re.sub('\\\"|\\[|\\]|\\'| |=','',item.lower()).split(\",\") if i!='' and i!=' '])\r\n","labels = list(set(labels))\r\n","mlb = MultiLabelBinarizer()\r\n","Y=mlb.fit_transform(tag)"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":282},"id":"A59_7YPmnZgA","executionInfo":{"status":"ok","timestamp":1610606395020,"user_tz":-210,"elapsed":1158,"user":{"displayName":"zeinab taghavi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GheNU3ejtJBEFfDC_0W_JdLEuwkW7SKnnDuH80MRA=s64","userId":"07214630829740929140"}},"outputId":"4e6c07cc-c364-4c8c-d614-88ea216a682a"},"source":["seq_len = [len(i.split()) for i in X]\n","pandas.Series(seq_len).hist(bins = 30)"],"execution_count":14,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<matplotlib.axes._subplots.AxesSubplot at 0x7f1815a097f0>"]},"metadata":{"tags":[]},"execution_count":14},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":282},"id":"1JEmlyFMm6Tf","executionInfo":{"status":"ok","timestamp":1610606467654,"user_tz":-210,"elapsed":2067,"user":{"displayName":"zeinab taghavi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GheNU3ejtJBEFfDC_0W_JdLEuwkW7SKnnDuH80MRA=s64","userId":"07214630829740929140"}},"outputId":"810cefed-2a17-4208-d80c-c79a8216b36f"},"source":["seq_len = [len([j for j in i.split() if len(j)>2]) for i in X]\n","pandas.Series(seq_len).hist(bins = 30)"],"execution_count":20,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<matplotlib.axes._subplots.AxesSubplot at 0x7f1814fd6cc0>"]},"metadata":{"tags":[]},"execution_count":20},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"code","metadata":{"id":"PH3jCKaZsEWo","executionInfo":{"status":"aborted","timestamp":1610606276973,"user_tz":-210,"elapsed":13539,"user":{"displayName":"zeinab taghavi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GheNU3ejtJBEFfDC_0W_JdLEuwkW7SKnnDuH80MRA=s64","userId":"07214630829740929140"}}},"source":["X_train, X_test, y_train, y_test = train_test_split(X,Y , test_size=0.2)\r\n","X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25)\r\n","print('train: ', len(X_train) , '\\ntest: ', len(X_test) , '\\nval: ', len(X_val) ,\"\\ny_tain:\",len(y_train) )"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Vei6iu9atmyd","colab":{"base_uri":"https://localhost:8080/","height":218,"referenced_widgets":["a3ef5416a82648b39dcbf8474f46f227","3422f153ea184233bf0617f0f1a513f0","1aacb0e2adf1405d802cb9180b3a5af3","46f6362309d84914bfbd5bbb6622e901","8fd11ab7d682429cbdb9e77ed2f570a8","c2a6b2445c47452fab5d52d34dc5cec4","73ef083ebb184ecd9c96c74ebd1eb6c3","285f79d166a44e579c276ee8ae2fd3bd","3098bf1a584a40fb9caadc5e4dc4dab5","ae91aebab8aa4c86ba5863ea9670f3f9","bdf4bbaedff14ad49613ecf7c4bc0f06","f0a718c958d141b3a065ca53ea200ddf","2d8f953b8ded45d0b03335bff6c231d5","2759100a4ab64f85b629699f2c53ee64","f709d56fd40443b5b16904776eecd8da","b0b732988a9d4be69d02adf071fb4e67","e06ce99100374fc3a298bb34a0cbd227","9dccad7199cc42e5a80187d624f64dca","e9f1fd800d114be1ba4d25c5e76c1fa3","3c8e0000cfca4224a8927f1068932cb5","e618797f3d484eb48a701275247dfc5c","35c8b63ed9db434ca778ae9cf9029778","744daed459c2484cbb8a51c6c2733257","e4200f2882f5470bb537e745c00658c4","1e9700db8ef14d3488233cb06d2dfec0","b1b7d223f973430285f2496b0d83d4c1","f1e89acfc98546ff9c8078bc3add7a6e","9a253da73a374944914683de75a72cdd","0c96cc82e51d4c9da009a7c20c97192f","75ba87174de34502be7bc6e877e2c7bc","585efae4980a4942ae8521c438f52782","9e07d5c1c2334009a45b5b974c0e7d57"]},"executionInfo":{"status":"ok","timestamp":1610510947243,"user_tz":-210,"elapsed":3895,"user":{"displayName":"mohadese rahnama","photoUrl":"","userId":"03886626379062840142"}},"outputId":"eaf6f80c-0806-4b33-b65e-25b75fd4d03f"},"source":["##we would load the tokenizer\r\n","tokenizer = AutoTokenizer.from_pretrained(\"HooshvareLab/bert-fa-base-uncased-clf-persiannews\")"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a3ef5416a82648b39dcbf8474f46f227","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1441.0, style=ProgressStyle(description…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"3098bf1a584a40fb9caadc5e4dc4dab5","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1198122.0, style=ProgressStyle(descript…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e06ce99100374fc3a298bb34a0cbd227","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=112.0, style=ProgressStyle(description_…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"1e9700db8ef14d3488233cb06d2dfec0","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=62.0, style=ProgressStyle(description_w…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"C7wdU0zejDNq","executionInfo":{"elapsed":1080,"status":"ok","timestamp":1610445646323,"user":{"displayName":"mohadese rahnama","photoUrl":"","userId":"03886626379062840142"},"user_tz":-210},"outputId":"ac1884a3-45c6-475a-c09b-11363003e47c"},"source":["#example\r\n","text = \"ما در هوشواره معتقدیم با انتقال صحیح دانش و آگاهی، همه افراد میتوانند از ابزارهای هوشمند استفاده کنند. شعار ما هوش مصنوعی برای همه است.\"\r\n","tokenized=tokenizer.tokenize(X_train[0])\r\n","input_ids = tokenizer.convert_tokens_to_ids(tokenized)\r\n","print(tokenized)\r\n","print(input_ids)\r\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["['نمی', 'دونم', 'واقعی', '##ه', 'خونده', 'می', 'خوا', '##ی', 'مطمين', 'بشی', 'تصمیم', '##ت', 'ببین', 'گرفتی', '##ش', 'جهان', 'طوری', 'باهات', 'می', 'کنه', 'داره', 'برنامه', 'می', 'ره', 'سنگ', '##ای', 'ریز', 'درشت', 'پات', 'می', 'افت', '##ه', 'قدرتی', 'می', 'خواد', 'جلوت', 'بایسته', 'می', 'تونی', 'امیدوار', 'قدما', '##ی', 'اولو', 'برداشتی', 'شبیه', 'قصه', 'ی', 'اکت', 'نیتی', '##و', 'روزی', 'بسم', 'الله', 'درگیر', 'اتفاقا', '##یی', 'قاعدتا', 'هفته', 'می', 'افتادن', 'صفحه', 'کلید', 'تاپ', 'مقدمه', 'کار', 'افتاد', 'روزای', 'اسفند', 'بتونه', 'درستش', 'کنه', 'بشه', 'صفحه', 'کلید', 'خرید', 'اندازه', 'ی', 'کشف', 'واکسن', 'کرونا', 'می', 'رسید', 'کیبورد', 'قدیمی', 'امانت', 'اونم', 'دکمه', 'ی', 'اسپیس', 'مجبور', 'تیکه', 'پاک', 'توش', 'کار', 'بذارم', 'اونم', 'کار', 'افتاد', 'بعدم', 'تعمیرکار', 'اومدم', 'دیدم', 'کیبورد', '##و', 'تعمیر', 'ویندوز', '##مم', 'پریده', 'الله', 'اکبر', 'اقبال', 'بلند', 'خونسردی', '##مو', 'حفظ', 'بگم', 'خیال', 'دست', 'برمی', 'تاپ', 'حالش', 'نشد', 'مهمی', 'اطلاعاتم', 'دست', 'عوضش', 'کیبورد', 'خریدم', 'فلاکت', '##ی', 'خوشم', 'گم', '##ونم', 'می', 'تون', '##م', 'خط', 'ها', 'بنویسم', 'سلام', 're', '##act', 'nat', '##ive', 'جهان', 'سرش', 'چسب', '##وندم']\n","[2510, 89453, 4023, 1177, 90712, 2044, 68139, 1158, 6097, 30885, 3013, 1174, 4462, 32415, 1176, 2685, 4624, 63173, 2044, 14678, 11723, 2385, 2044, 2796, 3369, 2026, 6900, 12695, 11374, 2044, 2694, 1177, 13070, 2044, 81898, 87203, 31519, 2044, 16845, 3763, 57321, 1158, 85106, 20869, 5617, 8468, 382, 5630, 35805, 1154, 5146, 15397, 3323, 5616, 8809, 14822, 14018, 2759, 2044, 11062, 4203, 5772, 8628, 10859, 2109, 5178, 81286, 3997, 49069, 47603, 14678, 16437, 4203, 5772, 2637, 4224, 382, 4628, 11903, 28114, 2044, 2621, 15089, 5320, 12315, 35100, 11868, 382, 29011, 5187, 42484, 3778, 36375, 2109, 66978, 35100, 2109, 5178, 66201, 37190, 40154, 7827, 15089, 1154, 7530, 6647, 10535, 34661, 3323, 6706, 9651, 3929, 27849, 21325, 3530, 19193, 8636, 2166, 6109, 8628, 21875, 4030, 4656, 73631, 2166, 67814, 15089, 26403, 27283, 1158, 11752, 7136, 14339, 2044, 6662, 1155, 2624, 5526, 22541, 3132, 10880, 19122, 31017, 14111, 2685, 10969, 10482, 67195]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Az4rwU0l5ECn"},"source":["# encode text\r\n","sent_id = tokenizer.batch_encode_plus(X_train[:10], padding=True, return_token_type_ids=False)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oNRU-SH65ZEE","executionInfo":{"status":"ok","timestamp":1610510956416,"user_tz":-210,"elapsed":1393,"user":{"displayName":"mohadese rahnama","photoUrl":"","userId":"03886626379062840142"}},"outputId":"05ce4767-dd4d-42bb-88e1-569ecfe0e8d1"},"source":["sent_id"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'input_ids': [[2, 5071, 4790, 32701, 3911, 19910, 74701, 3329, 52810, 2030, 4613, 57968, 7341, 4957, 3916, 3911, 4613, 9607, 39230, 4378, 28724, 36539, 5929, 15619, 20936, 41215, 2002, 5102, 57637, 6012, 74701, 5565, 2867, 5929, 26040, 6501, 4484, 64198, 5438, 13334, 23344, 58164, 6012, 6820, 58164, 4766, 6667, 33103, 35204, 6921, 37745, 23460, 4366, 5929, 2959, 45309, 8146, 4856, 4613, 2938, 5782, 4394, 2959, 45098, 60379, 2061, 45309, 8146, 29511, 5929, 52446, 11231, 2867, 6921, 8094, 52810, 64831, 35138, 33103, 62321, 4366, 5929, 2959, 27409, 45309, 8146, 23460, 4613, 35667, 33103, 62321, 6921, 37745, 4366, 5929, 33336, 2959, 27409, 45309, 8146, 52810, 64831, 35138, 4484, 18009, 92228, 74701, 37458, 48687, 52446, 22157, 45498, 29420, 4090, 23709, 2050, 30750, 7796, 6945, 11999, 32701, 3528, 10672, 35428, 17389, 5655, 3030, 5071, 3329, 52810, 2030, 4613, 44594, 18230, 4790, 52248, 7120, 28678, 10741, 3531, 3916, 45309, 62071, 88012, 5929, 74701, 3462, 5289, 7222, 5071, 96817, 88012, 67519, 70473, 11332, 54934, 5690, 3328, 6945, 3329, 10884, 39230, 45309, 8146, 5754, 4459, 88012, 5929, 52810, 64831, 35138, 17687, 3796, 5929, 98322, 33103, 88012, 2032, 6921, 8094, 98322, 17358, 4366, 5929, 2959, 45309, 8146, 88012, 54176, 2032, 8094, 45309, 8146, 5444, 22367, 10672, 43300, 28724, 88012, 43815, 47224, 11721, 54934, 4366, 5929, 2959, 42528, 45309, 8146, 52810, 5642, 52248, 7120, 28678, 10741, 11231, 12139, 4296, 28724, 2959, 54729, 23116, 17687, 9706, 44594, 71030, 3778, 52810, 32590, 29048, 5717, 7152, 52810, 2030, 18230, 13459, 4366, 5929, 6921, 52810, 32590, 29048, 33103, 88012, 2959, 42528, 45309, 8146, 88012, 54176, 2032, 8094, 28807, 19921, 30304, 11231, 5731, 3629, 10672, 4856, 32701, 4836, 27409, 71030, 3778, 4613, 49225, 89243, 11802, 7843, 10672, 18009, 28807, 19921, 30304, 15766, 10672, 5503, 49225, 3629, 10672, 88012, 38793, 3318, 3528, 5754, 6749, 71030, 3778, 52810, 60791, 2040, 13459, 4366, 5929, 71030, 3778, 2959, 42528, 45309, 8146, 71030, 3778, 52810, 2030, 3251, 5690, 4070, 4856, 71030, 3778, 52810, 2030, 10884, 8146, 52810, 2030, 12182, 13453, 14142, 4568, 7843, 18009, 96566, 5731, 3629, 67682, 2959, 35814, 18009, 28807, 19921, 30304, 10884, 45309, 8146, 52248, 7120, 28678, 10741, 11231, 18430, 3629, 10672, 7162, 10672, 12139, 10672, 18009, 98346, 96109, 18489, 10884, 45309, 8146, 52810, 2030, 28724, 8543, 10672, 28724, 52248, 7120, 28678, 10741, 7162, 10207, 4459, 88292, 88012, 5929, 6921, 52810, 64831, 35138, 10884, 32717, 45309, 17979, 23116, 74701, 5842, 88292, 88012, 5929, 19089, 4629, 5842, 50317, 28552, 5796, 71442, 4], [2, 5071, 8456, 23639, 5929, 25625, 36108, 32088, 30765, 13870, 86836, 24091, 4209, 4957, 2959, 42528, 4713, 48212, 4089, 3475, 28552, 4957, 19791, 5891, 39298, 88184, 86836, 24091, 25625, 6552, 4175, 58164, 3521, 10602, 25625, 3780, 3329, 12035, 8387, 3841, 3475, 5224, 7178, 11231, 25625, 58164, 23639, 5929, 11231, 5232, 5929, 3191, 58164, 16958, 2795, 79566, 2011, 15615, 39298, 5891, 7765, 24578, 35088, 7223, 68981, 6839, 22338, 2816, 4158, 2805, 7579, 23639, 25625, 5224, 17687, 4241, 10672, 7164, 15407, 23639, 5929, 32701, 3852, 35088, 13443, 10130, 25554, 23639, 5484, 4366, 5929, 25625, 17802, 13113, 12702, 6945, 22367, 3083, 3404, 70724, 2003, 12139, 17802, 3642, 22367, 10672, 8152, 12702, 23639, 5596, 58164, 5939, 5929, 6777, 50980, 14878, 22394, 2061, 7796, 45498, 82343, 46718, 25625, 86836, 24091, 3528, 17420, 21503, 6310, 13443, 10130, 25554, 13113, 15307, 15611, 23639, 6820, 5754, 6917, 14745, 48212, 28817, 3229, 6921, 48212, 4274, 17420, 58164, 6921, 4366, 5929, 27989, 14599, 13113, 6945, 4366, 5929, 3528, 10672, 70724, 2003, 32701, 22367, 3083, 23639, 5929, 4942, 45309, 62071, 33192, 4179, 8340, 20208, 3419, 5929, 3329, 12035, 6921, 4366, 5929, 48212, 2959, 64856, 19327, 10672, 18781, 46158, 5350, 5929, 6492, 5929, 11231, 74701, 23157, 26604, 98637, 2033, 3419, 5929, 3329, 12035, 1876, 3064, 48212, 2867, 4360, 18781, 46158, 5350, 5929, 4089, 39298, 27989, 3191, 9567, 5929, 3852, 61145, 19994, 6312, 24003, 2805, 27989, 7106, 2867, 8417, 81884, 52810, 2030, 53895, 2032, 38793, 13334, 47489, 23169, 28552, 4957, 4241, 27989, 7098, 84506, 2805, 29121, 4366, 5929, 6537, 81884, 5929, 6575, 28552, 4957, 3952, 54570, 65740, 4816, 24843, 23639, 52810, 2030, 22821, 36649, 3647, 3929, 3821, 43481, 2008, 23639, 52810, 2030, 28552, 4957, 2959, 10514, 10884, 8076, 57941, 58164, 17687, 4482, 6917, 8094, 32458, 22821, 36649, 5806, 37400, 30387, 32538, 3903, 11231, 52810, 2030, 5929, 5754, 10207, 58164, 17687, 4482, 23639, 5929, 4942, 23639, 50145, 46614, 22367, 3083, 96291, 77626, 4735, 11231, 23639, 3469, 12702, 8417, 4766, 10884, 5954, 4957, 15305, 15305, 12101, 28552, 4957, 4062, 17521, 3475, 5839, 36189, 11231, 22930, 23180, 2867, 14114, 14829, 12139, 3640, 3910, 5929, 3640, 6173, 17687, 9258, 23116, 17476, 26029, 12453, 23639, 22930, 49722, 13654, 4209, 4957, 2959, 3083, 26029, 12453, 12702, 23639, 22930, 49722, 58164, 4905, 5929, 24954, 9258, 28302, 6173, 86836, 24091, 4482, 5071, 23639, 5929, 11904, 2938, 32701, 3852, 48476, 2816, 36711, 12139, 50715, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [2, 65312, 8478, 1457, 1393, 1460, 1392, 65312, 8478, 1460, 1393, 1457, 1392, 1455, 2034, 65312, 8478, 1462, 1393, 1462, 1392, 43428, 41740, 8596, 40506, 2077, 18481, 61527, 2041, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [2, 4900, 41086, 3351, 4172, 3381, 11424, 3318, 4485, 4900, 3948, 3432, 15186, 4900, 3948, 4179, 7879, 8179, 72591, 2793, 3689, 4238, 3916, 7602, 2967, 5929, 7154, 72591, 4449, 4900, 3640, 76537, 6604, 7154, 5929, 6914, 5929, 3432, 5939, 5929, 4209, 3432, 8872, 9060, 2871, 3145, 3404, 3432, 5939, 5929, 3625, 3634, 5725, 78884, 2783, 5939, 5929, 7882, 4586, 5929, 5725, 2793, 3188, 4449, 3270, 72591, 15826, 35425, 47607, 10197, 17989, 94808, 83327, 42629, 2032, 3211, 5817, 3521, 5725, 4900, 5484, 6429, 5939, 5939, 5929, 2959, 2793, 9933, 5939, 3376, 32270, 23921, 47308, 6825, 3381, 3630, 2793, 6414, 4639, 7129, 5823, 16020, 3027, 3145, 3905, 4639, 9913, 6262, 67486, 4238, 3531, 6951, 3561, 13191, 5725, 8179, 23921, 68115, 42985, 2048, 3470, 37039, 41627, 12454, 63493, 4484, 4188, 3439, 2844, 5117, 2938, 3221, 2793, 10941, 3361, 78884, 2783, 13038, 42703, 4449, 78884, 2783, 5973, 2930, 5929, 8204, 3561, 3632, 4463, 5973, 3171, 19319, 3474, 3952, 2867, 3270, 5725, 4386, 9310, 3821, 74489, 10871, 3733, 2867, 3473, 4247, 18586, 24201, 5929, 5042, 3525, 24201, 10307, 24201, 5108, 4980, 8349, 5140, 37142, 3364, 4459, 4247, 18586, 4108, 2793, 6414, 5484, 6429, 3926, 10023, 18586, 5850, 37039, 41627, 3270, 5101, 11002, 5983, 8097, 7971, 43624, 72591, 3280, 5399, 4872, 6637, 6825, 12330, 3310, 5939, 5929, 3432, 2871, 3145, 6378, 3661, 2910, 3504, 4912, 6198, 6724, 4449, 4900, 18275, 3201, 9324, 5426, 4002, 6189, 5154, 7843, 11802, 4247, 5469, 7273, 4002, 7173, 5426, 4002, 6189, 5154, 7843, 11802, 4247, 5469, 7273, 4002, 7173, 37620, 4884, 10755, 9258, 5929, 19911, 6596, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [2, 53615, 5224, 15407, 3521, 3916, 9825, 3810, 4160, 2904, 3073, 3444, 4924, 3521, 6542, 22201, 29808, 22686, 4816, 62030, 43059, 6022, 7065, 5834, 5929, 3521, 53615, 3043, 7285, 25029, 2793, 5655, 6429, 16477, 53615, 31792, 3916, 4394, 5929, 3251, 5071, 3287, 6012, 2938, 6629, 4139, 8369, 53615, 3640, 16004, 3000, 2811, 9622, 3521, 31041, 6012, 3835, 3347, 5733, 3521, 3916, 7443, 53615, 9706, 53615, 3786, 5524, 8369, 16477, 6734, 4139, 16477, 53615, 2793, 3689, 3251, 3640, 2793, 17355, 2015, 4532, 9585, 4139, 16477, 53615, 5785, 6012, 6629, 4139, 8369, 53615, 3364, 3439, 3475, 5839, 53615, 3444, 4449, 6095, 2959, 3171, 3145, 5209, 5455, 4244, 3821, 3435, 4449, 5302, 4386, 4449, 5209, 4900, 8052, 4639, 4816, 53615, 53615, 3828, 2793, 74489, 4449, 53615, 6378, 63432, 4639, 3525, 3905, 53615, 3828, 7580, 4605, 5725, 5522, 4485, 53615, 3521, 5929, 3114, 9825, 6748, 7580, 5725, 8246, 22880, 4449, 4394, 53615, 2003, 4347, 7688, 53615, 3521, 4175, 3780, 5020, 3475, 3810, 3310, 8872, 5455, 7276, 53615, 3280, 5076, 4089, 4816, 4367, 3905, 8707, 4909, 2938, 3211, 4394, 7078, 5418, 2910, 2867, 5418, 3404, 7670, 3100, 4981, 3966, 4394, 5102, 57637, 12512, 4394, 5655, 3390, 5717, 12512, 3640, 4394, 7502, 3966, 12512, 6839, 3640, 4394, 6137, 4001, 4316, 5040, 3100, 12512, 4394, 4084, 13294, 36465, 3531, 3927, 2867, 4482, 5399, 7212, 3475, 11176, 53615, 6542, 7919, 4816, 4394, 5929, 53615, 2003, 7934, 4394, 4084, 6501, 4394, 4995, 6206, 3422, 5929, 23763, 2793, 70933, 4394, 5842, 5596, 5094, 23639, 92809, 4816, 12218, 8417, 2910, 2867, 4995, 21250, 39298, 79757, 2783, 5054, 62346, 13459, 3329, 17012, 3475, 11176, 53615, 4001, 3486, 15615, 5094, 5929, 23639, 5929, 53615, 2003, 3100, 4981, 3419, 5929, 46558, 30466, 23460, 46227, 48212, 3329, 4373, 53615, 6947, 4856, 5520, 4995, 7014, 2938, 4394, 3280, 6012, 3347, 5733, 3521, 3916, 3381, 16477, 3640, 2959, 54074, 3966, 53615, 5369, 5145, 2793, 8096, 66823, 3810, 3494, 8369, 16477, 8204, 4383, 53615, 7152, 4394, 5929, 4360, 4909, 3211, 3966, 53615, 6672, 3625, 3318, 4459, 3229, 2793, 31149, 4394, 3521, 53615, 5040, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [2, 6506, 4712, 4565, 5929, 4428, 7254, 5574, 7043, 6506, 10783, 5506, 5206, 7332, 7648, 3873, 3469, 6506, 4712, 3665, 5929, 2959, 6168, 13883, 3475, 3329, 5929, 7164, 6545, 4565, 3541, 5929, 5042, 5054, 6506, 4712, 3329, 6259, 4006, 15407, 3469, 9321, 8246, 2793, 5655, 3469, 6506, 4712, 7502, 12158, 6907, 5929, 6506, 13533, 7060, 4683, 7649, 5929, 4656, 5988, 4905, 5929, 7670, 3625, 29082, 5223, 3329, 5929, 4663, 6160, 5407, 3287, 4778, 3169, 4869, 3768, 9730, 38930, 88706, 2959, 13394, 4603, 6712, 4778, 6802, 7316, 2793, 31149, 10132, 5407, 3287, 4241, 3329, 23211, 53967, 8357, 4454, 4883, 73527, 46634, 81397, 49349, 2039, 3179, 3553, 6506, 4712, 2844, 5797, 7001, 1455, 1393, 1458, 3700, 8108, 5473, 2904, 3073, 2844, 30791, 1462, 1393, 1462, 3700, 5493, 8973, 4066, 3205, 3329, 6259, 4321, 7670, 7014, 11748, 12132, 46567, 8457, 7456, 7670, 4816, 4390, 7332, 2838, 13375, 2838, 3475, 11176, 3329, 5929, 6545, 7753, 20638, 2938, 6506, 4712, 9859, 3639, 3625, 3971, 3927, 3310, 4992, 5929, 4981, 3329, 5929, 5407, 3287, 3280, 3983, 7273, 5574, 3088, 9713, 10287, 9321, 4274, 5929, 6076, 3625, 17048, 5757, 3661, 7755, 25548, 7401, 4497, 4472, 3088, 4348, 6506, 3945, 3911, 3911, 6404, 7152, 3945, 3911, 3777, 6029, 4820, 2013, 35065, 2003, 6506, 4712, 3211, 3052, 5929, 23180, 6506, 13533, 3911, 3280, 3027, 3145, 2793, 31149, 14792, 3434, 3376, 6506, 13533, 16917, 16764, 34151, 58212, 3280, 3318, 4924, 3475, 11176, 6259, 4875, 5929, 3329, 5929, 16917, 2032, 40176, 45671, 23180, 4723, 3475, 11176, 5311, 2793, 9868, 4834, 10937, 4778, 6802, 3640, 37990, 5076, 4175, 22930, 3911, 2867, 5929, 4980, 4788, 4875, 5929, 22930, 6917, 6552, 5859, 2793, 3689, 11107, 5934, 5582, 4778, 11014, 74978, 23180, 5929, 5754, 2867, 4207, 22930, 3318, 11107, 16917, 4206, 16917, 40176, 58964, 4247, 23180, 22930, 45671, 4303, 4905, 5929, 3531, 9938, 5929, 4175, 4274, 5929, 5861, 6506, 13533, 3521, 4383, 5929, 4980, 5311, 2793, 9868, 3280, 3911, 10755, 3945, 5929, 5506, 3469, 2910, 3521, 4383, 5929, 5574, 16477, 3789, 5783, 9408, 6907, 5929, 7878, 11384, 3329, 6506, 13533, 15720, 3100, 3475, 6506, 4712, 4875, 5929, 6783, 3625, 5077, 8359, 9007, 7060, 4683, 4411, 3171, 5929, 5506, 5929, 4411, 2959, 5392, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [2, 79317, 5929, 3329, 3972, 10953, 79317, 5896, 5929, 9227, 3928, 11809, 11742, 7440, 3329, 5102, 18421, 79317, 3047, 2793, 4564, 3927, 16069, 3598, 3329, 2938, 2844, 3972, 2793, 5655, 3927, 16069, 4554, 2844, 3944, 5781, 4788, 62735, 2844, 3378, 5071, 14313, 5929, 5020, 3329, 5929, 5020, 3927, 16069, 3351, 6258, 14313, 5929, 5100, 5323, 2904, 3939, 4370, 5929, 6095, 2959, 2793, 9933, 14313, 5676, 3329, 3927, 16069, 91722, 3620, 3088, 7440, 3329, 6325, 4977, 13809, 13216, 25643, 5754, 5140, 4613, 8963, 7764, 5000, 3351, 4224, 3972, 3280, 5653, 3640, 2844, 28140, 15233, 6428, 6428, 3385, 15407, 4014, 3972, 5891, 2793, 39316, 16417, 5929, 2844, 6734, 3821, 3168, 7690, 13248, 5158, 3944, 3640, 4788, 5100, 3927, 16069, 2844, 3944, 5100, 6650, 5757, 3789, 5783, 3940, 5100, 27285, 12179, 5100, 5597, 1044, 7291, 89216, 1038, 24839, 4205, 12376, 5114, 25136, 23687, 1026, 24839, 6471, 90653, 19324, 1043, 24219, 3465, 62197, 36456, 2040, 17395, 16799, 14320, 3280, 3792, 5659, 2910, 47684, 4713, 3789, 5783, 15723, 4196, 12266, 36132, 5100, 7478, 12266, 4238, 6429, 6839, 3473, 24810, 16650, 3736, 12822, 12822, 5781, 2844, 3944, 2793, 11543, 3125, 6180, 4790, 32573, 10153, 2938, 3777, 9719, 2793, 11543, 2867, 15490, 3280, 4825, 3625, 2793, 6150, 2844, 19987, 3789, 5783, 5100, 3521, 5100, 5653, 5929, 3850, 3280, 5358, 4630, 3521, 5929, 4386, 5690, 3328, 3287, 3280, 2844, 3972, 3469, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [2, 3500, 4060, 4259, 7358, 67913, 7834, 3821, 5398, 2013, 8707, 8900, 4207, 7358, 4816, 11080, 65925, 3186, 67913, 3625, 3573, 4801, 3286, 3521, 4383, 5224, 7358, 2930, 11080, 55355, 2006, 13222, 5342, 21308, 5680, 4139, 4884, 12675, 10357, 19209, 4825, 18571, 5929, 4219, 16047, 7358, 5094, 4207, 2793, 3689, 1876, 2949, 5484, 6429, 7753, 94425, 3841, 20411, 9497, 4207, 7358, 33962, 3251, 5369, 5690, 2881, 1876, 2949, 7358, 23073, 8757, 5524, 3573, 14273, 67913, 5574, 7043, 3205, 7358, 2959, 3171, 2822, 1876, 3035, 3852, 2793, 17355, 2015, 3500, 4060, 7358, 3205, 3091, 5929, 11457, 5929, 3205, 3625, 6542, 5929, 6909, 3525, 3205, 9508, 5929, 9255, 7010, 5200, 4157, 23073, 7358, 14335, 5929, 3151, 3145, 23120, 36537, 18903, 84081, 25837, 3205, 7358, 4735, 38611, 3205, 20424, 4207, 5929, 9111, 4816, 4360, 14686, 3318, 3205, 7358, 2044, 7510, 5574, 7043, 11827, 6937, 16945, 6921, 65745, 4497, 7843, 4390, 3205, 3500, 7214, 11384, 79249, 5596, 3521, 72642, 4321, 3205, 5770, 2793, 31149, 5524, 7358, 2044, 11817, 5891, 4246, 5891, 4246, 32717, 3521, 6676, 12944, 9545, 6201, 67948, 7214, 6029, 7843, 17914, 21396, 6075, 17914, 19209, 3229, 6917, 67509, 5785, 4497, 4482, 7358, 3205, 32717, 94425, 5311, 42375, 12675, 4565, 10357, 7358, 7510, 94425, 16945, 17914, 6921, 91942, 4497, 7843, 4321, 5596, 3500, 4426, 12675, 10357, 5655, 3290, 1876, 12675, 10357, 7358, 5596, 94425, 3499, 39230, 7843, 17914, 11384, 3528, 4305, 5929, 19209, 4209, 2959, 5596, 5596, 94425, 2793, 31149, 12675, 18571, 5929, 7358, 3205, 7173, 7164, 15407, 18571, 5929, 7358, 2793, 31149, 19209, 70122, 1876, 2965, 7510, 94425, 4497, 16945, 6921, 91942, 7843, 4280, 5596, 3500, 1876, 2965, 3559, 12958, 5596, 7843, 17914, 19209, 4482, 5655, 3328, 18430, 65819, 2032, 14233, 4241, 3318, 5596, 5596, 2793, 31149, 7494, 5929, 11827, 13854, 60976, 7173, 55159, 37643, 1461, 5028, 65517, 8596, 5071, 3211, 2959, 3296, 10061, 3598, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [2, 14322, 23772, 2991, 5929, 9655, 29257, 3419, 5929, 3329, 12035, 13229, 11987, 22614, 5929, 6492, 5929, 6362, 3310, 6506, 3419, 2793, 17355, 2015, 3419, 3419, 11999, 5929, 3419, 15024, 3795, 3972, 6815, 11999, 7440, 4766, 5929, 8398, 17031, 3911, 2867, 3419, 5224, 15407, 29257, 3419, 3329, 12035, 3810, 3052, 5929, 4484, 5929, 3419, 5819, 3419, 3329, 17012, 3229, 9258, 45147, 3346, 3919, 7494, 5929, 6166, 6545, 20553, 2881, 3795, 3419, 3795, 4900, 9963, 7494, 5929, 14369, 11107, 3419, 4113, 48212, 6163, 3419, 5929, 3329, 12035, 6506, 14322, 23772, 5086, 3218, 1442, 11883, 6198, 4935, 4461, 1442, 3419, 6429, 4183, 1035, 64606, 2048, 53076, 3419, 6506, 4613, 11373, 2922, 9678, 5929, 3419, 5929, 3329, 12035, 3329, 12035, 2867, 10871, 5161, 10260, 16253, 3768, 5526, 3329, 4373, 14322, 23772, 3052, 3777, 7525, 3329, 4373, 3329, 4373, 14322, 23772, 21250, 5175, 5966, 10622, 5161, 11710, 5929, 3768, 5526, 3329, 17012, 7924, 5001, 74701, 11987, 22614, 14322, 23772, 10968, 3475, 45147, 86365, 14322, 23772, 3329, 12035, 9258, 3795, 3419, 21457, 3841, 9811, 5929, 11324, 11999, 8223, 30078, 8505, 6492, 14322, 23772, 32580, 18481, 23000, 3114, 3318, 3795, 3419, 4394, 10595, 7273, 8505, 3280, 4394, 22056, 10822, 23122, 28938, 61319, 91584, 66580, 9977, 11999, 7551, 11757, 5082, 7179, 3795, 3057, 10153, 2938, 13713, 14322, 23772, 14829, 12958, 3057, 3494, 3795, 62755, 14322, 23772, 3057, 48650, 7899, 33911, 2040, 3057, 5413, 4049, 17358, 3795, 48212, 62755, 46227, 2043, 13874, 8223, 12369, 17358, 4875, 5929, 7333, 5929, 9367, 4875, 53615, 28933, 2846, 4988, 20922, 8223, 13874, 3280, 9678, 5929, 5524, 6132, 3504, 4394, 13874, 2910, 5929, 3114, 3331, 13543, 52046, 22631, 30361, 59894, 1, 1044, 80971, 30784, 20845, 26018, 79061, 12907, 1, 1044, 80971, 68034, 21857, 23376, 54912, 93648, 54934, 1, 1044, 80971, 68034, 21857, 23376, 28654, 48774, 95380, 2025, 1, 1044, 80971, 68034, 21857, 23376, 4384, 69010, 3795, 11408, 6506, 3419, 3329, 12035, 14322, 23772, 4411, 3088, 6865, 3088, 8751, 3419, 3494, 24664, 4394, 5574, 7043, 5929, 3052, 5929, 3361, 3928, 3552, 14322, 23772, 4219, 6378, 3419, 3329, 12035, 30687, 3201, 3463, 6012, 3280, 7578, 6506, 14322, 23772, 4868, 6575, 4997, 7560, 14322, 23772, 7171, 5392, 43030, 57345, 18172, 21849, 3106, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [2, 3434, 5929, 6386, 5929, 4431, 9450, 7563, 3426, 3665, 5929, 5042, 4908, 44821, 5929, 6386, 5929, 17539, 3777, 5757, 6177, 3469, 13200, 2905, 5929, 6386, 2973, 3191, 3148, 5929, 3535, 13200, 2905, 7563, 3052, 8523, 4790, 3535, 13200, 2905, 6386, 7563, 3384, 3535, 13200, 2905, 6804, 6917, 5676, 5071, 4394, 53839, 22999, 4790, 3640, 13200, 2905, 6804, 7563, 8369, 14280, 3287, 3929, 21276, 7026, 2867, 7563, 19645, 4863, 6545, 3528, 9916, 2793, 3201, 6386, 3434, 17539, 14020, 5016, 3434, 5929, 6386, 5929, 17539, 6804, 4855, 36019, 4816, 5442, 7563, 7333, 2904, 3073, 6500, 6386, 3434, 17539, 25599, 3535, 13200, 2905, 45585, 5101, 4157, 13200, 2905, 6949, 6386, 5929, 4179, 32717, 4909, 70122, 3535, 13200, 2905, 6804, 7563, 11568, 7563, 7532, 4108, 3191, 13200, 2905, 5929, 6804, 6386, 17539, 8369, 3287, 8369, 13200, 2905, 5929, 4727, 3318, 3251, 8369, 3535, 13200, 2905, 6804, 5369, 5690, 3328, 44821, 6386, 3569, 4080, 5042, 7563, 3426, 6429, 13200, 43184, 2003, 6269, 4418, 13200, 2905, 5929, 5850, 3535, 4080, 10217, 3625, 5351, 8122, 3535, 13200, 2905, 5929, 30197, 19338, 6386, 5929, 10151, 13200, 2905, 5929, 19338, 3535, 3821, 3168, 3680, 14979, 3287, 9861, 3390, 13200, 2905, 5929, 4997, 5929, 6386, 5589, 6810, 5972, 9871, 13200, 2905, 5929, 6386, 32717, 3535, 13200, 2905, 7563, 6804, 6386, 5929, 5850, 5670, 3444, 6386, 17539, 4605, 3885, 3541, 5929, 6380, 3088, 3191, 13200, 2905, 5929, 6386, 17539, 3384, 9871, 13200, 2905, 6386, 5929, 3885, 6386, 4912, 3426, 13101, 4912, 4816, 7563, 6804, 3191, 13200, 2905, 11416, 3535, 13200, 2905, 8755, 7563, 20412, 3955, 6386, 5929, 6106, 6386, 5929, 6106, 5351, 3504, 18850, 2003, 4241, 6839, 7443, 4219, 4183, 6386, 17539, 3569, 4968, 4891, 3426, 13200, 43184, 2003, 5850, 4181, 17019, 36132, 5781, 10538, 6386, 4400, 2871, 3145, 5458, 5670, 4001, 3535, 13200, 2905, 6804, 3541, 5929, 5178, 18275, 5700, 6804, 6386, 2871, 3145, 44821, 4296, 4299, 6771, 6839, 13200, 2905, 5929, 6804, 4296, 16428, 3229, 15352, 5850, 4997, 5929, 6386, 3384, 3271, 96094, 6386, 12126, 5739, 3905, 2793, 31149, 6839, 13200, 2905, 5929, 6386, 3191, 4296, 6386, 3535, 13200, 2905, 7563, 3541, 5929, 5042, 4108, 3535, 13200, 2905, 6804, 3541, 5929, 3191, 13200, 2905, 6386, 5929, 17539, 6386, 3569, 4080, 7563, 3426, 5850, 13200, 43184, 2003, 6804, 6386, 5929, 17539, 9871, 4296, 6386, 4062, 3088, 16477, 3535, 13200, 2905, 6804, 4001, 3541, 5929, 3364, 4, 0, 0, 0, 0, 0, 0]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]]}"]},"metadata":{"tags":[]},"execution_count":12}]},{"cell_type":"code","metadata":{"id":"uF3FFsPzc6zD"},"source":["sentence_maxlen=128"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4m2Qc2IkrnEp","executionInfo":{"status":"ok","timestamp":1610510986449,"user_tz":-210,"elapsed":21178,"user":{"displayName":"mohadese rahnama","photoUrl":"","userId":"03886626379062840142"}},"outputId":"1d16ea52-338d-430c-c901-91c0d0f61d57"},"source":["##Tokenize training and validation sentences:\r\n","train_encodings = tokenizer.batch_encode_plus(X_train,\r\n","    max_length = sentence_maxlen,\r\n","    pad_to_max_length=True,\r\n","    truncation=True,\r\n","    return_token_type_ids=False)\r\n","\r\n","val_encodings = tokenizer.batch_encode_plus(X_val,\r\n","    max_length = sentence_maxlen,\r\n","    pad_to_max_length=True,\r\n","    truncation=True,\r\n","    return_token_type_ids=False)\r\n","\r\n","test_encodings=tokenizer.batch_encode_plus(X_test,\r\n","    max_length = sentence_maxlen,\r\n","    pad_to_max_length=True,\r\n","    truncation=True,\r\n","    return_token_type_ids=False)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2179: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IwjkXARbetX-","executionInfo":{"status":"ok","timestamp":1610510986454,"user_tz":-210,"elapsed":17675,"user":{"displayName":"mohadese rahnama","photoUrl":"","userId":"03886626379062840142"}},"outputId":"7a0d4997-5314-453f-c7f0-48412a1b987b"},"source":["train_encodings[0]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Encoding(num_tokens=128, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing])"]},"metadata":{"tags":[]},"execution_count":15}]},{"cell_type":"code","metadata":{"id":"-iCp2PUEupYK"},"source":["import torch\r\n","import torch.nn as nn\r\n","\r\n","# for train set\r\n","train_seq = torch.tensor(train_encodings['input_ids'])\r\n","train_mask = torch.tensor(train_encodings['attention_mask'])\r\n","train_y = torch.tensor(y_train)\r\n","\r\n","# for validation set\r\n","val_seq = torch.tensor(val_encodings['input_ids'])\r\n","val_mask = torch.tensor(val_encodings['attention_mask'])\r\n","val_y = torch.tensor(y_val)\r\n","\r\n","# for test set\r\n","test_seq = torch.tensor(test_encodings['input_ids'])\r\n","test_mask = torch.tensor(test_encodings['attention_mask'])\r\n","test_y = torch.tensor(y_test)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"h0JkQbxVBmbM","executionInfo":{"status":"ok","timestamp":1610510996763,"user_tz":-210,"elapsed":1015,"user":{"displayName":"mohadese rahnama","photoUrl":"","userId":"03886626379062840142"}},"outputId":"b828bf2e-a36b-47c9-cf44-90296e85c7ac"},"source":["train_y[0]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n","        0, 0, 0, 0, 0, 0])"]},"metadata":{"tags":[]},"execution_count":17}]},{"cell_type":"code","metadata":{"id":"T2xiV6Nb0ddZ"},"source":["from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\r\n","\r\n","#define a batch size\r\n","batch_size = 32\r\n","\r\n","# wrap tensors\r\n","train_data = TensorDataset(train_seq, train_mask, train_y)\r\n","\r\n","# sampler for sampling the data during training\r\n","train_sampler = RandomSampler(train_data)\r\n","\r\n","# dataLoader for train set\r\n","train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\r\n","\r\n","# wrap tensors\r\n","val_data = TensorDataset(val_seq, val_mask, val_y)\r\n","\r\n","# sampler for sampling the data during training\r\n","val_sampler = SequentialSampler(val_data)\r\n","\r\n","# dataLoader for validation set\r\n","val_dataloader = DataLoader(val_data, sampler = val_sampler, batch_size=batch_size)\r\n","\r\n","# wrap tensors\r\n","test_data = TensorDataset(test_seq, test_mask, test_y)\r\n","\r\n","# sampler for sampling the data during training\r\n","test_sampler = SequentialSampler(test_data)\r\n","\r\n","# dataLoader for validation set\r\n","test_dataloader = DataLoader(test_data, sampler = test_sampler, batch_size=batch_size)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":804,"referenced_widgets":["9cad5d68b43f4467915ed12fe1a52be4","b0e63ae99ed44a4cb8256f6d6efb2af1","a040a51a09d441349344877bc1f4ad04","55703f2bc7564bc380d78250434d7da0","4d4a5ce3325b48819c77349587df29e8","32ad198bdc2a404fa1a5224f0bceeb49","8157e1185f0e4f2aa94675bec5522b93","255b5b7d0ff34605bde86f7577ce0626"]},"id":"UwGHXIjGfmaN","executionInfo":{"status":"ok","timestamp":1610511068048,"user_tz":-210,"elapsed":24610,"user":{"displayName":"mohadese rahnama","photoUrl":"","userId":"03886626379062840142"}},"outputId":"ffc57061-f255-43c8-cbd7-40523b9a79f0"},"source":["# example\r\n","\r\n","\r\n","text = [\"this is a bert model tutorial\", \"we will fine-tune a bert model\"]\r\n","\r\n","# encode text\r\n","sent_id = tokenizer.batch_encode_plus(text, padding=True, return_token_type_ids=False)\r\n","print(sent_id)\r\n","\r\n","seq = torch.tensor(sent_id['input_ids'])\r\n","mask = torch.tensor(sent_id['attention_mask'])\r\n","train_y = torch.tensor([0,1])\r\n","\r\n","transformer_model = AutoModel.from_pretrained(\"HooshvareLab/bert-fa-base-uncased-clf-persiannews\")\r\n","cls_hs=transformer_model(seq,mask)\r\n","print(cls_hs)\r\n","print(cls_hs[0])\r\n","print(cls_hs[1])\r\n","print(cls_hs[1].shape)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["{'input_ids': [[2, 32071, 9574, 1026, 89390, 36260, 84378, 40908, 2041, 4, 0], [2, 13632, 25909, 70608, 1011, 40716, 2033, 1026, 89390, 36260, 4]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"9cad5d68b43f4467915ed12fe1a52be4","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=651477729.0, style=ProgressStyle(descri…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n","BaseModelOutputWithPoolingAndCrossAttentions(last_hidden_state=tensor([[[ 0.0526,  0.5571, -0.4614,  ..., -0.0968,  0.4727,  0.1742],\n","         [-0.2566,  1.5509, -2.0229,  ..., -1.1688, -0.4160,  0.1496],\n","         [-0.1851,  0.1336, -1.3189,  ..., -0.5912, -0.4864,  0.4295],\n","         ...,\n","         [-0.2249,  0.1459, -1.4157,  ..., -0.1764,  0.6163, -0.5646],\n","         [-0.3767, -0.2304, -0.3158,  ..., -0.5575,  0.0901,  0.6220],\n","         [-0.2883,  0.2287, -1.5781,  ..., -0.3559,  0.3813,  0.0665]],\n","\n","        [[ 0.0939, -0.5881, -1.2552,  ...,  0.9090,  0.5908, -0.1969],\n","         [-0.2802, -0.9775, -1.5731,  ...,  0.0902,  0.5980, -0.6988],\n","         [-0.2920, -0.6260, -0.9620,  ..., -0.4935,  0.6855, -1.1112],\n","         ...,\n","         [-0.1571, -0.1198, -2.0160,  ...,  0.3612,  0.7098, -0.9345],\n","         [-0.0399, -0.9591, -1.5613,  ...,  0.6662,  0.1020, -0.0502],\n","         [-0.4564, -1.5508, -0.4116,  ..., -0.1108,  1.1311,  0.2711]]],\n","       grad_fn=<NativeLayerNormBackward>), pooler_output=tensor([[ 0.7309, -0.4917, -0.7028,  ...,  0.3011,  0.4490, -0.6379],\n","        [ 0.9530,  0.1168, -0.2492,  ..., -0.4421,  0.0763, -0.8724]],\n","       grad_fn=<TanhBackward>), hidden_states=None, attentions=None, cross_attentions=None)\n","tensor([[[ 0.0526,  0.5571, -0.4614,  ..., -0.0968,  0.4727,  0.1742],\n","         [-0.2566,  1.5509, -2.0229,  ..., -1.1688, -0.4160,  0.1496],\n","         [-0.1851,  0.1336, -1.3189,  ..., -0.5912, -0.4864,  0.4295],\n","         ...,\n","         [-0.2249,  0.1459, -1.4157,  ..., -0.1764,  0.6163, -0.5646],\n","         [-0.3767, -0.2304, -0.3158,  ..., -0.5575,  0.0901,  0.6220],\n","         [-0.2883,  0.2287, -1.5781,  ..., -0.3559,  0.3813,  0.0665]],\n","\n","        [[ 0.0939, -0.5881, -1.2552,  ...,  0.9090,  0.5908, -0.1969],\n","         [-0.2802, -0.9775, -1.5731,  ...,  0.0902,  0.5980, -0.6988],\n","         [-0.2920, -0.6260, -0.9620,  ..., -0.4935,  0.6855, -1.1112],\n","         ...,\n","         [-0.1571, -0.1198, -2.0160,  ...,  0.3612,  0.7098, -0.9345],\n","         [-0.0399, -0.9591, -1.5613,  ...,  0.6662,  0.1020, -0.0502],\n","         [-0.4564, -1.5508, -0.4116,  ..., -0.1108,  1.1311,  0.2711]]],\n","       grad_fn=<NativeLayerNormBackward>)\n","tensor([[ 0.7309, -0.4917, -0.7028,  ...,  0.3011,  0.4490, -0.6379],\n","        [ 0.9530,  0.1168, -0.2492,  ..., -0.4421,  0.0763, -0.8724]],\n","       grad_fn=<TanhBackward>)\n","torch.Size([2, 768])\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"ByUEn_v4zknn"},"source":["## Model"]},{"cell_type":"code","metadata":{"id":"n3AjEaHcEMfb"},"source":["transformer_model = AutoModel.from_pretrained(\"HooshvareLab/bert-fa-base-uncased-clf-persiannews\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"RaAlYydhxPTd"},"source":["# freeze all the parameters\r\n","for param in transformer_model.parameters():\r\n","    param.requires_grad = False"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nUa1R1WQONe6","executionInfo":{"elapsed":1257,"status":"ok","timestamp":1610106239957,"user":{"displayName":"mohadese rahnama","photoUrl":"","userId":"03886626379062840142"},"user_tz":-210},"outputId":"2f67bcf6-b8d0-4796-9e3a-93162ab50275"},"source":["len(labels)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["78"]},"metadata":{"tags":[]},"execution_count":12}]},{"cell_type":"code","metadata":{"id":"oyE_ThEms5aZ"},"source":["class BERT_Arch(nn.Module):\r\n","\r\n","    def __init__(self, bert):\r\n","      \r\n","      super(BERT_Arch, self).__init__()\r\n","\r\n","      self.bert = bert \r\n","      \r\n","      # dropout layer\r\n","      self.dropout = nn.Dropout(0.1)\r\n","      \r\n","      # relu activation function\r\n","      self.relu =  nn.ReLU()\r\n","\r\n","      # dense layer 1\r\n","      self.fc1 = nn.Linear(768,512)\r\n","      \r\n","      # dense layer 2 (Output layer)\r\n","      self.fc2 = nn.Linear(512,78)\r\n","\r\n","      #sigmoid activation function\r\n","      self.sigmoid = nn.Sigmoid()\r\n","\r\n","    #define the forward pass\r\n","    def forward(self, sent_id, mask):\r\n","\r\n","      #pass the inputs to the model  \r\n","      cls_hs = self.bert(sent_id, attention_mask=mask)\r\n","      \r\n","      x = self.fc1(cls_hs[1])\r\n","\r\n","      x = self.relu(x)\r\n","\r\n","      x = self.dropout(x)\r\n","\r\n","      # output layer\r\n","      x = self.fc2(x)\r\n","      \r\n","      # apply sigmoid activation\r\n","      x = self.sigmoid(x)\r\n","\r\n","      return x"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"rDuHzo96z6z8"},"source":["# pass the pre-trained BERT to our define architecture\n","model = BERT_Arch(transformer_model)\n","\n","# push the model to GPU\n","model = model.to(device)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"FUNSLBYcLc9q"},"source":["# optimizer from hugging face transformers\n","from transformers import AdamW\n","\n","# define the optimizer\n","optimizer = AdamW(model.parameters(), lr = 1e-3)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ArHmwhh7JrZh"},"source":["loss_func =nn.MultiLabelSoftMarginLoss()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"c8LjQyDXs0bG"},"source":["# function to train the model\r\n","def train():\r\n","  \r\n","  model.train()\r\n","\r\n","  total_loss, total_accuracy = 0, 0\r\n","  \r\n","  # empty list to save model predictions\r\n","  total_preds=[]\r\n","  \r\n","  # iterate over batches\r\n","  for step,batch in enumerate(train_dataloader):\r\n","    \r\n","    # progress update after every 50 batches.\r\n","    if step % 50 == 0 and not step == 0:\r\n","      print('  Batch {:>5,}  of  {:>5,}.'.format(step, len(train_dataloader)))\r\n","\r\n","    # push the batch to gpu\r\n","    batch = [r.to(device) for r in batch]\r\n"," \r\n","    sent_id, mask, labels = batch\r\n","\r\n","    # clear previously calculated gradients \r\n","    model.zero_grad()        \r\n","\r\n","    # get model predictions for the current batch\r\n","    preds = model(sent_id, mask)\r\n","\r\n","    # compute the loss between actual and predicted values\r\n","    \r\n","    loss = loss_func(preds, labels)\r\n","    # add on to the total loss\r\n","    total_loss = total_loss + loss.item()\r\n","\r\n","    # backward pass to calculate the gradients\r\n","    loss.backward()\r\n","\r\n","    # clip the the gradients to 1.0. It helps in preventing the exploding gradient problem\r\n","    torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\r\n","\r\n","    # update parameters\r\n","    optimizer.step()\r\n","\r\n","    # model predictions are stored on GPU. So, push it to CPU\r\n","    preds=preds.detach().cpu().numpy()\r\n","\r\n","    # append the model predictions\r\n","    total_preds.append(preds)\r\n","\r\n","  # compute the training loss of the epoch\r\n","  avg_loss = total_loss / len(train_dataloader)\r\n","  \r\n","  # predictions are in the form of (no. of batches, size of batch, no. of classes).\r\n","  # reshape the predictions in form of (number of samples, no. of classes)\r\n","  total_preds  = numpy.concatenate(total_preds, axis=0)\r\n","\r\n","  #returns the loss and predictions\r\n","  return avg_loss, total_preds"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XNBRQo9WMHey"},"source":["# function for evaluating the model\r\n","def evaluate():\r\n","  \r\n","  print(\"\\nEvaluating...\")\r\n","  \r\n","  # deactivate dropout layers\r\n","  model.eval()\r\n","\r\n","  total_loss, total_accuracy = 0, 0\r\n","  \r\n","  # empty list to save the model predictions\r\n","  total_preds = []\r\n","\r\n","  # iterate over batches\r\n","  for step,batch in enumerate(val_dataloader):\r\n","    \r\n","    # Progress update every 50 batches.\r\n","    if step % 50 == 0 and not step == 0:\r\n","      \r\n","      # Calculate elapsed time in minutes.\r\n","      # elapsed = format_time(time.time() - t0)\r\n","            \r\n","      # Report progress.\r\n","      print('  Batch {:>5,}  of  {:>5,}.'.format(step, len(val_dataloader)))\r\n","\r\n","    # push the batch to gpu\r\n","    batch = [t.to(device) for t in batch]\r\n","\r\n","    sent_id, mask, labels = batch\r\n","\r\n","    # deactivate autograd\r\n","    with torch.no_grad():\r\n","      \r\n","      # model predictions\r\n","      preds = model(sent_id, mask)\r\n","\r\n","      # compute the validation loss between actual and predicted values\r\n","      loss = loss_func(preds,labels)\r\n","\r\n","      total_loss = total_loss + loss.item()\r\n","\r\n","      preds = preds.detach().cpu().numpy()\r\n","\r\n","      total_preds.append(preds)\r\n","\r\n","  # compute the validation loss of the epoch\r\n","  avg_loss = total_loss / len(val_dataloader) \r\n","\r\n","  # reshape the predictions in form of (number of samples, no. of classes)\r\n","  total_preds  = numpy.concatenate(total_preds, axis=0)\r\n","\r\n","  return avg_loss, total_preds"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Qu5pfrJKtTc0","executionInfo":{"status":"ok","timestamp":1610512540238,"user_tz":-210,"elapsed":355348,"user":{"displayName":"mohadese rahnama","photoUrl":"","userId":"03886626379062840142"}},"outputId":"f65aec90-cc63-4b9f-f1c5-d41282caca3f"},"source":["# number of training epochs\r\n","epochs = 10\r\n","\r\n","# set initial loss to infinite\r\n","best_valid_loss = float('inf')\r\n","\r\n","# empty lists to store training and validation loss of each epoch\r\n","train_losses=[]\r\n","valid_losses=[]\r\n","\r\n","#for each epoch\r\n","for epoch in range(epochs):\r\n","     \r\n","    print('\\n Epoch {:} / {:}'.format(epoch + 1, epochs))\r\n","    \r\n","    #train model\r\n","    train_loss, _ = train()\r\n","    \r\n","    #evaluate model\r\n","    valid_loss, _ = evaluate()\r\n","    \r\n","    #save the best model\r\n","    if valid_loss < best_valid_loss:\r\n","        best_valid_loss = valid_loss\r\n","        torch.save(model.state_dict(), 'saved_weights.pt')\r\n","    \r\n","    # append training and validation loss\r\n","    train_losses.append(train_loss)\r\n","    valid_losses.append(valid_loss)\r\n","    \r\n","    print(f'\\nTraining Loss: {train_loss:.3f}')\r\n","    print(f'Validation Loss: {valid_loss:.3f}')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\n"," Epoch 1 / 10\n","  Batch    50  of    403.\n","  Batch   100  of    403.\n","  Batch   150  of    403.\n","  Batch   200  of    403.\n","  Batch   250  of    403.\n","  Batch   300  of    403.\n","  Batch   350  of    403.\n","  Batch   400  of    403.\n","\n","Evaluating...\n","  Batch    50  of    135.\n","  Batch   100  of    135.\n","\n","Training Loss: 0.696\n","Validation Loss: 0.693\n","\n"," Epoch 2 / 10\n","  Batch    50  of    403.\n","  Batch   100  of    403.\n","  Batch   150  of    403.\n","  Batch   200  of    403.\n","  Batch   250  of    403.\n","  Batch   300  of    403.\n","  Batch   350  of    403.\n","  Batch   400  of    403.\n","\n","Evaluating...\n","  Batch    50  of    135.\n","  Batch   100  of    135.\n","\n","Training Loss: 0.693\n","Validation Loss: 0.693\n","\n"," Epoch 3 / 10\n","  Batch    50  of    403.\n","  Batch   100  of    403.\n","  Batch   150  of    403.\n","  Batch   200  of    403.\n","  Batch   250  of    403.\n","  Batch   300  of    403.\n","  Batch   350  of    403.\n","  Batch   400  of    403.\n","\n","Evaluating...\n","  Batch    50  of    135.\n","  Batch   100  of    135.\n","\n","Training Loss: 0.693\n","Validation Loss: 0.693\n","\n"," Epoch 4 / 10\n","  Batch    50  of    403.\n","  Batch   100  of    403.\n","  Batch   150  of    403.\n","  Batch   200  of    403.\n","  Batch   250  of    403.\n","  Batch   300  of    403.\n","  Batch   350  of    403.\n","  Batch   400  of    403.\n","\n","Evaluating...\n","  Batch    50  of    135.\n","  Batch   100  of    135.\n","\n","Training Loss: 0.693\n","Validation Loss: 0.693\n","\n"," Epoch 5 / 10\n","  Batch    50  of    403.\n","  Batch   100  of    403.\n","  Batch   150  of    403.\n","  Batch   200  of    403.\n","  Batch   250  of    403.\n","  Batch   300  of    403.\n","  Batch   350  of    403.\n","  Batch   400  of    403.\n","\n","Evaluating...\n","  Batch    50  of    135.\n","  Batch   100  of    135.\n","\n","Training Loss: 0.693\n","Validation Loss: 0.693\n","\n"," Epoch 6 / 10\n","  Batch    50  of    403.\n","  Batch   100  of    403.\n","  Batch   150  of    403.\n","  Batch   200  of    403.\n","  Batch   250  of    403.\n","  Batch   300  of    403.\n","  Batch   350  of    403.\n","  Batch   400  of    403.\n","\n","Evaluating...\n","  Batch    50  of    135.\n","  Batch   100  of    135.\n","\n","Training Loss: 0.693\n","Validation Loss: 0.693\n","\n"," Epoch 7 / 10\n","  Batch    50  of    403.\n","  Batch   100  of    403.\n","  Batch   150  of    403.\n","  Batch   200  of    403.\n","  Batch   250  of    403.\n","  Batch   300  of    403.\n","  Batch   350  of    403.\n","  Batch   400  of    403.\n","\n","Evaluating...\n","  Batch    50  of    135.\n","  Batch   100  of    135.\n","\n","Training Loss: 0.693\n","Validation Loss: 0.693\n","\n"," Epoch 8 / 10\n","  Batch    50  of    403.\n","  Batch   100  of    403.\n","  Batch   150  of    403.\n","  Batch   200  of    403.\n","  Batch   250  of    403.\n","  Batch   300  of    403.\n","  Batch   350  of    403.\n","  Batch   400  of    403.\n","\n","Evaluating...\n","  Batch    50  of    135.\n","  Batch   100  of    135.\n","\n","Training Loss: 0.693\n","Validation Loss: 0.693\n","\n"," Epoch 9 / 10\n","  Batch    50  of    403.\n","  Batch   100  of    403.\n","  Batch   150  of    403.\n","  Batch   200  of    403.\n","  Batch   250  of    403.\n","  Batch   300  of    403.\n","  Batch   350  of    403.\n","  Batch   400  of    403.\n","\n","Evaluating...\n","  Batch    50  of    135.\n","  Batch   100  of    135.\n","\n","Training Loss: 0.693\n","Validation Loss: 0.693\n","\n"," Epoch 10 / 10\n","  Batch    50  of    403.\n","  Batch   100  of    403.\n","  Batch   150  of    403.\n","  Batch   200  of    403.\n","  Batch   250  of    403.\n","  Batch   300  of    403.\n","  Batch   350  of    403.\n","  Batch   400  of    403.\n","\n","Evaluating...\n","  Batch    50  of    135.\n","  Batch   100  of    135.\n","\n","Training Loss: 0.693\n","Validation Loss: 0.693\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"cQ2_aS0zCLvp"},"source":["Loading saved model:"]},{"cell_type":"code","metadata":{"id":"cvR-FhPpuLkR"},"source":["# torch.cuda.empty_cache()\r\n","# pass the pre-trained BERT to our define architecture\r\n","model = BERT_Arch(transformer_model)\r\n","\r\n","# push the model to GPU\r\n","model = model.to(device)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3aOPRZ2jVvNR","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1610509380028,"user_tz":-210,"elapsed":4470,"user":{"displayName":"mohadese rahnama","photoUrl":"","userId":"03886626379062840142"}},"outputId":"8b608ad9-767d-4856-fcbe-443cc3ea4356"},"source":["#load weights of best model\r\n","path = 'saved_weights.pt'\r\n","model.load_state_dict(torch.load(path))"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<All keys matched successfully>"]},"metadata":{"tags":[]},"execution_count":18}]},{"cell_type":"markdown","metadata":{"id":"PM1uUcZFCPVg"},"source":["After loading model:"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XZhHObMnzuws","executionInfo":{"status":"ok","timestamp":1610512659970,"user_tz":-210,"elapsed":36569,"user":{"displayName":"mohadese rahnama","photoUrl":"","userId":"03886626379062840142"}},"outputId":"8cd3d5f9-c261-417e-f659-7f1de4417d39"},"source":["y_pred=[]\r\n","y_true=[]\r\n","for step,batch in enumerate(test_dataloader):\r\n","    \r\n","    # Progress update every 50 batches.\r\n","    if step % 50 == 0 and not step == 0:\r\n","      \r\n","      # Calculate elapsed time in minutes.\r\n","      # elapsed = format_time(time.time() - t0)\r\n","            \r\n","      # Report progress.\r\n","      print('  Batch {:>5,}  of  {:>5,}.'.format(step, len(test_dataloader)))\r\n","\r\n","    # push the batch to gpu\r\n","    batch = [t.to(device) for t in batch]\r\n","\r\n","    sent_id, mask, labels = batch\r\n","\r\n","    # deactivate autograd\r\n","    with torch.no_grad():\r\n","      \r\n","      # model predictions\r\n","      preds = model(sent_id, mask)\r\n","      # print(preds)\r\n","      # print(preds.cpu().numpy())\r\n","      preds = preds.cpu().numpy()\r\n","      # model's performance\r\n","    # preds = numpy.argmax(preds, axis = 1)\r\n","    \r\n","    measure = numpy.mean(preds[0]) + 1.15*numpy.sqrt(numpy.var(preds[0]))\r\n","    for l in preds:\r\n","      temp=[]\r\n","      for value in l:\r\n","        if value >= measure:\r\n","          temp.append(1)\r\n","        else:\r\n","          temp.append(0)\r\n","      y_pred.append(temp)\r\n","    y_true.extend(labels.cpu().numpy())\r\n","    # print(labels.cpu().numpy()[0], preds[0])\r\n","print(classification_report(y_true, y_pred))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["  Batch    50  of    135.\n","  Batch   100  of    135.\n","              precision    recall  f1-score   support\n","\n","           0       0.02      0.51      0.05       107\n","           1       0.04      0.27      0.06       153\n","           2       0.03      0.29      0.05       150\n","           3       0.00      0.17      0.00        18\n","           4       0.03      0.30      0.05        87\n","           5       0.00      0.29      0.01        17\n","           6       0.03      0.47      0.06       150\n","           7       0.01      0.46      0.02        41\n","           8       0.01      0.53      0.01        30\n","           9       0.02      0.43      0.05       106\n","          10       0.03      0.34      0.05       131\n","          11       0.01      0.21      0.03        68\n","          12       0.04      0.37      0.08       157\n","          13       0.00      0.22      0.01        18\n","          14       0.00      0.29      0.01        17\n","          15       0.03      0.53      0.07       150\n","          16       0.02      0.14      0.03       139\n","          17       0.05      0.49      0.08       160\n","          18       0.02      0.17      0.03       119\n","          19       0.01      0.58      0.03        64\n","          20       0.03      0.49      0.06       136\n","          21       0.03      0.35      0.05       134\n","          22       0.01      0.39      0.01        31\n","          23       0.03      0.33      0.05       150\n","          24       0.01      0.19      0.02        80\n","          25       0.03      0.53      0.06       124\n","          26       0.03      0.24      0.05       148\n","          27       0.02      0.17      0.03       132\n","          28       0.03      0.32      0.05       145\n","          29       0.02      0.21      0.04       154\n","          30       0.02      0.32      0.03        69\n","          31       0.02      0.51      0.05        84\n","          32       0.03      0.61      0.06       130\n","          33       0.03      0.45      0.06       146\n","          34       0.02      0.69      0.04        80\n","          35       0.03      0.36      0.05       132\n","          36       0.04      0.38      0.07       153\n","          37       0.01      0.15      0.02        73\n","          38       0.01      0.35      0.03        43\n","          39       0.01      0.39      0.01        33\n","          40       0.04      0.36      0.07       187\n","          41       0.01      0.07      0.01       115\n","          42       0.01      0.29      0.03        73\n","          43       0.02      0.26      0.05       150\n","          44       0.03      0.24      0.05       148\n","          45       0.00      0.25      0.00        16\n","          46       0.01      0.34      0.01        35\n","          47       0.01      0.19      0.03       124\n","          48       0.02      0.20      0.03       132\n","          49       0.02      0.55      0.03        66\n","          50       0.00      0.15      0.00        20\n","          51       0.01      0.36      0.01        28\n","          52       0.01      0.59      0.03        41\n","          53       0.02      0.41      0.03        90\n","          54       0.02      0.24      0.04       131\n","          55       0.01      0.30      0.02        37\n","          56       0.02      0.65      0.03        62\n","          57       0.02      0.64      0.05        55\n","          58       0.05      0.48      0.09       148\n","          59       0.04      0.34      0.06       157\n","          60       0.06      0.56      0.11       157\n","          61       0.01      0.46      0.03        54\n","          62       0.03      0.29      0.05       153\n","          63       0.03      0.37      0.05       140\n","          64       0.02      0.35      0.04        85\n","          65       0.03      0.27      0.05       155\n","          66       0.01      0.45      0.02        31\n","          67       0.03      0.30      0.06       106\n","          68       0.29      0.52      0.37       145\n","          69       0.03      0.42      0.05       131\n","          70       0.04      0.30      0.07       161\n","          71       0.03      0.29      0.06       164\n","          72       0.03      0.38      0.06       115\n","          73       0.01      0.33      0.02        40\n","          74       0.01      0.35      0.01        31\n","          75       0.04      0.46      0.07       159\n","          76       0.02      0.51      0.03        69\n","          77       0.03      0.46      0.06       114\n","\n","   micro avg       0.02      0.36      0.04      7884\n","   macro avg       0.02      0.37      0.04      7884\n","weighted avg       0.03      0.36      0.06      7884\n"," samples avg       0.01      0.38      0.02      7884\n","\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"],"name":"stderr"}]}]}