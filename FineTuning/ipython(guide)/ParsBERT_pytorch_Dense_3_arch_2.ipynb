{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"ParsBERT_pytorch_Dense_3_arch_2.ipynb","provenance":[{"file_id":"1k6QLcPAJKT5H2yTy61U-YCB267inolmb","timestamp":1610512876213},{"file_id":"1AIm-KimERCJutlpyjiZ2IAwM-cCrVsWM","timestamp":1610440221899},{"file_id":"17mqUcShahUjZjQxywgKQSGU1jV-CZW8o","timestamp":1610336820188},{"file_id":"1FgtzYXY0CXNyE_2FU4IEqJTQzmVZNvDh","timestamp":1610105938882}],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"widgets":{"application/vnd.jupyter.widget-state+json":{"005f74c45bdb48149dc5f8a7319d72d8":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_2a2134a7e8334f89a94093016d2b777d","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_87cb27ad58b24a0f828632275bd72b28","IPY_MODEL_0a79d0b4b4714313b55ffc760cc68c03"]}},"2a2134a7e8334f89a94093016d2b777d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"87cb27ad58b24a0f828632275bd72b28":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_2371bc6668c14d7a9f9edc6f11259cd2","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":1441,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1441,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_5fd93361b16e49b4aa2b9f7b3e95f693"}},"0a79d0b4b4714313b55ffc760cc68c03":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_c0b6cc6a3c054c60a729742099e17356","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 1.44k/1.44k [00:00&lt;00:00, 2.96kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_d168d74cc5a34c5f89da8382aa4859d8"}},"2371bc6668c14d7a9f9edc6f11259cd2":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"5fd93361b16e49b4aa2b9f7b3e95f693":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"c0b6cc6a3c054c60a729742099e17356":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"d168d74cc5a34c5f89da8382aa4859d8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"7b26b05e23a540f1bb18e9824ca7fe6e":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_174ee9ceaf644a6fb6372334b64c52aa","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_6271830c7c554562a1ee3b71fb705518","IPY_MODEL_97524ce4763e49b7b5b7f059b7a385cd"]}},"174ee9ceaf644a6fb6372334b64c52aa":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"6271830c7c554562a1ee3b71fb705518":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_5bcd3bca4d1144cfb6bc6176041de1d4","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":1198122,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1198122,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_83cd548ce4e243fda9f6af4de26afda2"}},"97524ce4763e49b7b5b7f059b7a385cd":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_903127f858054433bf129b52f865181c","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 1.20M/1.20M [00:00&lt;00:00, 6.98MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_e3580a1d0e9a4dc0ac2a09b0e9cf4f7f"}},"5bcd3bca4d1144cfb6bc6176041de1d4":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"83cd548ce4e243fda9f6af4de26afda2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"903127f858054433bf129b52f865181c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"e3580a1d0e9a4dc0ac2a09b0e9cf4f7f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"bc969cd6c3b447c292078343fc9dddcf":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_845bf2655d064d5fb2bf1e8e7708a370","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_14463c4ae2b741bf825dadd37cb6d3d8","IPY_MODEL_61b6367eb2884e739e87bce85045580b"]}},"845bf2655d064d5fb2bf1e8e7708a370":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"14463c4ae2b741bf825dadd37cb6d3d8":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_2e9dc03222b247db9efb02d7e57cc488","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":112,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":112,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_093a6850e2bc40498bdf3c1528b9c4d3"}},"61b6367eb2884e739e87bce85045580b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_220e691b359e4c8c95b0bd426703d7e5","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 112/112 [00:00&lt;00:00, 496B/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_fd519bdb80ca45f99fc08bc7714b55bf"}},"2e9dc03222b247db9efb02d7e57cc488":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"093a6850e2bc40498bdf3c1528b9c4d3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"220e691b359e4c8c95b0bd426703d7e5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"fd519bdb80ca45f99fc08bc7714b55bf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"110e1018b83844c4b3ce9a52c045bd1a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_92bbe90e2ffd41f3b7c8cb6e90bfff03","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_5068b187242d4adda4596015d54856db","IPY_MODEL_5bb27eec533b43d6b3510be06db9cf51"]}},"92bbe90e2ffd41f3b7c8cb6e90bfff03":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"5068b187242d4adda4596015d54856db":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_d038c4128d6f456199496b16b1bee8f6","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":62,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":62,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_39ae97f1923146388baed2c871e7b061"}},"5bb27eec533b43d6b3510be06db9cf51":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_bb10941a92fc4c33835a22d9d08ff847","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 62.0/62.0 [00:00&lt;00:00, 476B/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_7c84898491264b19a8fb20ddaf722150"}},"d038c4128d6f456199496b16b1bee8f6":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"39ae97f1923146388baed2c871e7b061":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"bb10941a92fc4c33835a22d9d08ff847":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"7c84898491264b19a8fb20ddaf722150":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"6c1ec0e26da047a8a97544c6bdf08e8a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_8c7bdeede5894115941c4597cc913210","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_386e0764eb59489fb902b5e651e24c66","IPY_MODEL_8ef629e33e2d4f1dae1bcbff1bcc3a9a"]}},"8c7bdeede5894115941c4597cc913210":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"386e0764eb59489fb902b5e651e24c66":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_12d4225ba1624245ac378b802dae39ac","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":651477729,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":651477729,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_674c72ec223c4635b635c41f511eda27"}},"8ef629e33e2d4f1dae1bcbff1bcc3a9a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_aea3fb6c20744259817fe361c065dc1e","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 651M/651M [00:15&lt;00:00, 41.8MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_a9a82c779fd84edca74c5ad52a19da87"}},"12d4225ba1624245ac378b802dae39ac":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"674c72ec223c4635b635c41f511eda27":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"aea3fb6c20744259817fe361c065dc1e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"a9a82c779fd84edca74c5ad52a19da87":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"markdown","metadata":{"id":"j1LTPn7IjqTz"},"source":["Source:\r\n","\r\n","huggingface: https://huggingface.co/HooshvareLab/bert-fa-base-uncased-clf-persiannews\r\n","\r\n","Tutorial:https://towardsdatascience.com/fine-tuning-hugging-face-model-with-custom-dataset-82b8092f5333"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OmPFvCbSqyZF","executionInfo":{"status":"ok","timestamp":1610537091678,"user_tz":-210,"elapsed":480349,"user":{"displayName":"zeinab taghavi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GheNU3ejtJBEFfDC_0W_JdLEuwkW7SKnnDuH80MRA=s64","userId":"07214630829740929140"}},"outputId":"4fd1ae81-b62e-4228-b77c-fd1bc5472c17"},"source":["from google.colab import drive\r\n","drive.mount('/content/drive')"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"iRxC0Pz1qzKc","executionInfo":{"status":"ok","timestamp":1610537091680,"user_tz":-210,"elapsed":480349,"user":{"displayName":"zeinab taghavi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GheNU3ejtJBEFfDC_0W_JdLEuwkW7SKnnDuH80MRA=s64","userId":"07214630829740929140"}}},"source":["import os\r\n","os.chdir('/content/drive/MyDrive/sharif/FineTuning/ipython(guide)')"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mCRkKc3NcgkX","executionInfo":{"status":"ok","timestamp":1610537095381,"user_tz":-210,"elapsed":484043,"user":{"displayName":"zeinab taghavi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GheNU3ejtJBEFfDC_0W_JdLEuwkW7SKnnDuH80MRA=s64","userId":"07214630829740929140"}},"outputId":"d6966ec5-b56e-4e2f-979f-ab0058cdaa50"},"source":["!pip install transformers"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Collecting transformers\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/50/0c/7d5950fcd80b029be0a8891727ba21e0cd27692c407c51261c3c921f6da3/transformers-4.1.1-py3-none-any.whl (1.5MB)\n","\r\u001b[K     |▏                               | 10kB 22.4MB/s eta 0:00:01\r\u001b[K     |▍                               | 20kB 20.5MB/s eta 0:00:01\r\u001b[K     |▋                               | 30kB 17.6MB/s eta 0:00:01\r\u001b[K     |▉                               | 40kB 16.6MB/s eta 0:00:01\r\u001b[K     |█                               | 51kB 13.3MB/s eta 0:00:01\r\u001b[K     |█▎                              | 61kB 13.1MB/s eta 0:00:01\r\u001b[K     |█▌                              | 71kB 14.6MB/s eta 0:00:01\r\u001b[K     |█▊                              | 81kB 14.0MB/s eta 0:00:01\r\u001b[K     |██                              | 92kB 14.7MB/s eta 0:00:01\r\u001b[K     |██▏                             | 102kB 14.3MB/s eta 0:00:01\r\u001b[K     |██▍                             | 112kB 14.3MB/s eta 0:00:01\r\u001b[K     |██▋                             | 122kB 14.3MB/s eta 0:00:01\r\u001b[K     |██▉                             | 133kB 14.3MB/s eta 0:00:01\r\u001b[K     |███                             | 143kB 14.3MB/s eta 0:00:01\r\u001b[K     |███▎                            | 153kB 14.3MB/s eta 0:00:01\r\u001b[K     |███▌                            | 163kB 14.3MB/s eta 0:00:01\r\u001b[K     |███▊                            | 174kB 14.3MB/s eta 0:00:01\r\u001b[K     |████                            | 184kB 14.3MB/s eta 0:00:01\r\u001b[K     |████▏                           | 194kB 14.3MB/s eta 0:00:01\r\u001b[K     |████▎                           | 204kB 14.3MB/s eta 0:00:01\r\u001b[K     |████▌                           | 215kB 14.3MB/s eta 0:00:01\r\u001b[K     |████▊                           | 225kB 14.3MB/s eta 0:00:01\r\u001b[K     |█████                           | 235kB 14.3MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 245kB 14.3MB/s eta 0:00:01\r\u001b[K     |█████▍                          | 256kB 14.3MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 266kB 14.3MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 276kB 14.3MB/s eta 0:00:01\r\u001b[K     |██████                          | 286kB 14.3MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 296kB 14.3MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 307kB 14.3MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 317kB 14.3MB/s eta 0:00:01\r\u001b[K     |███████                         | 327kB 14.3MB/s eta 0:00:01\r\u001b[K     |███████▏                        | 337kB 14.3MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 348kB 14.3MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 358kB 14.3MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 368kB 14.3MB/s eta 0:00:01\r\u001b[K     |████████                        | 378kB 14.3MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 389kB 14.3MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 399kB 14.3MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 409kB 14.3MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 419kB 14.3MB/s eta 0:00:01\r\u001b[K     |█████████                       | 430kB 14.3MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 440kB 14.3MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 450kB 14.3MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 460kB 14.3MB/s eta 0:00:01\r\u001b[K     |██████████                      | 471kB 14.3MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 481kB 14.3MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 491kB 14.3MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 501kB 14.3MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 512kB 14.3MB/s eta 0:00:01\r\u001b[K     |███████████                     | 522kB 14.3MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 532kB 14.3MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 542kB 14.3MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 552kB 14.3MB/s eta 0:00:01\r\u001b[K     |████████████                    | 563kB 14.3MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 573kB 14.3MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 583kB 14.3MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 593kB 14.3MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 604kB 14.3MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 614kB 14.3MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 624kB 14.3MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 634kB 14.3MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 645kB 14.3MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 655kB 14.3MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 665kB 14.3MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 675kB 14.3MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 686kB 14.3MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 696kB 14.3MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 706kB 14.3MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 716kB 14.3MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 727kB 14.3MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 737kB 14.3MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 747kB 14.3MB/s eta 0:00:01\r\u001b[K     |████████████████                | 757kB 14.3MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 768kB 14.3MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 778kB 14.3MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 788kB 14.3MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 798kB 14.3MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 808kB 14.3MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 819kB 14.3MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 829kB 14.3MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 839kB 14.3MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 849kB 14.3MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 860kB 14.3MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 870kB 14.3MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 880kB 14.3MB/s eta 0:00:01\r\u001b[K     |██████████████████▉             | 890kB 14.3MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 901kB 14.3MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 911kB 14.3MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 921kB 14.3MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 931kB 14.3MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 942kB 14.3MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 952kB 14.3MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 962kB 14.3MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 972kB 14.3MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 983kB 14.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 993kB 14.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 1.0MB 14.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 1.0MB 14.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 1.0MB 14.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 1.0MB 14.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 1.0MB 14.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 1.1MB 14.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 1.1MB 14.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 1.1MB 14.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 1.1MB 14.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 1.1MB 14.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 1.1MB 14.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 1.1MB 14.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 1.1MB 14.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 1.1MB 14.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 1.1MB 14.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 1.2MB 14.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 1.2MB 14.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 1.2MB 14.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 1.2MB 14.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 1.2MB 14.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 1.2MB 14.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 1.2MB 14.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 1.2MB 14.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 1.2MB 14.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 1.2MB 14.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▋     | 1.3MB 14.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 1.3MB 14.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 1.3MB 14.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 1.3MB 14.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 1.3MB 14.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 1.3MB 14.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 1.3MB 14.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 1.3MB 14.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 1.3MB 14.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 1.4MB 14.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 1.4MB 14.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 1.4MB 14.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▎  | 1.4MB 14.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 1.4MB 14.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 1.4MB 14.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 1.4MB 14.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 1.4MB 14.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 1.4MB 14.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 1.4MB 14.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 1.5MB 14.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 1.5MB 14.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 1.5MB 14.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 1.5MB 14.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 1.5MB 14.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 1.5MB 14.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.5MB 14.3MB/s \n","\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.19.5)\n","Collecting tokenizers==0.9.4\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0f/1c/e789a8b12e28be5bc1ce2156cf87cb522b379be9cadc7ad8091a4cc107c4/tokenizers-0.9.4-cp36-cp36m-manylinux2010_x86_64.whl (2.9MB)\n","\u001b[K     |████████████████████████████████| 2.9MB 47.6MB/s \n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n","Collecting sacremoses\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n","\u001b[K     |████████████████████████████████| 890kB 50.8MB/s \n","\u001b[?25hRequirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.8)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.8)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.12.5)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.15.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.0.0)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n","Building wheels for collected packages: sacremoses\n","  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893261 sha256=400740ff6de4e968a687f35289b9d29fefa17a9f670df84919ced4c664c69717\n","  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n","Successfully built sacremoses\n","Installing collected packages: tokenizers, sacremoses, transformers\n","Successfully installed sacremoses-0.0.43 tokenizers-0.9.4 transformers-4.1.1\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ODc44DglgNjZ","executionInfo":{"status":"ok","timestamp":1610537097932,"user_tz":-210,"elapsed":486589,"user":{"displayName":"zeinab taghavi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GheNU3ejtJBEFfDC_0W_JdLEuwkW7SKnnDuH80MRA=s64","userId":"07214630829740929140"}},"outputId":"f6217c64-7147-41fd-8bde-849ce89362d0"},"source":["!pip3 install sentencepiece"],"execution_count":5,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: sentencepiece in /usr/local/lib/python3.6/dist-packages (0.1.95)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qJY_L2p9a0t0","executionInfo":{"status":"ok","timestamp":1610537097933,"user_tz":-210,"elapsed":486584,"user":{"displayName":"zeinab taghavi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GheNU3ejtJBEFfDC_0W_JdLEuwkW7SKnnDuH80MRA=s64","userId":"07214630829740929140"}},"outputId":"1872943d-6b32-43e5-9d99-7d19242d13ce"},"source":["!git clone https://huggingface.co/HooshvareLab/bert-fa-base-uncased-clf-persiannews\r\n","GIT_LFS_SKIP_SMUDGE=1"],"execution_count":6,"outputs":[{"output_type":"stream","text":["fatal: destination path 'bert-fa-base-uncased-clf-persiannews' already exists and is not an empty directory.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Eg3Up037nThu","executionInfo":{"status":"ok","timestamp":1610537105926,"user_tz":-210,"elapsed":494575,"user":{"displayName":"zeinab taghavi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GheNU3ejtJBEFfDC_0W_JdLEuwkW7SKnnDuH80MRA=s64","userId":"07214630829740929140"}}},"source":["import torch\r\n","import numpy\r\n","import pandas\r\n","import re\r\n","from sklearn.preprocessing import MultiLabelBinarizer\r\n","from sklearn.model_selection import train_test_split\r\n","from transformers import AutoTokenizer, AutoModelForSequenceClassification,AutoConfig,TFAutoModel,AutoModel\r\n","from transformers import BertConfig, BertTokenizer\r\n","from transformers import TFBertModel, TFBertForSequenceClassification\r\n","from transformers import glue_convert_examples_to_features, InputExample\r\n","from sklearn.metrics import classification_report"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"2Ur9wv1ytrZu","executionInfo":{"status":"ok","timestamp":1610537105927,"user_tz":-210,"elapsed":494572,"user":{"displayName":"zeinab taghavi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GheNU3ejtJBEFfDC_0W_JdLEuwkW7SKnnDuH80MRA=s64","userId":"07214630829740929140"}}},"source":["# specify GPU\r\n","device = torch.device(\"cuda\")"],"execution_count":8,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xax4bHubzpMp"},"source":["## Data"]},{"cell_type":"code","metadata":{"id":"TJf6T40glV5g","executionInfo":{"status":"ok","timestamp":1610537106536,"user_tz":-210,"elapsed":495180,"user":{"displayName":"zeinab taghavi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GheNU3ejtJBEFfDC_0W_JdLEuwkW7SKnnDuH80MRA=s64","userId":"07214630829740929140"}}},"source":["limit_number = 750\r\n","data = pandas.read_csv('../Data/limited_to_'+str(limit_number)+'.csv',index_col=0)\r\n","data = data.dropna().reset_index(drop=True)\r\n","X = data[\"body\"].values.tolist()\r\n","y = pandas.read_csv('../Data/limited_to_'+str(limit_number)+'.csv')\r\n","labels = []\r\n","tag=[]\r\n","for item in y['tag']:\r\n","  labels += [i for i in re.sub('\\\"|\\[|\\]|\\'| |=','',item.lower()).split(\",\") if i!='' and i!=' ']\r\n","  tag.append([i for i in re.sub('\\\"|\\[|\\]|\\'| |=','',item.lower()).split(\",\") if i!='' and i!=' '])\r\n","labels = list(set(labels))\r\n","mlb = MultiLabelBinarizer()\r\n","Y=mlb.fit_transform(tag)"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PH3jCKaZsEWo","executionInfo":{"status":"ok","timestamp":1610537106537,"user_tz":-210,"elapsed":495175,"user":{"displayName":"zeinab taghavi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GheNU3ejtJBEFfDC_0W_JdLEuwkW7SKnnDuH80MRA=s64","userId":"07214630829740929140"}},"outputId":"2bac4c81-36e9-44af-b66e-1abdc5fc13e5"},"source":["X_train, X_test, y_train, y_test = train_test_split(X,Y , test_size=0.2)\r\n","X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25)\r\n","print('train: ', len(X_train) , '\\ntest: ', len(X_test) , '\\nval: ', len(X_val) ,\"\\ny_tain:\",len(y_train) )"],"execution_count":10,"outputs":[{"output_type":"stream","text":["train:  12896 \n","test:  4299 \n","val:  4299 \n","y_tain: 12896\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Vei6iu9atmyd","colab":{"base_uri":"https://localhost:8080/","height":213,"referenced_widgets":["005f74c45bdb48149dc5f8a7319d72d8","2a2134a7e8334f89a94093016d2b777d","87cb27ad58b24a0f828632275bd72b28","0a79d0b4b4714313b55ffc760cc68c03","2371bc6668c14d7a9f9edc6f11259cd2","5fd93361b16e49b4aa2b9f7b3e95f693","c0b6cc6a3c054c60a729742099e17356","d168d74cc5a34c5f89da8382aa4859d8","7b26b05e23a540f1bb18e9824ca7fe6e","174ee9ceaf644a6fb6372334b64c52aa","6271830c7c554562a1ee3b71fb705518","97524ce4763e49b7b5b7f059b7a385cd","5bcd3bca4d1144cfb6bc6176041de1d4","83cd548ce4e243fda9f6af4de26afda2","903127f858054433bf129b52f865181c","e3580a1d0e9a4dc0ac2a09b0e9cf4f7f","bc969cd6c3b447c292078343fc9dddcf","845bf2655d064d5fb2bf1e8e7708a370","14463c4ae2b741bf825dadd37cb6d3d8","61b6367eb2884e739e87bce85045580b","2e9dc03222b247db9efb02d7e57cc488","093a6850e2bc40498bdf3c1528b9c4d3","220e691b359e4c8c95b0bd426703d7e5","fd519bdb80ca45f99fc08bc7714b55bf","110e1018b83844c4b3ce9a52c045bd1a","92bbe90e2ffd41f3b7c8cb6e90bfff03","5068b187242d4adda4596015d54856db","5bb27eec533b43d6b3510be06db9cf51","d038c4128d6f456199496b16b1bee8f6","39ae97f1923146388baed2c871e7b061","bb10941a92fc4c33835a22d9d08ff847","7c84898491264b19a8fb20ddaf722150"]},"executionInfo":{"status":"ok","timestamp":1610537108345,"user_tz":-210,"elapsed":496976,"user":{"displayName":"zeinab taghavi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GheNU3ejtJBEFfDC_0W_JdLEuwkW7SKnnDuH80MRA=s64","userId":"07214630829740929140"}},"outputId":"0ca47179-3ea1-447d-998a-08a2cadcbfd5"},"source":["##we would load the tokenizer\r\n","tokenizer = AutoTokenizer.from_pretrained(\"HooshvareLab/bert-fa-base-uncased-clf-persiannews\")"],"execution_count":11,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"005f74c45bdb48149dc5f8a7319d72d8","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1441.0, style=ProgressStyle(description…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"7b26b05e23a540f1bb18e9824ca7fe6e","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1198122.0, style=ProgressStyle(descript…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"bc969cd6c3b447c292078343fc9dddcf","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=112.0, style=ProgressStyle(description_…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"110e1018b83844c4b3ce9a52c045bd1a","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=62.0, style=ProgressStyle(description_w…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"C7wdU0zejDNq","executionInfo":{"status":"ok","timestamp":1610537108346,"user_tz":-210,"elapsed":496970,"user":{"displayName":"zeinab taghavi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GheNU3ejtJBEFfDC_0W_JdLEuwkW7SKnnDuH80MRA=s64","userId":"07214630829740929140"}},"outputId":"d9554325-70d1-40de-daef-9e309fee83c4"},"source":["#example\r\n","text = \"ما در هوشواره معتقدیم با انتقال صحیح دانش و آگاهی، همه افراد میتوانند از ابزارهای هوشمند استفاده کنند. شعار ما هوش مصنوعی برای همه است.\"\r\n","tokenized=tokenizer.tokenize(X_train[0])\r\n","input_ids = tokenizer.convert_tokens_to_ids(tokenized)\r\n","print(tokenized)\r\n","print(input_ids)\r\n"],"execution_count":12,"outputs":[{"output_type":"stream","text":["['مبحث', 'محاسبات', 'مدارات', 'گیت', 'ورودی', 'خروجی', 'توفو', '##لی', 'tof', '##fo', '##li', 'گیتی', 'جامع', 'برگشت', 'پذیر', 'جامع', 'معنی', 'گیت', 'مدار', 'ها', 'برگشت', 'پذیر', 'گیت', 'طراحی', 'پیاده', 'برگشت', 'پذیری', 'ساده', 'خروجی', 'گیت', 'می', 'توانیم', 'مقادیر', 'ورودی', 'ببریم', 'ادامه', 'مقاله', 'همراه', 'گیت', 'توفو', '##لی', 'اشنا', 'نقطه', 'ریاضی', 'تابع', 'برگشت', 'پذیر', 'ازای', 'خروجی', 'ورودی', 'منحصر', 'داشتهباشد', 'رابطه', 'برقرار', 'برگشت', 'پذیر', 'تابع', 'فرم', 'مقادیر', 'نگاشت', 'گیت', 'ها', 'برگشت', 'پذیر', 'سال', '۱۹۶۰', 'دلیل', 'حرارت', 'تولید', 'مطالعه', 'قرار', 'گرفته', 'اند', 'گیت', 'عادی', 'خروجی', 'ها', 'واقع', 'اطلاعات', 'خروجی', 'ورودی', 'ها', 'اطلاعات', 'ورودی', 'گیت', 'ها', 'عادی', 'اطلاعات', 'ورودی', 'می', 'روند', 'رفتن', 'اطلاعات', 'معنی', 'هدر', 'رفتن', 'انرژی', 'قالب', 'گرما', 'دلیل', 'ورودی', 'خروجی', 'ها', 'گیت', 'خروجی', 'ها', 'می', 'توانیم', 'مقادیر', 'ورودی', 'دست', 'بحث', 'برگشت', 'پذیری', 'معماران', 'مهندسان', 'کامپیوتر', 'اهمیت', 'گیت', 'توفو', '##لی', 'control', '##led', 'control', '##led', 'not', 'اختصار', 'cc', '##no', '##t', 'واقع', 'اسم', 'چگونگی', 'عملکرد', 'حکایت', 'کلمه', 'control', '##led', 'می', 'توانیم', 'ببریم', 'ساختار', 'گیت', 'مذکور', 'کنترلی', 'شرطی', 'گیت', 'ها', 'کنترلی', 'اجازه', 'پیاده', 'ساختاری', 'شرطی', 'شبیه', 'else', 'می', 'دانیم', 'واحد', 'اصلی', 'پردازش', 'اطلاعات', 'کلاسیکی', 'بیت', 'bit', 'درستی', 'شرط', 'غلط', 'نمایش', 'می', 'دهیم', 'مثال', 'گیت', 'ورودی', 'control', '##led', 'not', 'گن', '##یم', 'گیت', 'گیت', 'توفو', '##لی', 'توماس', 'توفو', '##لی', 'tom', '##mas', '##o', 'tof', '##fo', '##li', 'سال', '۱۹۸۰', 'ارايه', 'گزینه', 'مناسبی', 'مجموعه', 'ای', 'گیت', 'ها', 'توفو', '##لی', 'می', 'توانیم', 'محاسبه', 'تابع', 'حقیقی', 'برگشت', 'پذیری', 'عملیاتی', 'واقع', 'تابع', 'boole', '##an', 'function', 'فرم', 'می', 'توانیم', 'مداری', 'متشکل', 'گیت', 'توفو', '##لی', 'بسازیم', 'مقادیر', 'صفر', 'اضافی', 'ورودی', 'خروجی', 'عملیات', 'متناظر', 'تابع', 'همراه', 'بیت', 'ها', 'اضافی', 'نتیجه', 'دانیم', 'محاسبات', 'کوانتومی', 'گیت', 'ها', 'نگاشتی', 'نتیجه', 'برگشت', 'پذیرند', 'عملگر', 'اپراتور', 'گیت', 'توفو', '##لی', 'کوانتومی', 'ژانویه', 'سال', '۲۰۰۹', 'دانشگاه', 'اینس', '##برا', '##ک', 'استرالیا', 'ارايه', 'نمایش', 'ماتریسی', 'عملگر', 'توفو', '##لی', 'ماتریس', 'فرم', 'گیت', 'کوانتومی', 'توفو', '##لی', 'همراه', 'گیت', 'ها', 'کیوبیت', '##ی', 'محاسبات', 'جامع', 'فراگیر', 'گیت', 'ها', 'محاسبات', 'کلاسیکی', 'پیاده', 'مثال', 'شکل', 'قرار', 'گیت', 'not', 'کیوبیت', 'ها', 'کنترلی', 'ورود', 'گیت', 'توفو', '##لی', 'not', 'نتیجه', 'نهایی', 'گیت', 'توفو', '##لی', 'می', 'توانیم', 'گیت', 'بسازیم', 'شکل', 'بلوک', 'ماتریس', 'پايولی', 'فرم', 'begin', 'bm', '##at', '##rix', 'end', 'bm', '##at', '##rix', 'محاسبات', 'کوانتومی', 'گیت', 'not', 'مثالی', 'شکل', 'کیوبیت', 'ورودی', 'هدف', 'گیت', 'توفو', '##لی', 'صفر', 'قرار', 'می', 'توانیم', 'گیت', 'and', 'بسازیم', 'قرار', 'گیت', 'not', 'خروجی', 'گیت', 'شکل', 'گیت', 'nand', 'گیتی', 'فراگیر', 'جامع', 'ساخت', 'علاقه', 'مندی', 'مباحث', 'مرتبط', 'علوم', 'مهندسی', 'کامپیوتر', 'اموزش', 'ها', 'پیشنهاد']\n","[15445, 8359, 34564, 8126, 5641, 6945, 35451, 2812, 36002, 36194, 25154, 21411, 5496, 6936, 4108, 5496, 4924, 8126, 4696, 5929, 6936, 4108, 8126, 3841, 5321, 6936, 9585, 4613, 6945, 8126, 2793, 74489, 7977, 5641, 12020, 3251, 6012, 3287, 8126, 35451, 2812, 5369, 4832, 6133, 6312, 6936, 4108, 7535, 6945, 5641, 6730, 25643, 4251, 6138, 6936, 4108, 6312, 4772, 7977, 14698, 8126, 5929, 6936, 4108, 2844, 9178, 3310, 7687, 3114, 4893, 2959, 3296, 3145, 8126, 6111, 6945, 5929, 3473, 3531, 6945, 5641, 5929, 3531, 5641, 8126, 5929, 6111, 3531, 5641, 2793, 4393, 5200, 3531, 4924, 11921, 5200, 4010, 5094, 9262, 3310, 5641, 6945, 5929, 8126, 6945, 5929, 2793, 74489, 7977, 5641, 2910, 4316, 6936, 9585, 15078, 12273, 6075, 4418, 8126, 35451, 2812, 26472, 14485, 26472, 14485, 15936, 13870, 25987, 23148, 2040, 3473, 4907, 7346, 4224, 8814, 6310, 26472, 14485, 2793, 74489, 12020, 4856, 8126, 6301, 15043, 13713, 8126, 5929, 15043, 4463, 5321, 8646, 13713, 5101, 44752, 2793, 95593, 3926, 3376, 7755, 3531, 38038, 5229, 27094, 7201, 7093, 8969, 3528, 2793, 5994, 4183, 8126, 5641, 26472, 14485, 15936, 5647, 2818, 8126, 8126, 35451, 2812, 10872, 35451, 2812, 23775, 72855, 2030, 36002, 36194, 25154, 2844, 8588, 3625, 6917, 5972, 3855, 2938, 8126, 5929, 35451, 2812, 2793, 74489, 5935, 6312, 7514, 6936, 9585, 7000, 3473, 6312, 99770, 3868, 31762, 4772, 2793, 74489, 15031, 8203, 8126, 35451, 2812, 18230, 7977, 6061, 8398, 5641, 6945, 4390, 16508, 6312, 3287, 5229, 5929, 8398, 3680, 95593, 8359, 10706, 8126, 5929, 73018, 3680, 6936, 49416, 19664, 5962, 8126, 35451, 2812, 10706, 6180, 2844, 6753, 3363, 25757, 18560, 2004, 6866, 3625, 3528, 34510, 19664, 35451, 2812, 10801, 4772, 8126, 10706, 35451, 2812, 3287, 8126, 5929, 64726, 2003, 8359, 5496, 9711, 8126, 5929, 8359, 38038, 5321, 4183, 3499, 2959, 8126, 15936, 64726, 5929, 15043, 4247, 8126, 35451, 2812, 15936, 3680, 5035, 8126, 35451, 2812, 2793, 74489, 8126, 18230, 3499, 9059, 10801, 57459, 4772, 60010, 26510, 4304, 25508, 20563, 26510, 4304, 25508, 8359, 10706, 8126, 15936, 16650, 3499, 64726, 5641, 3736, 8126, 35451, 2812, 6061, 2959, 2793, 74489, 8126, 9088, 18230, 2959, 8126, 15936, 6945, 8126, 3499, 8126, 59370, 21411, 9711, 5496, 3043, 5351, 15293, 8309, 4713, 4458, 5461, 6075, 3911, 5929, 4360]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Az4rwU0l5ECn","executionInfo":{"status":"ok","timestamp":1610537108346,"user_tz":-210,"elapsed":496968,"user":{"displayName":"zeinab taghavi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GheNU3ejtJBEFfDC_0W_JdLEuwkW7SKnnDuH80MRA=s64","userId":"07214630829740929140"}}},"source":["# encode text\r\n","sent_id = tokenizer.batch_encode_plus(X_train[:10], padding=True, return_token_type_ids=False)"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oNRU-SH65ZEE","executionInfo":{"status":"ok","timestamp":1610537108347,"user_tz":-210,"elapsed":496962,"user":{"displayName":"zeinab taghavi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GheNU3ejtJBEFfDC_0W_JdLEuwkW7SKnnDuH80MRA=s64","userId":"07214630829740929140"}},"outputId":"ee719854-764b-487a-90f7-e47894402bc9"},"source":["sent_id"],"execution_count":14,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'input_ids': [[2, 15445, 8359, 34564, 8126, 5641, 6945, 35451, 2812, 36002, 36194, 25154, 21411, 5496, 6936, 4108, 5496, 4924, 8126, 4696, 5929, 6936, 4108, 8126, 3841, 5321, 6936, 9585, 4613, 6945, 8126, 2793, 74489, 7977, 5641, 12020, 3251, 6012, 3287, 8126, 35451, 2812, 5369, 4832, 6133, 6312, 6936, 4108, 7535, 6945, 5641, 6730, 25643, 4251, 6138, 6936, 4108, 6312, 4772, 7977, 14698, 8126, 5929, 6936, 4108, 2844, 9178, 3310, 7687, 3114, 4893, 2959, 3296, 3145, 8126, 6111, 6945, 5929, 3473, 3531, 6945, 5641, 5929, 3531, 5641, 8126, 5929, 6111, 3531, 5641, 2793, 4393, 5200, 3531, 4924, 11921, 5200, 4010, 5094, 9262, 3310, 5641, 6945, 5929, 8126, 6945, 5929, 2793, 74489, 7977, 5641, 2910, 4316, 6936, 9585, 15078, 12273, 6075, 4418, 8126, 35451, 2812, 26472, 14485, 26472, 14485, 15936, 13870, 25987, 23148, 2040, 3473, 4907, 7346, 4224, 8814, 6310, 26472, 14485, 2793, 74489, 12020, 4856, 8126, 6301, 15043, 13713, 8126, 5929, 15043, 4463, 5321, 8646, 13713, 5101, 44752, 2793, 95593, 3926, 3376, 7755, 3531, 38038, 5229, 27094, 7201, 7093, 8969, 3528, 2793, 5994, 4183, 8126, 5641, 26472, 14485, 15936, 5647, 2818, 8126, 8126, 35451, 2812, 10872, 35451, 2812, 23775, 72855, 2030, 36002, 36194, 25154, 2844, 8588, 3625, 6917, 5972, 3855, 2938, 8126, 5929, 35451, 2812, 2793, 74489, 5935, 6312, 7514, 6936, 9585, 7000, 3473, 6312, 99770, 3868, 31762, 4772, 2793, 74489, 15031, 8203, 8126, 35451, 2812, 18230, 7977, 6061, 8398, 5641, 6945, 4390, 16508, 6312, 3287, 5229, 5929, 8398, 3680, 95593, 8359, 10706, 8126, 5929, 73018, 3680, 6936, 49416, 19664, 5962, 8126, 35451, 2812, 10706, 6180, 2844, 6753, 3363, 25757, 18560, 2004, 6866, 3625, 3528, 34510, 19664, 35451, 2812, 10801, 4772, 8126, 10706, 35451, 2812, 3287, 8126, 5929, 64726, 2003, 8359, 5496, 9711, 8126, 5929, 8359, 38038, 5321, 4183, 3499, 2959, 8126, 15936, 64726, 5929, 15043, 4247, 8126, 35451, 2812, 15936, 3680, 5035, 8126, 35451, 2812, 2793, 74489, 8126, 18230, 3499, 9059, 10801, 57459, 4772, 60010, 26510, 4304, 25508, 20563, 26510, 4304, 25508, 8359, 10706, 8126, 15936, 16650, 3499, 64726, 5641, 3736, 8126, 35451, 2812, 6061, 2959, 2793, 74489, 8126, 9088, 18230, 2959, 8126, 15936, 6945, 8126, 3499, 8126, 59370, 21411, 9711, 5496, 3043, 5351, 15293, 8309, 4713, 4458, 5461, 6075, 3911, 5929, 4360, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [2, 12835, 5208, 22372, 2014, 88292, 3927, 2867, 4924, 30481, 9225, 3927, 2867, 3573, 4007, 3280, 5290, 5526, 4066, 3531, 4766, 10672, 4472, 3777, 3945, 3927, 2867, 28228, 7754, 2011, 5926, 4108, 12139, 8466, 4108, 11089, 3945, 3927, 2867, 32999, 2816, 6728, 19791, 4110, 11583, 20077, 11654, 35560, 5870, 6310, 31194, 18757, 69017, 3768, 12835, 5929, 3205, 3598, 2011, 3525, 25528, 21081, 5870, 4651, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [2, 5071, 4090, 72768, 48144, 5496, 3287, 3625, 4183, 3640, 2959, 6168, 3559, 5071, 5988, 7775, 5929, 7276, 2938, 5754, 5223, 4274, 5929, 4090, 72768, 48144, 6734, 3640, 7134, 18470, 13699, 3211, 5358, 5993, 26414, 3007, 8751, 3948, 4207, 3911, 5929, 8126, 7134, 18470, 4893, 4251, 5358, 4360, 4090, 72768, 48144, 10339, 8126, 2793, 9868, 10339, 4484, 3731, 4207, 10339, 8126, 44527, 4461, 10339, 6234, 15611, 8126, 10339, 9607, 3731, 12856, 4484, 3813, 72768, 48144, 28134, 72768, 28134, 3972, 2793, 9868, 6037, 46022, 5929, 8126, 10339, 46022, 5929, 76972, 2008, 11940, 8428, 6921, 5929, 7649, 6921, 33970, 3728, 2904, 3073, 8199, 2009, 5929, 3640, 10688, 28134, 72768, 28134, 5782, 52446, 86605, 4484, 4484, 3731, 7729, 6754, 28200, 2031, 8126, 7440, 76972, 2008, 72768, 76972, 2008, 5929, 5875, 72768, 48144, 17677, 9607, 8126, 3910, 76972, 2008, 72768, 3910, 28134, 5426, 5988, 6500, 25643, 2959, 25643, 9341, 15615, 6364, 7275, 72768, 43815, 2025, 3910, 15615, 4828, 72768, 48144, 6921, 17677, 8126, 44527, 4461, 34433, 85054, 45086, 4850, 43815, 2025, 5495, 10351, 4348, 3640, 13129, 9238, 28134, 72768, 10278, 5620, 6921, 17677, 6205, 3910, 5929, 6909, 4712, 5988, 25643, 5094, 5929, 5875, 8428, 4183, 7346, 15607, 4274, 5929, 5094, 4274, 6667, 5094, 5929, 5094, 5929, 5875, 3528, 17677, 72768, 17810, 10130, 5988, 5094, 72768, 17810, 10130, 5929, 4568, 11458, 10339, 8126, 17810, 10130, 5929, 4788, 9607, 17677, 5929, 72768, 48144, 86605, 34433, 86605, 3552, 5988, 86605, 4319, 4090, 28134, 3731, 6198, 3728, 2904, 3073, 6917, 5929, 17677, 3640, 2959, 72768, 48144, 6917, 3920, 5754, 3251, 7168, 96935, 24737, 5350, 3755, 4090, 4431, 5929, 3634, 9593, 70420, 40069, 9529, 5929, 6634, 5929, 4237, 6945, 5929, 3296, 28422, 3939, 19723, 2033, 12507, 2917, 7168, 10339, 19723, 2033, 2793, 9868, 91948, 8811, 24141, 25961, 8811, 43815, 78851, 15515, 12507, 2795, 28134, 2938, 5094, 5929, 85054, 45086, 4850, 43815, 2025, 37863, 2040, 42475, 2955, 6921, 13904, 6037, 3910, 72768, 42475, 2793, 9868, 6921, 10987, 28134, 72768, 1022, 1, 5426, 5850, 5988, 4790, 5605, 28134, 72768, 1022, 1, 4872, 29684, 6921, 5929, 2867, 4484, 25643, 4565, 5929, 9238, 85054, 45086, 4850, 43815, 2025, 3251, 4151, 3145, 40669, 2059, 46799, 18199, 10201, 59191, 18435, 31834, 14543, 9057, 45693, 34076, 21695, 9834, 39425, 2058, 73434, 4090, 5504, 5929, 4825, 10339, 4319, 4816, 60862, 3434, 5929, 30135, 2032, 4825, 5929, 3634, 19055, 5504, 4855, 73222, 41629, 14592, 89511, 15198, 2022, 10339, 3043, 10339, 4795, 3731, 3043, 10339, 19723, 2033, 3043, 5094, 48144, 44527, 4461, 10339, 8126, 7649, 4196, 5850, 4188, 3911, 5929, 4360, 4], [2, 3419, 3329, 12035, 58235, 3310, 68648, 4613, 7273, 5223, 7110, 9227, 4274, 5929, 4089, 18531, 3419, 5929, 3329, 12035, 3810, 3318, 3218, 3419, 5929, 22504, 4861, 15407, 6022, 7223, 4393, 5929, 3692, 4394, 13187, 54995, 3448, 3419, 22504, 9816, 3419, 5929, 3329, 12035, 4861, 15407, 7868, 6012, 5565, 4298, 13187, 54995, 3448, 2930, 5929, 19158, 3525, 4539, 4548, 3307, 5774, 4305, 6630, 7330, 3640, 3419, 5224, 11111, 5209, 3329, 12035, 5690, 7434, 3125, 22504, 26757, 2930, 5929, 19158, 32542, 4069, 2783, 5055, 58235, 3125, 6215, 2844, 5797, 5055, 17790, 5929, 48212, 37027, 7842, 26757, 13187, 54995, 3448, 2930, 5929, 19158, 5001, 3191, 5055, 15221, 3511, 5929, 5254, 6362, 4011, 3100, 9101, 5880, 4004, 6506, 3419, 3329, 12035, 37027, 3511, 3911, 5442, 6552, 14322, 11847, 8141, 5563, 7173, 5506, 3944, 3419, 5929, 4084, 3329, 12035, 2926, 3469, 3945, 6249, 2041, 6111, 7782, 10628, 8357, 3419, 5929, 3329, 12035, 11111, 5506, 3318, 6249, 2041, 15826, 13047, 63606, 4261, 9088, 64109, 24416, 70947, 5642, 16637, 70366, 19513, 8662, 3561, 8747, 2844, 5797, 5055, 37027, 58235, 3201, 68858, 4459, 2844, 6790, 22504, 26757, 5690, 5246, 7668, 58235, 5086, 5422, 32257, 2959, 3473, 2844, 6344, 22504, 5055, 5929, 4533, 2793, 3171, 5055, 5929, 3191, 5055, 58235, 3419, 69327, 2844, 5797, 5055, 5929, 9948, 13187, 54995, 3448, 4533, 3171, 3145, 6506, 3419, 3329, 12035, 22504, 3511, 3911, 5442, 6552, 22504, 11847, 8141, 5563, 7173, 8357, 3419, 5929, 3329, 12035, 5213, 3055, 3640, 8357, 3419, 22504, 2930, 5929, 19158, 31041, 8357, 3419, 5929, 3329, 12035, 3108, 5929, 3381, 8153, 4067, 4156, 7698, 4312, 7330, 3211, 4298, 2910, 2930, 5929, 58235, 5055, 5929, 9948, 4394, 13187, 54995, 3448, 4062, 3088, 6316, 37027, 48212, 46558, 2959, 2844, 6344, 3318, 6629, 3444, 6012, 3361, 13187, 54995, 3448, 2930, 5929, 6783, 9595, 3475, 3419, 5929, 3329, 12035, 5042, 8357, 5563, 7173, 3419, 5351, 3191, 8357, 3419, 5929, 3329, 12035, 2927, 3419, 5161, 8357, 7868, 3944, 18531, 39230, 7560, 5984, 5929, 4816, 11847, 8141, 6468, 7171, 5426, 4002, 6189, 5154, 7843, 11802, 4247, 5469, 7273, 4002, 7173, 5426, 4002, 6189, 5154, 7843, 11802, 4247, 5469, 7273, 4002, 7173, 37620, 4884, 10755, 9258, 5929, 19911, 6596, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [2, 54609, 2011, 3919, 2793, 18537, 3256, 2014, 4826, 10214, 3864, 3333, 4528, 5770, 4576, 8457, 3333, 3864, 5929, 3614, 3843, 5070, 8161, 8925, 4449, 4880, 4825, 3531, 13184, 4825, 4900, 3553, 5033, 4900, 5424, 4002, 4778, 7028, 19082, 2793, 5994, 6947, 3948, 5021, 4900, 3553, 8953, 4826, 5929, 42157, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [2, 4766, 5929, 3916, 4484, 2867, 3218, 1442, 4454, 27626, 2793, 5655, 3439, 8789, 3916, 6137, 4766, 4912, 4484, 5929, 4766, 5929, 6325, 2938, 4766, 5929, 4613, 6342, 3736, 4766, 26978, 2003, 10600, 5929, 3376, 3052, 5929, 3218, 1442, 7252, 3972, 5700, 1442, 6308, 3916, 4484, 8097, 3916, 8554, 6640, 15618, 8276, 3280, 3310, 3052, 5929, 4766, 8919, 6308, 4484, 5929, 36132, 4766, 3088, 3448, 30890, 89511, 2030, 3088, 3448, 4766, 5442, 3916, 4484, 2867, 4613, 11324, 3088, 3448, 3916, 84776, 4766, 5561, 5929, 5108, 4482, 3108, 5929, 4484, 3426, 5929, 6205, 6783, 2938, 2793, 31149, 3088, 3448, 3426, 5929, 2867, 8909, 2867, 10109, 5108, 5929, 3731, 12623, 2938, 12623, 1442, 4241, 6921, 5929, 6205, 6075, 5108, 3280, 12623, 5561, 5108, 5929, 8983, 6640, 15618, 3218, 1442, 4241, 4909, 5929, 5561, 5929, 3948, 11000, 3088, 3448, 5524, 2793, 31149, 4482, 7842, 5001, 3318, 3088, 3448, 4207, 1442, 5859, 5524, 5223, 6342, 4209, 2793, 16881, 4274, 5929, 12374, 3088, 3448, 2793, 31149, 4207, 1442, 6075, 5407, 25534, 4122, 22913, 57212, 10306, 5351, 3952, 15976, 4122, 22913, 2793, 31149, 3952, 3972, 7494, 3280, 5717, 1442, 9424, 10516, 3426, 5929, 19713, 4122, 22913, 3473, 3179, 7494, 4341, 5929, 5574, 11378, 7000, 4824, 4183, 7494, 6079, 2867, 2959, 8748, 4122, 22913, 4274, 10319, 11663, 2008, 2793, 31149, 3229, 4484, 5929, 15976, 11324, 11663, 2008, 4484, 5929, 2793, 31149, 12623, 29083, 5561, 6257, 4484, 5929, 6820, 6500, 3640, 3680, 4766, 3968, 4484, 3640, 3952, 3329, 2867, 5929, 4482, 1442, 6951, 3426, 5929, 3287, 11000, 6921, 5929, 6937, 6095, 5929, 5561, 2867, 8543, 2867, 5717, 3777, 34525, 40004, 2028, 4766, 3852, 11663, 2008, 5859, 2793, 31149, 9728, 4207, 1442, 6259, 12324, 6552, 4209, 11663, 2008, 5392, 5223, 8942, 5929, 6012, 5929, 3050, 5929, 3972, 4319, 3318, 85019, 60912, 23000, 85019, 4766, 8919, 4484, 6783, 4766, 3736, 3841, 3318, 9360, 25834, 4296, 3439, 25643, 2793, 31149, 4766, 3916, 4484, 6386, 3280, 3043, 6386, 5929, 4299, 4274, 5232, 36094, 85019, 4766, 5929, 5442, 3916, 3088, 3448, 7720, 85019, 29285, 4341, 6552, 5196, 4341, 3499, 4732, 3377, 2046, 1393, 3700, 6606, 4341, 1442, 3377, 3700, 19670, 4209, 15890, 6012, 4766, 5929, 3916, 4484, 5369, 3916, 3972, 3404, 4766, 5929, 5563, 3426, 5929, 9360, 25834, 7765, 12835, 3179, 2867, 5442, 79317, 14331, 6501, 3424, 1442, 8408, 23116, 6379, 3469, 2793, 12035, 2015, 14760, 2011, 9172, 12473, 3510, 5796, 34451, 52963, 2011, 4394, 5796, 36469, 2011, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [2, 12835, 5929, 3855, 5929, 2867, 72924, 5076, 3404, 13338, 3280, 4007, 6335, 3499, 3736, 3114, 3573, 27364, 5889, 2006, 3100, 9866, 4321, 3499, 11166, 5752, 3573, 3125, 18182, 5401, 3855, 12835, 4568, 4613, 3088, 14300, 4472, 3088, 5602, 4007, 9221, 8739, 12835, 6724, 4274, 5929, 3376, 8646, 3927, 16069, 5929, 18587, 12835, 8097, 6724, 25799, 6564, 12835, 3419, 4613, 3088, 6347, 3884, 5676, 3573, 4923, 2938, 3823, 3422, 45351, 2003, 6168, 7847, 4691, 4691, 8417, 6155, 7440, 3280, 3027, 3145, 2867, 6192, 3229, 3426, 3625, 3573, 4931, 7692, 6308, 3229, 4338, 10061, 3884, 4110, 3439, 3630, 8394, 4459, 3444, 3823, 3491, 4931, 3497, 39458, 6173, 4639, 2927, 3927, 46008, 2003, 5762, 12835, 4568, 4259, 3927, 2867, 5929, 5323, 19319, 3474, 5762, 3905, 6308, 12835, 4659, 16636, 3469, 5020, 5076, 5418, 3966, 3927, 2867, 5929, 18587, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [2, 5101, 4605, 6292, 4822, 20745, 5101, 4434, 5929, 22184, 3310, 91420, 2874, 4605, 11384, 6364, 5929, 5101, 4434, 5929, 6533, 5574, 7043, 65812, 4207, 5929, 8601, 11846, 3983, 7273, 5875, 2959, 7253, 4497, 9971, 5392, 9262, 53105, 2064, 7872, 2047, 7273, 65812, 90856, 2816, 4992, 4247, 11846, 4691, 3983, 7273, 65812, 3852, 4816, 3517, 8166, 5449, 6597, 53105, 2064, 41862, 86559, 2059, 31762, 11846, 9678, 5929, 4183, 4497, 4828, 5392, 9262, 9971, 4010, 6597, 4366, 5929, 6137, 8776, 3419, 3329, 12035, 6137, 5612, 11846, 35515, 3778, 53105, 2064, 11436, 6533, 5929, 3499, 26353, 3983, 7273, 65812, 4207, 1442, 8601, 6471, 4816, 2959, 6597, 11945, 14404, 3517, 10093, 12273, 13482, 6777, 8012, 6133, 19664, 5929, 6364, 5929, 8751, 6085, 7707, 4822, 5929, 6325, 3517, 8166, 4613, 3088, 4497, 4723, 9971, 3983, 7273, 65812, 11436, 4183, 3951, 31590, 39534, 74211, 3205, 9971, 4010, 6917, 50715, 39636, 2032, 9971, 5392, 4010, 4691, 4113, 9971, 4196, 2904, 3073, 7440, 4366, 5929, 4226, 4207, 5929, 6597, 7094, 11945, 3043, 53105, 2064, 4497, 5392, 9262, 6940, 28482, 93754, 3889, 10622, 5392, 9262, 6940, 28482, 3528, 9971, 4226, 29166, 17395, 2482, 2045, 74766, 1048, 2050, 2043, 4224, 5929, 3983, 7273, 65812, 35043, 4224, 5929, 6133, 32943, 6316, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [2, 7154, 51987, 4017, 4476, 11312, 43647, 5425, 2904, 3073, 10635, 4924, 12077, 4900, 9352, 7212, 3538, 2904, 3073, 4394, 11328, 4825, 4394, 5929, 7154, 5929, 5069, 4002, 4002, 8983, 4002, 4002, 4842, 1442, 5069, 8703, 5967, 7154, 3595, 4002, 7154, 5967, 7154, 6914, 3764, 5785, 3764, 6914, 5353, 4394, 6914, 4900, 5353, 12179, 6914, 3733, 3351, 6914, 4394, 5823, 3504, 3777, 12616, 3630, 4497, 5292, 3733, 5567, 7189, 2979, 6227, 3310, 7953, 58495, 4387, 9910, 3634, 3972, 3504, 6914, 92295, 4497, 7085, 5292, 3201, 4601, 10606, 3777, 8390, 4394, 7154, 5929, 42447, 4900, 4825, 17200, 13089, 9497, 6914, 4394, 6825, 3364, 3347, 59457, 7154, 4303, 7346, 4002, 4828, 70122, 7154, 43647, 5196, 4907, 2927, 13344, 5599, 51987, 5599, 4017, 10635, 4476, 5223, 5582, 3318, 5209, 7886, 8695, 3052, 5929, 10755, 9091, 6596, 4347, 5620, 4394, 7154, 9551, 9087, 39761, 2867, 3376, 4907, 6914, 16680, 2843, 5458, 6012, 80455, 6914, 3927, 2867, 4386, 6914, 6730, 12220, 7212, 5209, 4900, 12220, 9087, 39761, 4259, 5094, 14820, 8633, 5817, 3792, 76274, 2793, 3048, 21354, 13785, 7154, 5929, 4476, 6596, 2927, 66685, 5232, 4825, 4813, 5366, 7154, 6097, 5254, 3363, 5929, 5504, 4259, 8137, 12707, 6712, 2793, 3689, 4788, 2806, 6288, 5196, 36139, 18712, 3567, 7093, 4002, 3625, 12220, 10123, 5108, 3333, 3388, 22623, 13785, 3052, 6097, 4299, 8137, 12707, 6712, 5519, 4319, 2806, 54935, 13785, 7212, 40387, 5504, 4259, 4738, 3911, 5445, 2793, 3689, 31087, 2035, 13785, 5216, 3270, 5929, 4433, 8137, 79587, 33308, 5178, 5243, 13271, 4842, 3052, 3048, 23617, 3052, 5929, 3625, 5839, 4900, 4259, 2927, 74332, 4002, 43647, 11436, 3535, 4002, 7154, 16945, 3229, 4863, 3535, 7154, 3731, 3640, 3064, 35362, 2792, 6269, 76289, 3795, 3595, 3535, 3229, 7154, 4909, 32795, 6461, 3592, 36849, 4909, 9352, 3229, 4942, 5602, 4387, 6198, 19421, 7014, 3404, 22023, 3310, 4605, 26169, 2012, 5196, 10989, 51987, 4472, 4184, 5669, 2784, 63914, 2805, 11312, 4347, 4816, 98785, 74162, 3891, 18808, 3972, 7059, 8649, 4183, 3569, 7995, 34672, 61982, 27029, 2033, 79351, 80193, 7154, 3116, 2005, 5669, 2784, 4465, 8491, 7761, 6304, 11436, 3531, 6012, 3229, 43647, 4893, 3229, 6029, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [2, 3951, 3251, 16698, 5929, 6783, 1035, 64606, 2048, 4879, 4790, 70122, 5988, 38905, 7649, 9925, 5929, 4912, 49225, 14114, 28918, 8094, 49225, 71324, 3852, 2867, 63858, 3083, 5399, 4766, 11999, 5929, 27841, 4766, 98471, 4366, 5929, 23460, 49225, 4241, 7649, 5929, 17687, 26040, 4366, 5929, 8146, 33398, 49225, 52394, 3229, 18009, 71324, 55152, 15766, 18009, 23116, 7615, 12269, 2816, 2959, 26040, 45309, 8146, 7649, 5929, 5444, 2959, 5208, 9225, 13344, 37240, 7761, 5660, 2959, 73811, 9925, 21659, 7649, 2959, 41425, 55549, 5842, 6945, 6820, 7649, 5655, 3030, 8146, 32675, 3968, 7649, 4655, 45676, 22367, 26702, 58164, 7615, 10310, 27989, 17358, 5875, 3460, 5854, 7649, 3880, 5929, 93623, 18230, 13459, 18009, 68019, 16637, 2032, 7649, 10884, 6945, 6820, 9705, 3047, 3880, 4565, 11231, 11904, 2938, 65510, 58164, 4431, 5972, 4816, 15972, 5762, 19791, 81209, 6945, 5884, 3027, 57637, 49225, 18165, 7649, 34233, 3528, 10672, 13344, 9925, 37192, 23376, 2959, 58164, 13344, 37192, 23376, 9925, 11904, 2938, 81209, 5594, 6945, 6820, 13344, 37192, 23376, 2959, 4790, 70122, 5988, 7649, 7201, 7214, 2976, 3020, 17420, 21280, 85197, 79566, 2013, 7964, 7649, 4957, 15059, 81209, 8755, 45243, 58164, 8823, 4639, 8823, 4639, 17521, 15059, 10672, 4766, 58164, 3972, 5823, 4816, 19791, 7615, 4912, 8705, 14114, 5071, 48476, 2816, 36711, 12139, 3598, 7735, 3892, 2874, 3366, 18481, 5916, 8412, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}"]},"metadata":{"tags":[]},"execution_count":14}]},{"cell_type":"code","metadata":{"id":"uF3FFsPzc6zD","executionInfo":{"status":"ok","timestamp":1610537109232,"user_tz":-210,"elapsed":497845,"user":{"displayName":"zeinab taghavi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GheNU3ejtJBEFfDC_0W_JdLEuwkW7SKnnDuH80MRA=s64","userId":"07214630829740929140"}}},"source":["sentence_maxlen=128"],"execution_count":15,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4m2Qc2IkrnEp","executionInfo":{"status":"ok","timestamp":1610537128822,"user_tz":-210,"elapsed":517430,"user":{"displayName":"zeinab taghavi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GheNU3ejtJBEFfDC_0W_JdLEuwkW7SKnnDuH80MRA=s64","userId":"07214630829740929140"}},"outputId":"4a108d23-c973-4cd7-cee1-ae3b6d62e015"},"source":["##Tokenize training and validation sentences:\r\n","train_encodings = tokenizer.batch_encode_plus(X_train,\r\n","    max_length = sentence_maxlen,\r\n","    pad_to_max_length=True,\r\n","    truncation=True,\r\n","    return_token_type_ids=False)\r\n","\r\n","val_encodings = tokenizer.batch_encode_plus(X_val,\r\n","    max_length = sentence_maxlen,\r\n","    pad_to_max_length=True,\r\n","    truncation=True,\r\n","    return_token_type_ids=False)\r\n","\r\n","test_encodings=tokenizer.batch_encode_plus(X_test,\r\n","    max_length = sentence_maxlen,\r\n","    pad_to_max_length=True,\r\n","    truncation=True,\r\n","    return_token_type_ids=False)"],"execution_count":16,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2179: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IwjkXARbetX-","executionInfo":{"status":"ok","timestamp":1610537128824,"user_tz":-210,"elapsed":517426,"user":{"displayName":"zeinab taghavi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GheNU3ejtJBEFfDC_0W_JdLEuwkW7SKnnDuH80MRA=s64","userId":"07214630829740929140"}},"outputId":"3f228c83-1115-4879-dc63-ec6971d6b517"},"source":["train_encodings[0]"],"execution_count":17,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Encoding(num_tokens=128, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing])"]},"metadata":{"tags":[]},"execution_count":17}]},{"cell_type":"code","metadata":{"id":"-iCp2PUEupYK","executionInfo":{"status":"ok","timestamp":1610537128824,"user_tz":-210,"elapsed":517424,"user":{"displayName":"zeinab taghavi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GheNU3ejtJBEFfDC_0W_JdLEuwkW7SKnnDuH80MRA=s64","userId":"07214630829740929140"}}},"source":["import torch\r\n","import torch.nn as nn\r\n","\r\n","# for train set\r\n","train_seq = torch.tensor(train_encodings['input_ids'])\r\n","train_mask = torch.tensor(train_encodings['attention_mask'])\r\n","train_y = torch.tensor(y_train)\r\n","\r\n","# for validation set\r\n","val_seq = torch.tensor(val_encodings['input_ids'])\r\n","val_mask = torch.tensor(val_encodings['attention_mask'])\r\n","val_y = torch.tensor(y_val)\r\n","\r\n","# for test set\r\n","test_seq = torch.tensor(test_encodings['input_ids'])\r\n","test_mask = torch.tensor(test_encodings['attention_mask'])\r\n","test_y = torch.tensor(y_test)"],"execution_count":18,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"h0JkQbxVBmbM","executionInfo":{"status":"ok","timestamp":1610537128825,"user_tz":-210,"elapsed":517419,"user":{"displayName":"zeinab taghavi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GheNU3ejtJBEFfDC_0W_JdLEuwkW7SKnnDuH80MRA=s64","userId":"07214630829740929140"}},"outputId":"268a6650-ffbc-4330-fb5b-23773d7adc58"},"source":["train_y[0]"],"execution_count":19,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 1, 0, 0, 0, 0])"]},"metadata":{"tags":[]},"execution_count":19}]},{"cell_type":"code","metadata":{"id":"T2xiV6Nb0ddZ","executionInfo":{"status":"ok","timestamp":1610537128825,"user_tz":-210,"elapsed":517417,"user":{"displayName":"zeinab taghavi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GheNU3ejtJBEFfDC_0W_JdLEuwkW7SKnnDuH80MRA=s64","userId":"07214630829740929140"}}},"source":["from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\r\n","\r\n","#define a batch size\r\n","batch_size = 32\r\n","\r\n","# wrap tensors\r\n","train_data = TensorDataset(train_seq, train_mask, train_y)\r\n","\r\n","# sampler for sampling the data during training\r\n","train_sampler = RandomSampler(train_data)\r\n","\r\n","# dataLoader for train set\r\n","train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\r\n","\r\n","# wrap tensors\r\n","val_data = TensorDataset(val_seq, val_mask, val_y)\r\n","\r\n","# sampler for sampling the data during training\r\n","val_sampler = SequentialSampler(val_data)\r\n","\r\n","# dataLoader for validation set\r\n","val_dataloader = DataLoader(val_data, sampler = val_sampler, batch_size=batch_size)\r\n","\r\n","# wrap tensors\r\n","test_data = TensorDataset(test_seq, test_mask, test_y)\r\n","\r\n","# sampler for sampling the data during training\r\n","test_sampler = SequentialSampler(test_data)\r\n","\r\n","# dataLoader for validation set\r\n","test_dataloader = DataLoader(test_data, sampler = test_sampler, batch_size=batch_size)"],"execution_count":20,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":749,"referenced_widgets":["6c1ec0e26da047a8a97544c6bdf08e8a","8c7bdeede5894115941c4597cc913210","386e0764eb59489fb902b5e651e24c66","8ef629e33e2d4f1dae1bcbff1bcc3a9a","12d4225ba1624245ac378b802dae39ac","674c72ec223c4635b635c41f511eda27","aea3fb6c20744259817fe361c065dc1e","a9a82c779fd84edca74c5ad52a19da87"]},"id":"UwGHXIjGfmaN","executionInfo":{"status":"ok","timestamp":1610537147908,"user_tz":-210,"elapsed":536494,"user":{"displayName":"zeinab taghavi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GheNU3ejtJBEFfDC_0W_JdLEuwkW7SKnnDuH80MRA=s64","userId":"07214630829740929140"}},"outputId":"e98c6796-17ce-48e1-d455-cb7a99a8b9ad"},"source":["# example\r\n","\r\n","\r\n","text = [\"this is a bert model tutorial\", \"we will fine-tune a bert model\"]\r\n","\r\n","# encode text\r\n","sent_id = tokenizer.batch_encode_plus(text, padding=True, return_token_type_ids=False)\r\n","print(sent_id)\r\n","\r\n","seq = torch.tensor(sent_id['input_ids'])\r\n","mask = torch.tensor(sent_id['attention_mask'])\r\n","train_y = torch.tensor([0,1])\r\n","\r\n","transformer_model = AutoModel.from_pretrained(\"HooshvareLab/bert-fa-base-uncased-clf-persiannews\")\r\n","cls_hs=transformer_model(seq,mask)\r\n","print(cls_hs)\r\n","print(cls_hs[0])\r\n","print(cls_hs[1])\r\n","print(cls_hs[1].shape)"],"execution_count":21,"outputs":[{"output_type":"stream","text":["{'input_ids': [[2, 32071, 9574, 1026, 89390, 36260, 84378, 40908, 2041, 4, 0], [2, 13632, 25909, 70608, 1011, 40716, 2033, 1026, 89390, 36260, 4]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"6c1ec0e26da047a8a97544c6bdf08e8a","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=651477729.0, style=ProgressStyle(descri…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n","BaseModelOutputWithPoolingAndCrossAttentions(last_hidden_state=tensor([[[ 0.0526,  0.5571, -0.4614,  ..., -0.0968,  0.4727,  0.1742],\n","         [-0.2566,  1.5509, -2.0229,  ..., -1.1688, -0.4160,  0.1496],\n","         [-0.1851,  0.1336, -1.3189,  ..., -0.5912, -0.4864,  0.4295],\n","         ...,\n","         [-0.2249,  0.1459, -1.4157,  ..., -0.1764,  0.6163, -0.5646],\n","         [-0.3767, -0.2304, -0.3158,  ..., -0.5575,  0.0901,  0.6220],\n","         [-0.2883,  0.2287, -1.5781,  ..., -0.3559,  0.3813,  0.0665]],\n","\n","        [[ 0.0939, -0.5881, -1.2552,  ...,  0.9090,  0.5908, -0.1969],\n","         [-0.2802, -0.9775, -1.5731,  ...,  0.0902,  0.5980, -0.6988],\n","         [-0.2920, -0.6260, -0.9620,  ..., -0.4935,  0.6855, -1.1112],\n","         ...,\n","         [-0.1571, -0.1198, -2.0160,  ...,  0.3612,  0.7098, -0.9345],\n","         [-0.0399, -0.9591, -1.5613,  ...,  0.6662,  0.1020, -0.0502],\n","         [-0.4564, -1.5508, -0.4116,  ..., -0.1108,  1.1311,  0.2711]]],\n","       grad_fn=<NativeLayerNormBackward>), pooler_output=tensor([[ 0.7309, -0.4917, -0.7028,  ...,  0.3011,  0.4490, -0.6379],\n","        [ 0.9530,  0.1168, -0.2492,  ..., -0.4421,  0.0763, -0.8724]],\n","       grad_fn=<TanhBackward>), hidden_states=None, attentions=None, cross_attentions=None)\n","tensor([[[ 0.0526,  0.5571, -0.4614,  ..., -0.0968,  0.4727,  0.1742],\n","         [-0.2566,  1.5509, -2.0229,  ..., -1.1688, -0.4160,  0.1496],\n","         [-0.1851,  0.1336, -1.3189,  ..., -0.5912, -0.4864,  0.4295],\n","         ...,\n","         [-0.2249,  0.1459, -1.4157,  ..., -0.1764,  0.6163, -0.5646],\n","         [-0.3767, -0.2304, -0.3158,  ..., -0.5575,  0.0901,  0.6220],\n","         [-0.2883,  0.2287, -1.5781,  ..., -0.3559,  0.3813,  0.0665]],\n","\n","        [[ 0.0939, -0.5881, -1.2552,  ...,  0.9090,  0.5908, -0.1969],\n","         [-0.2802, -0.9775, -1.5731,  ...,  0.0902,  0.5980, -0.6988],\n","         [-0.2920, -0.6260, -0.9620,  ..., -0.4935,  0.6855, -1.1112],\n","         ...,\n","         [-0.1571, -0.1198, -2.0160,  ...,  0.3612,  0.7098, -0.9345],\n","         [-0.0399, -0.9591, -1.5613,  ...,  0.6662,  0.1020, -0.0502],\n","         [-0.4564, -1.5508, -0.4116,  ..., -0.1108,  1.1311,  0.2711]]],\n","       grad_fn=<NativeLayerNormBackward>)\n","tensor([[ 0.7309, -0.4917, -0.7028,  ...,  0.3011,  0.4490, -0.6379],\n","        [ 0.9530,  0.1168, -0.2492,  ..., -0.4421,  0.0763, -0.8724]],\n","       grad_fn=<TanhBackward>)\n","torch.Size([2, 768])\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"ByUEn_v4zknn"},"source":["## Model"]},{"cell_type":"code","metadata":{"id":"n3AjEaHcEMfb","executionInfo":{"status":"ok","timestamp":1610537151281,"user_tz":-210,"elapsed":539864,"user":{"displayName":"zeinab taghavi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GheNU3ejtJBEFfDC_0W_JdLEuwkW7SKnnDuH80MRA=s64","userId":"07214630829740929140"}}},"source":["transformer_model = AutoModel.from_pretrained(\"HooshvareLab/bert-fa-base-uncased-clf-persiannews\")"],"execution_count":22,"outputs":[]},{"cell_type":"code","metadata":{"id":"RaAlYydhxPTd","executionInfo":{"status":"ok","timestamp":1610537151283,"user_tz":-210,"elapsed":539861,"user":{"displayName":"zeinab taghavi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GheNU3ejtJBEFfDC_0W_JdLEuwkW7SKnnDuH80MRA=s64","userId":"07214630829740929140"}}},"source":["# freeze all the parameters\r\n","for param in transformer_model.parameters():\r\n","    param.requires_grad = False"],"execution_count":23,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nUa1R1WQONe6","executionInfo":{"status":"ok","timestamp":1610537151284,"user_tz":-210,"elapsed":539855,"user":{"displayName":"zeinab taghavi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GheNU3ejtJBEFfDC_0W_JdLEuwkW7SKnnDuH80MRA=s64","userId":"07214630829740929140"}},"outputId":"ada48428-348e-453c-b44c-edf757ad9ba7"},"source":["len(labels)"],"execution_count":24,"outputs":[{"output_type":"execute_result","data":{"text/plain":["78"]},"metadata":{"tags":[]},"execution_count":24}]},{"cell_type":"code","metadata":{"id":"oyE_ThEms5aZ","executionInfo":{"status":"ok","timestamp":1610537151284,"user_tz":-210,"elapsed":539854,"user":{"displayName":"zeinab taghavi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GheNU3ejtJBEFfDC_0W_JdLEuwkW7SKnnDuH80MRA=s64","userId":"07214630829740929140"}}},"source":["class BERT_Arch(nn.Module):\r\n","\r\n","    def __init__(self, bert):\r\n","      \r\n","      super(BERT_Arch, self).__init__()\r\n","\r\n","      self.bert = bert \r\n","      \r\n","      # dropout layer\r\n","      self.dropout = nn.Dropout(0.1)\r\n","      \r\n","      # relu activation function\r\n","      self.relu =  nn.ReLU()\r\n","\r\n","      # dense layer 1\r\n","      self.fc1 = nn.Linear(768,512)\r\n","      \r\n","      # dense layer 2 (Output layer)\r\n","      self.fc2 = nn.Linear(512,256)\r\n","\r\n","      # dense layer 3 (Output layer)\r\n","      self.fc3 = nn.Linear(256,78)\r\n","\r\n","      #sigmoid activation function\r\n","      self.sigmoid = nn.Sigmoid()\r\n","\r\n","    #define the forward pass\r\n","    def forward(self, sent_id, mask):\r\n","\r\n","      #pass the inputs to the model  \r\n","      cls_hs = self.bert(sent_id, attention_mask=mask)\r\n","      \r\n","      x = self.fc1(cls_hs[1])\r\n","\r\n","      x = self.relu(x)\r\n","\r\n","      x = self.dropout(x)\r\n","\r\n","      # output layer\r\n","      x = self.fc2(x)\r\n","      x = self.relu(x)\r\n","      x = self.fc3(x)\r\n","      \r\n","      # apply sigmoid activation\r\n","      x = self.sigmoid(x)\r\n","\r\n","      return x"],"execution_count":25,"outputs":[]},{"cell_type":"code","metadata":{"id":"rDuHzo96z6z8","executionInfo":{"status":"ok","timestamp":1610537165685,"user_tz":-210,"elapsed":554253,"user":{"displayName":"zeinab taghavi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GheNU3ejtJBEFfDC_0W_JdLEuwkW7SKnnDuH80MRA=s64","userId":"07214630829740929140"}}},"source":["# pass the pre-trained BERT to our define architecture\n","model = BERT_Arch(transformer_model)\n","\n","# push the model to GPU\n","model = model.to(device)"],"execution_count":26,"outputs":[]},{"cell_type":"code","metadata":{"id":"FUNSLBYcLc9q","executionInfo":{"status":"ok","timestamp":1610537165687,"user_tz":-210,"elapsed":554253,"user":{"displayName":"zeinab taghavi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GheNU3ejtJBEFfDC_0W_JdLEuwkW7SKnnDuH80MRA=s64","userId":"07214630829740929140"}}},"source":["# optimizer from hugging face transformers\n","from transformers import AdamW\n","\n","# define the optimizer\n","optimizer = AdamW(model.parameters(), lr = 1e-3)"],"execution_count":27,"outputs":[]},{"cell_type":"code","metadata":{"id":"ArHmwhh7JrZh","executionInfo":{"status":"ok","timestamp":1610537165688,"user_tz":-210,"elapsed":554252,"user":{"displayName":"zeinab taghavi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GheNU3ejtJBEFfDC_0W_JdLEuwkW7SKnnDuH80MRA=s64","userId":"07214630829740929140"}}},"source":["loss_func =nn.MultiLabelSoftMarginLoss()"],"execution_count":28,"outputs":[]},{"cell_type":"code","metadata":{"id":"c8LjQyDXs0bG","executionInfo":{"status":"ok","timestamp":1610537165688,"user_tz":-210,"elapsed":554251,"user":{"displayName":"zeinab taghavi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GheNU3ejtJBEFfDC_0W_JdLEuwkW7SKnnDuH80MRA=s64","userId":"07214630829740929140"}}},"source":["# function to train the model\r\n","def train():\r\n","  \r\n","  model.train()\r\n","\r\n","  total_loss, total_accuracy = 0, 0\r\n","  \r\n","  # empty list to save model predictions\r\n","  total_preds=[]\r\n","  \r\n","  # iterate over batches\r\n","  for step,batch in enumerate(train_dataloader):\r\n","    \r\n","    # progress update after every 50 batches.\r\n","    if step % 50 == 0 and not step == 0:\r\n","      print('  Batch {:>5,}  of  {:>5,}.'.format(step, len(train_dataloader)))\r\n","\r\n","    # push the batch to gpu\r\n","    batch = [r.to(device) for r in batch]\r\n"," \r\n","    sent_id, mask, labels = batch\r\n","\r\n","    # clear previously calculated gradients \r\n","    model.zero_grad()        \r\n","\r\n","    # get model predictions for the current batch\r\n","    preds = model(sent_id, mask)\r\n","\r\n","    # compute the loss between actual and predicted values\r\n","    \r\n","    loss = loss_func(preds, labels)\r\n","    # add on to the total loss\r\n","    total_loss = total_loss + loss.item()\r\n","\r\n","    # backward pass to calculate the gradients\r\n","    loss.backward()\r\n","\r\n","    # clip the the gradients to 1.0. It helps in preventing the exploding gradient problem\r\n","    torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\r\n","\r\n","    # update parameters\r\n","    optimizer.step()\r\n","\r\n","    # model predictions are stored on GPU. So, push it to CPU\r\n","    preds=preds.detach().cpu().numpy()\r\n","\r\n","    # append the model predictions\r\n","    total_preds.append(preds)\r\n","\r\n","  # compute the training loss of the epoch\r\n","  avg_loss = total_loss / len(train_dataloader)\r\n","  \r\n","  # predictions are in the form of (no. of batches, size of batch, no. of classes).\r\n","  # reshape the predictions in form of (number of samples, no. of classes)\r\n","  total_preds  = numpy.concatenate(total_preds, axis=0)\r\n","\r\n","  #returns the loss and predictions\r\n","  return avg_loss, total_preds"],"execution_count":29,"outputs":[]},{"cell_type":"code","metadata":{"id":"XNBRQo9WMHey","executionInfo":{"status":"ok","timestamp":1610537165689,"user_tz":-210,"elapsed":554250,"user":{"displayName":"zeinab taghavi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GheNU3ejtJBEFfDC_0W_JdLEuwkW7SKnnDuH80MRA=s64","userId":"07214630829740929140"}}},"source":["# function for evaluating the model\r\n","def evaluate():\r\n","  \r\n","  print(\"\\nEvaluating...\")\r\n","  \r\n","  # deactivate dropout layers\r\n","  model.eval()\r\n","\r\n","  total_loss, total_accuracy = 0, 0\r\n","  \r\n","  # empty list to save the model predictions\r\n","  total_preds = []\r\n","\r\n","  # iterate over batches\r\n","  for step,batch in enumerate(val_dataloader):\r\n","    \r\n","    # Progress update every 50 batches.\r\n","    if step % 50 == 0 and not step == 0:\r\n","      \r\n","      # Calculate elapsed time in minutes.\r\n","      # elapsed = format_time(time.time() - t0)\r\n","            \r\n","      # Report progress.\r\n","      print('  Batch {:>5,}  of  {:>5,}.'.format(step, len(val_dataloader)))\r\n","\r\n","    # push the batch to gpu\r\n","    batch = [t.to(device) for t in batch]\r\n","\r\n","    sent_id, mask, labels = batch\r\n","\r\n","    # deactivate autograd\r\n","    with torch.no_grad():\r\n","      \r\n","      # model predictions\r\n","      preds = model(sent_id, mask)\r\n","\r\n","      # compute the validation loss between actual and predicted values\r\n","      loss = loss_func(preds,labels)\r\n","\r\n","      total_loss = total_loss + loss.item()\r\n","\r\n","      preds = preds.detach().cpu().numpy()\r\n","\r\n","      total_preds.append(preds)\r\n","\r\n","  # compute the validation loss of the epoch\r\n","  avg_loss = total_loss / len(val_dataloader) \r\n","\r\n","  # reshape the predictions in form of (number of samples, no. of classes)\r\n","  total_preds  = numpy.concatenate(total_preds, axis=0)\r\n","\r\n","  return avg_loss, total_preds"],"execution_count":30,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Qu5pfrJKtTc0","executionInfo":{"status":"ok","timestamp":1610538530238,"user_tz":-210,"elapsed":1918793,"user":{"displayName":"zeinab taghavi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GheNU3ejtJBEFfDC_0W_JdLEuwkW7SKnnDuH80MRA=s64","userId":"07214630829740929140"}},"outputId":"bd223075-4b42-4989-d0f0-555d98d7a111"},"source":["# number of training epochs\r\n","epochs = 10\r\n","\r\n","# set initial loss to infinite\r\n","best_valid_loss = float('inf')\r\n","\r\n","# empty lists to store training and validation loss of each epoch\r\n","train_losses=[]\r\n","valid_losses=[]\r\n","\r\n","#for each epoch\r\n","for epoch in range(epochs):\r\n","     \r\n","    print('\\n Epoch {:} / {:}'.format(epoch + 1, epochs))\r\n","    \r\n","    #train model\r\n","    train_loss, _ = train()\r\n","    \r\n","    #evaluate model\r\n","    valid_loss, _ = evaluate()\r\n","    \r\n","    #save the best model\r\n","    if valid_loss < best_valid_loss:\r\n","        best_valid_loss = valid_loss\r\n","        torch.save(model.state_dict(), 'saved_weights.pt')\r\n","    \r\n","    # append training and validation loss\r\n","    train_losses.append(train_loss)\r\n","    valid_losses.append(valid_loss)\r\n","    \r\n","    print(f'\\nTraining Loss: {train_loss:.3f}')\r\n","    print(f'Validation Loss: {valid_loss:.3f}')"],"execution_count":31,"outputs":[{"output_type":"stream","text":["\n"," Epoch 1 / 10\n","  Batch    50  of    403.\n","  Batch   100  of    403.\n","  Batch   150  of    403.\n","  Batch   200  of    403.\n","  Batch   250  of    403.\n","  Batch   300  of    403.\n","  Batch   350  of    403.\n","  Batch   400  of    403.\n","\n","Evaluating...\n","  Batch    50  of    135.\n","  Batch   100  of    135.\n","\n","Training Loss: 0.697\n","Validation Loss: 0.693\n","\n"," Epoch 2 / 10\n","  Batch    50  of    403.\n","  Batch   100  of    403.\n","  Batch   150  of    403.\n","  Batch   200  of    403.\n","  Batch   250  of    403.\n","  Batch   300  of    403.\n","  Batch   350  of    403.\n","  Batch   400  of    403.\n","\n","Evaluating...\n","  Batch    50  of    135.\n","  Batch   100  of    135.\n","\n","Training Loss: 0.693\n","Validation Loss: 0.693\n","\n"," Epoch 3 / 10\n","  Batch    50  of    403.\n","  Batch   100  of    403.\n","  Batch   150  of    403.\n","  Batch   200  of    403.\n","  Batch   250  of    403.\n","  Batch   300  of    403.\n","  Batch   350  of    403.\n","  Batch   400  of    403.\n","\n","Evaluating...\n","  Batch    50  of    135.\n","  Batch   100  of    135.\n","\n","Training Loss: 0.693\n","Validation Loss: 0.693\n","\n"," Epoch 4 / 10\n","  Batch    50  of    403.\n","  Batch   100  of    403.\n","  Batch   150  of    403.\n","  Batch   200  of    403.\n","  Batch   250  of    403.\n","  Batch   300  of    403.\n","  Batch   350  of    403.\n","  Batch   400  of    403.\n","\n","Evaluating...\n","  Batch    50  of    135.\n","  Batch   100  of    135.\n","\n","Training Loss: 0.693\n","Validation Loss: 0.693\n","\n"," Epoch 5 / 10\n","  Batch    50  of    403.\n","  Batch   100  of    403.\n","  Batch   150  of    403.\n","  Batch   200  of    403.\n","  Batch   250  of    403.\n","  Batch   300  of    403.\n","  Batch   350  of    403.\n","  Batch   400  of    403.\n","\n","Evaluating...\n","  Batch    50  of    135.\n","  Batch   100  of    135.\n","\n","Training Loss: 0.693\n","Validation Loss: 0.693\n","\n"," Epoch 6 / 10\n","  Batch    50  of    403.\n","  Batch   100  of    403.\n","  Batch   150  of    403.\n","  Batch   200  of    403.\n","  Batch   250  of    403.\n","  Batch   300  of    403.\n","  Batch   350  of    403.\n","  Batch   400  of    403.\n","\n","Evaluating...\n","  Batch    50  of    135.\n","  Batch   100  of    135.\n","\n","Training Loss: 0.693\n","Validation Loss: 0.693\n","\n"," Epoch 7 / 10\n","  Batch    50  of    403.\n","  Batch   100  of    403.\n","  Batch   150  of    403.\n","  Batch   200  of    403.\n","  Batch   250  of    403.\n","  Batch   300  of    403.\n","  Batch   350  of    403.\n","  Batch   400  of    403.\n","\n","Evaluating...\n","  Batch    50  of    135.\n","  Batch   100  of    135.\n","\n","Training Loss: 0.693\n","Validation Loss: 0.693\n","\n"," Epoch 8 / 10\n","  Batch    50  of    403.\n","  Batch   100  of    403.\n","  Batch   150  of    403.\n","  Batch   200  of    403.\n","  Batch   250  of    403.\n","  Batch   300  of    403.\n","  Batch   350  of    403.\n","  Batch   400  of    403.\n","\n","Evaluating...\n","  Batch    50  of    135.\n","  Batch   100  of    135.\n","\n","Training Loss: 0.693\n","Validation Loss: 0.693\n","\n"," Epoch 9 / 10\n","  Batch    50  of    403.\n","  Batch   100  of    403.\n","  Batch   150  of    403.\n","  Batch   200  of    403.\n","  Batch   250  of    403.\n","  Batch   300  of    403.\n","  Batch   350  of    403.\n","  Batch   400  of    403.\n","\n","Evaluating...\n","  Batch    50  of    135.\n","  Batch   100  of    135.\n","\n","Training Loss: 0.693\n","Validation Loss: 0.693\n","\n"," Epoch 10 / 10\n","  Batch    50  of    403.\n","  Batch   100  of    403.\n","  Batch   150  of    403.\n","  Batch   200  of    403.\n","  Batch   250  of    403.\n","  Batch   300  of    403.\n","  Batch   350  of    403.\n","  Batch   400  of    403.\n","\n","Evaluating...\n","  Batch    50  of    135.\n","  Batch   100  of    135.\n","\n","Training Loss: 0.693\n","Validation Loss: 0.693\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"GlJpADKkIOqX"},"source":["Loading saved model:"]},{"cell_type":"code","metadata":{"id":"nVrfkSoKIOIV","executionInfo":{"status":"ok","timestamp":1610538545545,"user_tz":-210,"elapsed":1934098,"user":{"displayName":"zeinab taghavi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GheNU3ejtJBEFfDC_0W_JdLEuwkW7SKnnDuH80MRA=s64","userId":"07214630829740929140"}}},"source":["path = 'saved_weights_dense_3.pt'\n","torch.save(model.state_dict(), path)"],"execution_count":32,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"cQ2_aS0zCLvp"},"source":["Loading saved model:"]},{"cell_type":"code","metadata":{"id":"cvR-FhPpuLkR","executionInfo":{"status":"ok","timestamp":1610538545547,"user_tz":-210,"elapsed":1934099,"user":{"displayName":"zeinab taghavi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GheNU3ejtJBEFfDC_0W_JdLEuwkW7SKnnDuH80MRA=s64","userId":"07214630829740929140"}}},"source":["# torch.cuda.empty_cache()\r\n","# pass the pre-trained BERT to our define architecture\r\n","model = BERT_Arch(transformer_model)\r\n","\r\n","# push the model to GPU\r\n","model = model.to(device)"],"execution_count":33,"outputs":[]},{"cell_type":"code","metadata":{"id":"3aOPRZ2jVvNR","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1610538546884,"user_tz":-210,"elapsed":1935433,"user":{"displayName":"zeinab taghavi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GheNU3ejtJBEFfDC_0W_JdLEuwkW7SKnnDuH80MRA=s64","userId":"07214630829740929140"}},"outputId":"c4aa9dad-58f0-4197-90b2-72607cbaed8e"},"source":["#load weights of best model\r\n","path = 'saved_weights_dense_3.pt'\r\n","model.load_state_dict(torch.load(path))"],"execution_count":34,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<All keys matched successfully>"]},"metadata":{"tags":[]},"execution_count":34}]},{"cell_type":"markdown","metadata":{"id":"PM1uUcZFCPVg"},"source":["After loading model:"]},{"cell_type":"code","metadata":{"id":"XZhHObMnzuws","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1610538580700,"user_tz":-210,"elapsed":1969248,"user":{"displayName":"zeinab taghavi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GheNU3ejtJBEFfDC_0W_JdLEuwkW7SKnnDuH80MRA=s64","userId":"07214630829740929140"}},"outputId":"5ae806c2-02f1-4ad2-8045-90ac68dfee42"},"source":["y_pred=[]\r\n","y_true=[]\r\n","for step,batch in enumerate(test_dataloader):\r\n","    \r\n","    # Progress update every 50 batches.\r\n","    if step % 50 == 0 and not step == 0:\r\n","      \r\n","      # Calculate elapsed time in minutes.\r\n","      # elapsed = format_time(time.time() - t0)\r\n","            \r\n","      # Report progress.\r\n","      print('  Batch {:>5,}  of  {:>5,}.'.format(step, len(test_dataloader)))\r\n","\r\n","    # push the batch to gpu\r\n","    batch = [t.to(device) for t in batch]\r\n","\r\n","    sent_id, mask, labels = batch\r\n","\r\n","    # deactivate autograd\r\n","    with torch.no_grad():\r\n","      \r\n","      # model predictions\r\n","      preds = model(sent_id, mask)\r\n","      # print(preds)\r\n","      # print(preds.cpu().numpy())\r\n","      preds = preds.cpu().numpy()\r\n","      # model's performance\r\n","    # preds = numpy.argmax(preds, axis = 1)\r\n","    \r\n","    measure = numpy.mean(preds[0]) + 1.15*numpy.sqrt(numpy.var(preds[0]))\r\n","    for l in preds:\r\n","      temp=[]\r\n","      for value in l:\r\n","        if value >= measure:\r\n","          temp.append(1)\r\n","        else:\r\n","          temp.append(0)\r\n","      y_pred.append(temp)\r\n","    y_true.extend(labels.cpu().numpy())\r\n","    # print(labels.cpu().numpy()[0], preds[0])\r\n","print(classification_report(y_true, y_pred))"],"execution_count":35,"outputs":[{"output_type":"stream","text":["  Batch    50  of    135.\n","  Batch   100  of    135.\n","              precision    recall  f1-score   support\n","\n","           0       0.02      0.22      0.03       115\n","           1       0.04      0.42      0.07       155\n","           2       0.03      0.30      0.05       153\n","           3       0.00      0.40      0.01        15\n","           4       0.03      0.31      0.05        90\n","           5       0.00      0.36      0.01        22\n","           6       0.03      0.60      0.06       135\n","           7       0.01      0.43      0.02        54\n","           8       0.01      0.19      0.01        37\n","           9       0.02      0.26      0.03       101\n","          10       0.02      0.18      0.03       150\n","          11       0.02      0.34      0.03        85\n","          12       0.04      0.47      0.08       155\n","          13       0.00      0.31      0.01        13\n","          14       0.00      0.14      0.00        21\n","          15       0.02      0.20      0.04       153\n","          16       0.02      0.29      0.04       147\n","          17       0.04      0.64      0.08       149\n","          18       0.01      0.22      0.03       107\n","          19       0.02      0.40      0.03        68\n","          20       0.03      0.60      0.06       132\n","          21       0.03      0.41      0.06       143\n","          22       0.01      0.50      0.02        48\n","          23       0.02      0.18      0.04       152\n","          24       0.02      0.54      0.03        84\n","          25       0.05      0.39      0.09       152\n","          26       0.03      0.43      0.05       157\n","          27       0.02      0.16      0.04       146\n","          28       0.02      0.25      0.04       146\n","          29       0.02      0.30      0.04       142\n","          30       0.02      0.44      0.03        64\n","          31       0.03      0.47      0.05        90\n","          32       0.03      0.26      0.05       147\n","          33       0.02      0.15      0.03       163\n","          34       0.02      0.33      0.04        76\n","          35       0.02      0.19      0.04       155\n","          36       0.02      0.38      0.05       130\n","          37       0.01      0.21      0.02        63\n","          38       0.02      0.42      0.04        66\n","          39       0.01      0.30      0.01        33\n","          40       0.03      0.36      0.05       154\n","          41       0.01      0.16      0.02       109\n","          42       0.02      0.39      0.03        88\n","          43       0.02      0.22      0.04       156\n","          44       0.02      0.25      0.05       160\n","          45       0.01      0.63      0.02        30\n","          46       0.01      0.35      0.01        34\n","          47       0.02      0.16      0.03       148\n","          48       0.02      0.39      0.05       147\n","          49       0.02      0.35      0.03        79\n","          50       0.00      0.29      0.01        24\n","          51       0.01      0.31      0.01        26\n","          52       0.02      0.63      0.03        49\n","          53       0.02      0.59      0.04        97\n","          54       0.02      0.22      0.04       145\n","          55       0.01      0.38      0.02        39\n","          56       0.02      0.48      0.04        71\n","          57       0.03      0.60      0.05        57\n","          58       0.05      0.72      0.09       147\n","          59       0.03      0.36      0.05       140\n","          60       0.08      0.63      0.14       161\n","          61       0.01      0.32      0.02        44\n","          62       0.02      0.19      0.04       158\n","          63       0.02      0.23      0.04       151\n","          64       0.01      0.24      0.02        79\n","          65       0.03      0.43      0.06       161\n","          66       0.01      0.62      0.03        37\n","          67       0.03      0.39      0.05       122\n","          68       0.05      0.79      0.09       132\n","          69       0.03      0.28      0.06       163\n","          70       0.04      0.39      0.07       165\n","          71       0.03      0.28      0.05       145\n","          72       0.04      0.35      0.06       144\n","          73       0.01      0.17      0.01        35\n","          74       0.01      0.50      0.01        24\n","          75       0.04      0.47      0.07       156\n","          76       0.02      0.66      0.03        65\n","          77       0.04      0.56      0.07       117\n","\n","   micro avg       0.02      0.36      0.04      8173\n","   macro avg       0.02      0.37      0.04      8173\n","weighted avg       0.03      0.36      0.05      8173\n"," samples avg       0.01      0.41      0.03      8173\n","\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"7ytQvgyzHt8v","executionInfo":{"status":"ok","timestamp":1610538580701,"user_tz":-210,"elapsed":1969247,"user":{"displayName":"zeinab taghavi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GheNU3ejtJBEFfDC_0W_JdLEuwkW7SKnnDuH80MRA=s64","userId":"07214630829740929140"}}},"source":[""],"execution_count":35,"outputs":[]}]}